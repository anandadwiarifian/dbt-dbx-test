{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/manifest/v4.json", "dbt_version": "1.0.3", "generated_at": "2022-03-24T16:28:24.093221Z", "invocation_id": "63b87390-694d-4eb6-92e8-66baeb426a9a", "env": {}, "project_id": "7a996264d086f25c12fe342e6d1bbbbf", "user_id": "321a2b7c-b945-45ee-b4e4-149c1730317d", "send_anonymous_usage_stats": true, "adapter_type": "databricks"}, "nodes": {"model.test_dbx.raw_order_product": {"raw_sql": "SELECT\n    o.order_id AS ORDER_ID,\n    o.order_date AS ORDER_DATE,\n    o.customer_id AS CUSTOMER_ID,\n    op.product_id AS PRODUCT_ID,\n    op.qty AS QTY,\n    op.order_amt AS ORDER_AMT\nFROM \n    {{ source('test_dbt', 'order_product') }} op\n    FULL OUTER JOIN {{ source('test_dbt', 'order') }} o\n    ON op.order_id = o.order_id", "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.test_dbx.test_dbt.order", "source.test_dbx.test_dbt.order_product"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": ["raw"], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "raw_stage", "raw_order_product"], "unique_id": "model.test_dbx.raw_order_product", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "raw_stage/raw_order_product.sql", "original_file_path": "models/raw_stage/raw_order_product.sql", "name": "raw_order_product", "alias": "raw_order_product", "checksum": {"name": "sha256", "checksum": "671153244a1f47e3c8b2092d851f04073fbbe9738a4bb290859389da4d38ec87"}, "tags": ["raw"], "refs": [], "sources": [["test_dbt", "order"], ["test_dbt", "order_product"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "tags": ["raw"]}, "created_at": 1648134126.893783}, "model.test_dbx.raw_product": {"raw_sql": "SELECT\n    product_id AS PRODUCT_ID,\n    product_desc AS PRODUCT_DESC\nFROM \n    {{ source('test_dbt', 'product') }}", "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.test_dbx.test_dbt.product"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": ["raw"], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "raw_stage", "raw_product"], "unique_id": "model.test_dbx.raw_product", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "raw_stage/raw_product.sql", "original_file_path": "models/raw_stage/raw_product.sql", "name": "raw_product", "alias": "raw_product", "checksum": {"name": "sha256", "checksum": "725dfb1ebffdb71b6bb81d42b018a6dccd7fa3a600ff1e02b60f5580ef9ea717"}, "tags": ["raw"], "refs": [], "sources": [["test_dbt", "product"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "tags": ["raw"]}, "created_at": 1648134126.903465}, "model.test_dbx.raw_customer": {"raw_sql": "{{ config(materialized='view') }}\nSELECT\n    customer_id AS CUSTOMER_ID,\n    first_name AS FIRST_NAME,\n    last_name AS LAST_NAME,\n    email AS EMAIL \nFROM \n    {{ source('test_dbt', 'customer') }}", "resource_type": "model", "depends_on": {"macros": [], "nodes": ["source.test_dbx.test_dbt.customer"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": ["raw"], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "raw_stage", "raw_customer"], "unique_id": "model.test_dbx.raw_customer", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "raw_stage/raw_customer.sql", "original_file_path": "models/raw_stage/raw_customer.sql", "name": "raw_customer", "alias": "raw_customer", "checksum": {"name": "sha256", "checksum": "cd60d82a8f75304041b1a709a85b7d2a94a5eb40dcaca8fdd0ec31c568080fe2"}, "tags": ["raw"], "refs": [], "sources": [["test_dbt", "customer"]], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "tags": ["raw"]}, "created_at": 1648134126.905623}, "model.test_dbx.sat_order": {"raw_sql": "{{ config(materialized='view') }}\n\n{%- set yaml_metadata -%}\nsource_model: 'stg_order_product'\nderived_columns:\n  RECORD_SOURCE: \"!1SAP\"\n  LOAD_DATETIME: 'CURRENT_TIMESTAMP()'\nhashed_columns:\n  ORDER_HK: ORDER_ID\n  ORDER_HASHDIFF:\n    is_hashdiff: true\n    columns:\n      - ORDER_DATE\n{%- endset -%}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ dbtvault.stage(include_source_columns=true,\n                  source_model=metadata_dict['source_model'],\n                  derived_columns=metadata_dict['derived_columns'],\n                  hashed_columns=metadata_dict['hashed_columns'],\n                  ranked_columns=none) }}", "resource_type": "model", "depends_on": {"macros": ["macro.dbtvault.stage"], "nodes": ["model.test_dbx.stg_order_product"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": ["datavault"], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "datavault", "sat_order"], "unique_id": "model.test_dbx.sat_order", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "datavault/sat_order.sql", "original_file_path": "models/datavault/sat_order.sql", "name": "sat_order", "alias": "sat_order", "checksum": {"name": "sha256", "checksum": "0e43d2bb359c55beb3e042c4a7c1e6e6b3314bdb51930bd80fd6266f346ca611"}, "tags": ["datavault"], "refs": [["stg_order_product"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "tags": ["datavault"]}, "created_at": 1648138063.086679}, "model.test_dbx.hub_customer": {"raw_sql": "{{ config(\n    materialized='incremental'\n)    }}\n\n{%- set yaml_metadata -%}\nsource_model: stg_customer\nsrc_pk: CUSTOMER_HK\nsrc_nk: CUSTOMER_ID\nsrc_ldts: LOAD_DATETIME\nsrc_source: RECORD_SOURCE\n{%- endset -%}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ dbtvault.hub(src_pk=metadata_dict[\"src_pk\"],\n                src_nk=metadata_dict[\"src_nk\"], \n                src_ldts=metadata_dict[\"src_ldts\"],\n                src_source=metadata_dict[\"src_source\"],\n                source_model=metadata_dict[\"source_model\"]) }}", "resource_type": "model", "depends_on": {"macros": ["macro.dbtvault.hub"], "nodes": ["model.test_dbx.stg_customer"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": ["datavault"], "meta": {}, "materialized": "incremental", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "datavault", "hub_customer"], "unique_id": "model.test_dbx.hub_customer", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "datavault/hub_customer.sql", "original_file_path": "models/datavault/hub_customer.sql", "name": "hub_customer", "alias": "hub_customer", "checksum": {"name": "sha256", "checksum": "f77c6cde1ae71fdcc55004eff6d1028a0245ff2f1192a204251aa9486abd727d"}, "tags": ["datavault"], "refs": [["stg_customer"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "incremental", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "tags": ["datavault"]}, "created_at": 1648138063.2039099}, "model.test_dbx.sat_customer": {"raw_sql": "{{ config(materialized='incremental') }}\n\n{%- set yaml_metadata -%}\nsource_model: \"stg_customer\"\nsrc_pk: \"CUSTOMER_HK\"\nsrc_hashdiff: \n  source_column: \"CUSTOMER_HASHDIFF\"\n  alias: \"HASHDIFF\"\nsrc_payload:\n  - \"FIRST_NAME\"\n  - \"LAST_NAME\"\n  - \"EMAIL\"\nsrc_ldts: \"LOAD_DATETIME\"\nsrc_source: \"RECORD_SOURCE\"\n{%- endset -%}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ dbtvault.sat(src_pk=metadata_dict[\"src_pk\"],\n                src_hashdiff=metadata_dict[\"src_hashdiff\"],\n                src_payload=metadata_dict[\"src_payload\"],\n                src_eff=metadata_dict[\"src_eff\"],\n                src_ldts=metadata_dict[\"src_ldts\"],\n                src_source=metadata_dict[\"src_source\"],\n                source_model=metadata_dict[\"source_model\"])   }}", "resource_type": "model", "depends_on": {"macros": ["macro.dbtvault.sat"], "nodes": ["model.test_dbx.stg_customer"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": ["datavault"], "meta": {}, "materialized": "incremental", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "datavault", "sat_customer"], "unique_id": "model.test_dbx.sat_customer", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "datavault/sat_customer.sql", "original_file_path": "models/datavault/sat_customer.sql", "name": "sat_customer", "alias": "sat_customer", "checksum": {"name": "sha256", "checksum": "91cd8ca86659170885ae28dcc897a0edb0a5d4bac57884382554e4a38c4f5732"}, "tags": ["datavault"], "refs": [["stg_customer"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "incremental", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "tags": ["datavault"]}, "created_at": 1648138063.274131}, "model.test_dbx.stg_customer": {"raw_sql": "{{ config(materialized='view') }}\n\n{%- set yaml_metadata -%}\nsource_model: 'raw_customer'\nderived_columns:\n  RECORD_SOURCE: '!1SAP'\n  LOAD_DATETIME: 'CURRENT_TIMESTAMP()'\nhashed_columns:\n  CUSTOMER_HK: CUSTOMER_ID\n  CUSTOMER_HASHDIFF:\n    is_hashdiff: true\n    columns:\n      - FIRST_NAME\n      - LAST_NAME\n      - EMAIL\n{%- endset -%}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ dbtvault.stage(include_source_columns=true,\n                  source_model=metadata_dict['source_model'],\n                  derived_columns=metadata_dict['derived_columns'],\n                  hashed_columns=metadata_dict['hashed_columns'],\n                  ranked_columns=none) }}", "resource_type": "model", "depends_on": {"macros": ["macro.dbtvault.stage"], "nodes": ["model.test_dbx.raw_customer"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "stage", "stg_customer"], "unique_id": "model.test_dbx.stg_customer", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "stage/stg_customer.sql", "original_file_path": "models/stage/stg_customer.sql", "name": "stg_customer", "alias": "stg_customer", "checksum": {"name": "sha256", "checksum": "4fef1612c5dfc44aee300d4671c34dbc0b79765d9a3426cb05c623ac4aa39451"}, "tags": [], "refs": [["raw_customer"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view"}, "created_at": 1648138063.3156202}, "model.test_dbx.hub_order": {"raw_sql": "{{ config(materialized='incremental') }}\n\n{%- set yaml_metadata -%}\nsource_model: stg_order_product\nsrc_pk: ORDER_HK\nsrc_nk: ORDER_ID\nsrc_ldts: LOAD_DATETIME\nsrc_source: RECORD_SOURCE\n{%- endset -%}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ dbtvault.hub(src_pk=metadata_dict[\"src_pk\"],\n                src_nk=metadata_dict[\"src_nk\"], \n                src_ldts=metadata_dict[\"src_ldts\"],\n                src_source=metadata_dict[\"src_source\"],\n                source_model=metadata_dict[\"source_model\"]) }}", "resource_type": "model", "depends_on": {"macros": ["macro.dbtvault.hub"], "nodes": ["model.test_dbx.stg_order_product"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": ["datavault"], "meta": {}, "materialized": "incremental", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "datavault", "hub_order"], "unique_id": "model.test_dbx.hub_order", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "datavault/hub_order.sql", "original_file_path": "models/datavault/hub_order.sql", "name": "hub_order", "alias": "hub_order", "checksum": {"name": "sha256", "checksum": "7dd0f800c086876217f010d6904e6dfbe69f0bde81cbcdbda456d31440b7d156"}, "tags": ["datavault"], "refs": [["stg_order_product"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "incremental", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "tags": ["datavault"]}, "created_at": 1648138063.340758}, "model.test_dbx.stg_order_product": {"raw_sql": "{{ config(materialized='view') }}\n\n{%- set yaml_metadata -%}\nsource_model: 'raw_order_product'\nderived_columns:\n  RECORD_SOURCE: '!1SAP'\n  LOAD_DATETIME: 'CURRENT_TIMESTAMP()'\n  CUSTOMER_ID: CUSTOMER_ID\n  PRODUCT_ID: PRODUCT_ID\nhashed_columns:\n  ORDER_HK: ORDER_ID\n  LINK_ORDER_PRODUCT_HK:\n     - ORDER_ID\n     - PRODUCT_ID\n     - CUSTOMER_ID\n  ORDER_HASHDIFF:\n    is_hashdiff: true\n    columns:\n      - ORDER_DATE\n  ORDER_PRODUCT_HASHDIFF:\n    is_hashdiff: true\n    columns:\n      - QTY\n      - ORDER_AMT\n{%- endset -%}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ dbtvault.stage(include_source_columns=true,\n                  source_model=metadata_dict['source_model'],\n                  derived_columns=metadata_dict['derived_columns'],\n                  hashed_columns=metadata_dict['hashed_columns'],\n                  ranked_columns=none) }}", "resource_type": "model", "depends_on": {"macros": ["macro.dbtvault.stage"], "nodes": ["model.test_dbx.raw_order_product"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "stage", "stg_order_product"], "unique_id": "model.test_dbx.stg_order_product", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "stage/stg_order_product.sql", "original_file_path": "models/stage/stg_order_product.sql", "name": "stg_order_product", "alias": "stg_order_product", "checksum": {"name": "sha256", "checksum": "535ef2742c878797606160155425d44f8c1655cc6966af2b671717a1482682d8"}, "tags": [], "refs": [["raw_order_product"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view"}, "created_at": 1648138063.3715048}, "model.test_dbx.hub_product": {"raw_sql": "{{ config(materialized='incremental') }}\n\n{%- set yaml_metadata -%}\nsource_model: stg_product\nsrc_pk: PRODUCT_HK\nsrc_nk: PRODUCT_ID\nsrc_ldts: LOAD_DATETIME\nsrc_source: RECORD_SOURCE\n{%- endset -%}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ dbtvault.hub(src_pk=metadata_dict[\"src_pk\"],\n                src_nk=metadata_dict[\"src_nk\"], \n                src_ldts=metadata_dict[\"src_ldts\"],\n                src_source=metadata_dict[\"src_source\"],\n                source_model=metadata_dict[\"source_model\"]) }}", "resource_type": "model", "depends_on": {"macros": ["macro.dbtvault.hub"], "nodes": ["model.test_dbx.stg_product"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": ["datavault"], "meta": {}, "materialized": "incremental", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "datavault", "hub_product"], "unique_id": "model.test_dbx.hub_product", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "datavault/hub_product.sql", "original_file_path": "models/datavault/hub_product.sql", "name": "hub_product", "alias": "hub_product", "checksum": {"name": "sha256", "checksum": "494371905d4a4009106cea2219fa3e6f228f6dadec83e156d38e25ede25cd975"}, "tags": ["datavault"], "refs": [["stg_product"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "incremental", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "tags": ["datavault"]}, "created_at": 1648138063.412095}, "model.test_dbx.sat_product": {"raw_sql": "{{ config(materialized='incremental') }}\n\n{%- set yaml_metadata -%}\nsource_model: \"stg_product\"\nsrc_pk: \"PRODUCT_HK\"\nsrc_hashdiff: \n  source_column: \"PRODUCT_HASHDIFF\"\n  alias: \"HASHDIFF\"\nsrc_payload:\n  - \"PRODUCT_DESC\"\nsrc_ldts: \"LOAD_DATETIME\"\nsrc_source: \"RECORD_SOURCE\"\n{%- endset -%}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ dbtvault.sat(src_pk=metadata_dict[\"src_pk\"],\n                src_hashdiff=metadata_dict[\"src_hashdiff\"],\n                src_payload=metadata_dict[\"src_payload\"],\n                src_eff=metadata_dict[\"src_eff\"],\n                src_ldts=metadata_dict[\"src_ldts\"],\n                src_source=metadata_dict[\"src_source\"],\n                source_model=metadata_dict[\"source_model\"])   }}", "resource_type": "model", "depends_on": {"macros": ["macro.dbtvault.sat"], "nodes": ["model.test_dbx.stg_product"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": ["datavault"], "meta": {}, "materialized": "incremental", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "datavault", "sat_product"], "unique_id": "model.test_dbx.sat_product", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "datavault/sat_product.sql", "original_file_path": "models/datavault/sat_product.sql", "name": "sat_product", "alias": "sat_product", "checksum": {"name": "sha256", "checksum": "b9b525985660bf47112450dab731c398740ee4eae635b1b117b671c21a224672"}, "tags": ["datavault"], "refs": [["stg_product"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "incremental", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "tags": ["datavault"]}, "created_at": 1648138063.42633}, "model.test_dbx.stg_product": {"raw_sql": "{{ config(materialized='view') }}\n\n{%- set yaml_metadata -%}\nsource_model: 'raw_product'\nderived_columns:\n  RECORD_SOURCE: \"!1SAP\"\n  LOAD_DATETIME: 'CURRENT_TIMESTAMP()'\nhashed_columns:\n  PRODUCT_HK: PRODUCT_ID\n  PRODUCT_HASHDIFF:\n    is_hashdiff: true\n    columns:\n      - PRODUCT_DESC\n{%- endset -%}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ dbtvault.stage(include_source_columns=true,\n                  source_model=metadata_dict['source_model'],\n                  derived_columns=metadata_dict['derived_columns'],\n                  hashed_columns=metadata_dict['hashed_columns'],\n                  ranked_columns=none) }}", "resource_type": "model", "depends_on": {"macros": ["macro.dbtvault.stage"], "nodes": ["model.test_dbx.raw_product"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": [], "meta": {}, "materialized": "view", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "stage", "stg_product"], "unique_id": "model.test_dbx.stg_product", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "stage/stg_product.sql", "original_file_path": "models/stage/stg_product.sql", "name": "stg_product", "alias": "stg_product", "checksum": {"name": "sha256", "checksum": "ea42b8db50f41f6be668f15001de8faf68e3743cc95e62b45d7970db15e74ce9"}, "tags": [], "refs": [["raw_product"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "view"}, "created_at": 1648138063.44105}, "model.test_dbx.link_order_product": {"raw_sql": "{%- set yaml_metadata -%}\nsource_model: stg_order_product\nsrc_pk: LINK_ORDER_PRODUCT_HK\nsrc_fk: \n  - ORDER_ID\n  - PRODUCT_ID\n  - CUSTOMER_ID\nsrc_ldts: LOAD_DATETIME\nsrc_source: RECORD_SOURCE\n{%- endset -%}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ dbtvault.link(src_pk=metadata_dict[\"src_pk\"],\n                 src_fk=metadata_dict[\"src_fk\"], \n                 src_ldts=metadata_dict[\"src_ldts\"],\n                 src_source=metadata_dict[\"src_source\"], \n                 source_model=metadata_dict[\"source_model\"]) }}", "resource_type": "model", "depends_on": {"macros": ["macro.dbtvault.link"], "nodes": ["model.test_dbx.stg_order_product"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": ["datavault"], "meta": {}, "materialized": "incremental", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "datavault", "link_order_product"], "unique_id": "model.test_dbx.link_order_product", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "datavault/link_order_product.sql", "original_file_path": "models/datavault/link_order_product.sql", "name": "link_order_product", "alias": "link_order_product", "checksum": {"name": "sha256", "checksum": "07463171a5d9641cc1133f728420367e49a9d21273731e6476591c69a3bc8163"}, "tags": ["datavault"], "refs": [["stg_order_product"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": null, "build_path": null, "deferred": false, "unrendered_config": {"materialized": "incremental", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "tags": ["datavault"]}, "created_at": 1648139130.304919}, "model.test_dbx.sat_order_product": {"raw_sql": "{{ config(materialized='incremental') }}\n\n{%- set yaml_metadata -%}\nsource_model: \"stg_order_product\"\nsrc_pk: \"LINK_ORDER_PRODUCT_HK\"\nsrc_hashdiff: \n  source_column: \"ORDER_PRODUCT_HASHDIFF\"\n  alias: \"HASHDIFF\"\nsrc_payload:\n  - \"QTY\"\n  - \"ORDER_AMT\"\nsrc_ldts: \"LOAD_DATETIME\"\nsrc_source: \"RECORD_SOURCE\"\n{%- endset -%}\n\n{% set metadata_dict = fromyaml(yaml_metadata) %}\n\n{{ dbtvault.sat(src_pk=metadata_dict[\"src_pk\"],\n                src_hashdiff=metadata_dict[\"src_hashdiff\"],\n                src_payload=metadata_dict[\"src_payload\"],\n                src_eff=metadata_dict[\"src_eff\"],\n                src_ldts=metadata_dict[\"src_ldts\"],\n                src_source=metadata_dict[\"src_source\"],\n                source_model=metadata_dict[\"source_model\"])   }}", "compiled": true, "resource_type": "model", "depends_on": {"macros": ["macro.dbtvault.sat", "macro.dbt_spark.dbt_spark_validate_get_file_format", "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy", "macro.dbt.should_full_refresh", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.load_relation", "macro.dbt.make_temp_relation", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt.statement", "macro.dbt.persist_docs"], "nodes": ["model.test_dbx.stg_order_product"]}, "config": {"enabled": true, "alias": null, "schema": null, "database": null, "tags": ["datavault"], "meta": {}, "materialized": "incremental", "persist_docs": {}, "quoting": {}, "column_types": {}, "full_refresh": null, "on_schema_change": "ignore", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "post-hook": [], "pre-hook": []}, "database": null, "schema": "test_dbt", "fqn": ["test_dbx", "datavault", "sat_order_product"], "unique_id": "model.test_dbx.sat_order_product", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "datavault/sat_order_product.sql", "original_file_path": "models/datavault/sat_order_product.sql", "name": "sat_order_product", "alias": "sat_order_product", "checksum": {"name": "sha256", "checksum": "243ba4b0ed45dc7bcd7094ba8fece20dd9bc1593d57c56c36193e5cdc45f90b9"}, "tags": ["datavault"], "refs": [["stg_order_product"]], "sources": [], "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "compiled_path": "target/compiled/test_dbx/models/datavault/sat_order_product.sql", "build_path": "target/run/test_dbx/models/datavault/sat_order_product.sql", "deferred": false, "unrendered_config": {"materialized": "incremental", "file_format": "delta", "location_root": "/mnt/adls_ss_finance/SS Finance/test", "incremental_strategy": "append", "tags": ["datavault"]}, "created_at": 1648139304.372958, "compiled_sql": "\n\n-- Generated by dbtvault.\n\nWITH source_data AS (\n    SELECT a.LINK_ORDER_PRODUCT_HK, a.ORDER_PRODUCT_HASHDIFF, a.QTY, a.ORDER_AMT, a.LOAD_DATETIME, a.RECORD_SOURCE\n    FROM test_dbt.stg_order_product AS a\n    WHERE a.LINK_ORDER_PRODUCT_HK IS NOT NULL\n),\n\n\n\nrecords_to_insert AS (\n    SELECT DISTINCT stage.LINK_ORDER_PRODUCT_HK, stage.ORDER_PRODUCT_HASHDIFF AS HASHDIFF, stage.QTY, stage.ORDER_AMT, stage.LOAD_DATETIME, stage.RECORD_SOURCE\n    FROM source_data AS stage\n)\n\nSELECT * FROM records_to_insert", "extra_ctes_injected": true, "extra_ctes": [], "relation_name": "test_dbt.sat_order_product"}}, "sources": {"source.test_dbx.test_dbt.customer": {"fqn": ["test_dbx", "test_dbt", "customer"], "database": null, "schema": "test_dbt", "unique_id": "source.test_dbx.test_dbt.customer", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "models/schema.yaml", "original_file_path": "models/schema.yaml", "name": "customer", "source_name": "test_dbt", "source_description": "", "loader": "", "identifier": "customer", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "test_dbt.customer", "created_at": 1648134127.201749}, "source.test_dbx.test_dbt.product": {"fqn": ["test_dbx", "test_dbt", "product"], "database": null, "schema": "test_dbt", "unique_id": "source.test_dbx.test_dbt.product", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "models/schema.yaml", "original_file_path": "models/schema.yaml", "name": "product", "source_name": "test_dbt", "source_description": "", "loader": "", "identifier": "product", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "test_dbt.product", "created_at": 1648134127.2018921}, "source.test_dbx.test_dbt.order": {"fqn": ["test_dbx", "test_dbt", "order"], "database": null, "schema": "test_dbt", "unique_id": "source.test_dbx.test_dbt.order", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "models/schema.yaml", "original_file_path": "models/schema.yaml", "name": "order", "source_name": "test_dbt", "source_description": "", "loader": "", "identifier": "order", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "test_dbt.order", "created_at": 1648134127.2020092}, "source.test_dbx.test_dbt.order_product": {"fqn": ["test_dbx", "test_dbt", "order_product"], "database": null, "schema": "test_dbt", "unique_id": "source.test_dbx.test_dbt.order_product", "package_name": "test_dbx", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx", "path": "models/schema.yaml", "original_file_path": "models/schema.yaml", "name": "order_product", "source_name": "test_dbt", "source_description": "", "loader": "", "identifier": "order_product", "resource_type": "source", "quoting": {"database": null, "schema": null, "identifier": null, "column": null}, "loaded_at_field": null, "freshness": {"warn_after": {"count": null, "period": null}, "error_after": {"count": null, "period": null}, "filter": null}, "external": null, "description": "", "columns": {}, "meta": {}, "source_meta": {}, "tags": [], "config": {"enabled": true}, "patch_path": null, "unrendered_config": {}, "relation_name": "test_dbt.order_product", "created_at": 1648134127.2022169}}, "macros": {"macro.dbt_databricks.dbt_databricks_file_format_clause": {"unique_id": "macro.dbt_databricks.dbt_databricks_file_format_clause", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "dbt_databricks_file_format_clause", "macro_sql": "{% macro dbt_databricks_file_format_clause() %}\n  {%- set file_format = config.get('file_format', default='delta') -%}\n  {%- if file_format is not none %}\n    using {{ file_format }}\n  {%- endif %}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.033897}, "macro.dbt_databricks.dbt_databricks_location_clause": {"unique_id": "macro.dbt_databricks.dbt_databricks_location_clause", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "dbt_databricks_location_clause", "macro_sql": "{% macro dbt_databricks_location_clause() %}\n  {%- set location_root = config.get('location_root', validator=validation.any[basestring]) -%}\n  {%- set identifier = model['alias'] -%}\n  {%- if location_root is not none %}\n    location '{{ location_root }}/{{ identifier }}'\n  {%- endif %}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.034871}, "macro.dbt_databricks.dbt_databricks_options_clause": {"unique_id": "macro.dbt_databricks.dbt_databricks_options_clause", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "dbt_databricks_options_clause", "macro_sql": "{% macro dbt_databricks_options_clause() -%}\n  {%- set options = config.get('options') -%}\n  {%- if config.get('file_format', default='delta') == 'hudi' -%}\n    {%- set unique_key = config.get('unique_key') -%}\n    {%- if unique_key is not none and options is none -%}\n      {%- set options = {'primaryKey': config.get('unique_key')} -%}\n    {%- elif unique_key is not none and options is not none and 'primaryKey' not in options -%}\n      {%- set _ = options.update({'primaryKey': config.get('unique_key')}) -%}\n    {%- elif options is not none and 'primaryKey' in options and options['primaryKey'] != unique_key -%}\n      {{ exceptions.raise_compiler_error(\"unique_key and options('primaryKey') should be the same column(s).\") }}\n    {%- endif %}\n  {%- endif %}\n\n  {%- if options is not none %}\n    options (\n      {%- for option in options -%}\n      {{ option }} \"{{ options[option] }}\" {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.037858}, "macro.dbt_databricks.dbt_databricks_comment_clause": {"unique_id": "macro.dbt_databricks.dbt_databricks_comment_clause", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "dbt_databricks_comment_clause", "macro_sql": "{% macro dbt_databricks_comment_clause() %}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n\n  {%- if raw_persist_docs is mapping -%}\n    {%- set raw_relation = raw_persist_docs.get('relation', false) -%}\n      {%- if raw_relation -%}\n      comment '{{ model.description | replace(\"'\", \"\\\\'\") }}'\n      {% endif %}\n  {%- elif raw_persist_docs -%}\n    {{ exceptions.raise_compiler_error(\"Invalid value provided for 'persist_docs'. Expected dict but got value: \" ~ raw_persist_docs) }}\n  {% endif %}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.0391822}, "macro.dbt_databricks.dbt_databricks_partition_cols": {"unique_id": "macro.dbt_databricks.dbt_databricks_partition_cols", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "dbt_databricks_partition_cols", "macro_sql": "{% macro dbt_databricks_partition_cols(label, required=false) %}\n  {%- set cols = config.get('partition_by', validator=validation.any[list, basestring]) -%}\n  {%- if cols is not none %}\n    {%- if cols is string -%}\n      {%- set cols = [cols] -%}\n    {%- endif -%}\n    {{ label }} (\n    {%- for item in cols -%}\n      {{ item }}\n      {%- if not loop.last -%},{%- endif -%}\n    {%- endfor -%}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.040541}, "macro.dbt_databricks.dbt_databricks_clustered_cols": {"unique_id": "macro.dbt_databricks.dbt_databricks_clustered_cols", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "dbt_databricks_clustered_cols", "macro_sql": "{% macro dbt_databricks_clustered_cols(label, required=false) %}\n  {%- set cols = config.get('clustered_by', validator=validation.any[list, basestring]) -%}\n  {%- set buckets = config.get('buckets', validator=validation.any[int]) -%}\n  {%- if (cols is not none) and (buckets is not none) %}\n    {%- if cols is string -%}\n      {%- set cols = [cols] -%}\n    {%- endif -%}\n    {{ label }} (\n    {%- for item in cols -%}\n      {{ item }}\n      {%- if not loop.last -%},{%- endif -%}\n    {%- endfor -%}\n    ) into {{ buckets }} buckets\n  {%- endif %}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.04235}, "macro.dbt_databricks.dbt_databricks_create_temporary_view": {"unique_id": "macro.dbt_databricks.dbt_databricks_create_temporary_view", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "dbt_databricks_create_temporary_view", "macro_sql": "{% macro dbt_databricks_create_temporary_view(relation, sql) -%}\n  create temporary view {{ relation.include(schema=false) }} as\n    {{ sql }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.042808}, "macro.dbt_databricks.databricks__create_table_as": {"unique_id": "macro.dbt_databricks.databricks__create_table_as", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "databricks__create_table_as", "macro_sql": "{% macro databricks__create_table_as(temporary, relation, sql) -%}\n  {% if temporary -%}\n    {{ dbt_databricks_create_temporary_view(relation, sql) }}\n  {%- else -%}\n    {% if config.get('file_format', default='delta') == 'delta' %}\n      create or replace table {{ relation }}\n    {% else %}\n      create table {{ relation }}\n    {% endif %}\n    {{ dbt_databricks_file_format_clause() }}\n    {{ dbt_databricks_options_clause() }}\n    {{ dbt_databricks_partition_cols(label=\"partitioned by\") }}\n    {{ dbt_databricks_clustered_cols(label=\"clustered by\") }}\n    {{ dbt_databricks_location_clause() }}\n    {{ dbt_databricks_comment_clause() }}\n    as\n      {{ sql }}\n  {%- endif %}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_databricks.dbt_databricks_create_temporary_view", "macro.dbt_databricks.dbt_databricks_file_format_clause", "macro.dbt_databricks.dbt_databricks_options_clause", "macro.dbt_databricks.dbt_databricks_partition_cols", "macro.dbt_databricks.dbt_databricks_clustered_cols", "macro.dbt_databricks.dbt_databricks_location_clause", "macro.dbt_databricks.dbt_databricks_comment_clause"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.044405}, "macro.dbt_databricks.databricks__create_view_as": {"unique_id": "macro.dbt_databricks.databricks__create_view_as", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "databricks__create_view_as", "macro_sql": "{% macro databricks__create_view_as(relation, sql) -%}\n  create or replace view {{ relation }}\n  {{ dbt_databricks_comment_clause() }}\n  as\n    {{ sql }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_databricks.dbt_databricks_comment_clause"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.044864}, "macro.dbt_databricks.databricks__alter_column_comment": {"unique_id": "macro.dbt_databricks.databricks__alter_column_comment", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "databricks__alter_column_comment", "macro_sql": "{% macro databricks__alter_column_comment(relation, column_dict) %}\n  {% if config.get('file_format', default='delta') in ['delta', 'hudi'] %}\n    {% for column_name in column_dict %}\n      {% set comment = column_dict[column_name]['description'] %}\n      {% set escaped_comment = comment | replace('\\'', '\\\\\\'') %}\n      {% set comment_query %}\n        alter table {{ relation }} change column \n            {{ adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name }}\n            comment '{{ escaped_comment }}';\n      {% endset %}\n      {% do run_query(comment_query) %}\n    {% endfor %}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.046649}, "macro.dbt_databricks.databricks__get_binding_char": {"unique_id": "macro.dbt_databricks.databricks__get_binding_char", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "name": "databricks__get_binding_char", "macro_sql": "{% macro databricks__get_binding_char() %}\n  {{ return('%s') }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.0482152}, "macro.dbt_databricks.databricks__create_csv_table": {"unique_id": "macro.dbt_databricks.databricks__create_csv_table", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "name": "databricks__create_csv_table", "macro_sql": "{% macro databricks__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n    {{ dbt_databricks_file_format_clause() }}\n    {{ dbt_databricks_partition_cols(label=\"partitioned by\") }}\n    {{ dbt_databricks_clustered_cols(label=\"clustered by\") }}\n    {{ dbt_databricks_location_clause() }}\n    {{ dbt_databricks_comment_clause() }}\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_databricks.dbt_databricks_file_format_clause", "macro.dbt_databricks.dbt_databricks_partition_cols", "macro.dbt_databricks.dbt_databricks_clustered_cols", "macro.dbt_databricks.dbt_databricks_location_clause", "macro.dbt_databricks.dbt_databricks_comment_clause", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.050899}, "macro.dbt_databricks.materialization_view_databricks": {"unique_id": "macro.dbt_databricks.materialization_view_databricks", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "name": "materialization_view_databricks", "macro_sql": "{% materialization view, adapter='databricks' -%}\n    {{ return(create_or_replace_view()) }}\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.create_or_replace_view"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.0515351}, "macro.dbt_databricks.materialization_table_databricks": {"unique_id": "macro.dbt_databricks.materialization_table_databricks", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "name": "materialization_table_databricks", "macro_sql": "{% materialization table, adapter = 'databricks' %}\n\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n\n  {{ run_hooks(pre_hooks) }}\n\n  -- setup: if the target relation already exists, drop it\n  -- in case if the existing and future table is delta, we want to do a\n  -- create or replace table instead of dropping, so we don't have the table unavailable\n  {% if old_relation and not (old_relation.is_delta and config.get('file_format', default='delta') == 'delta') -%}\n    {{ adapter.drop_relation(old_relation) }}\n  {%- endif %}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_table_as(False, target_relation, sql) }}\n  {%- endcall %}\n  \n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]})}}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.create_table_as", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.0546901}, "macro.dbt_databricks.databricks_build_snapshot_staging_table": {"unique_id": "macro.dbt_databricks.databricks_build_snapshot_staging_table", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "name": "databricks_build_snapshot_staging_table", "macro_sql": "{% macro databricks_build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_identifier = target_relation.identifier ~ '__dbt_tmp' %}\n\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                                  schema=target_relation.schema,\n                                                  database=none,\n                                                  type='view') -%}\n\n    {% set select = snapshot_staging_table(strategy, sql, target_relation) %}\n\n    {# needs to be a non-temp view so that its columns can be ascertained via `describe` #}\n    {% call statement('build_snapshot_staging_relation') %}\n        {{ create_view_as(tmp_relation, select) }}\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.snapshot_staging_table", "macro.dbt.statement", "macro.dbt.create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.064918}, "macro.dbt_databricks.materialization_snapshot_databricks": {"unique_id": "macro.dbt_databricks.materialization_snapshot_databricks", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "name": "materialization_snapshot_databricks", "macro_sql": "{% materialization snapshot, adapter='databricks' %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n  {%- set file_format = config.get('file_format', 'delta') -%}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=none,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if file_format not in ['delta', 'hudi'] -%}\n    {% set invalid_format_msg -%}\n      Invalid file format: {{ file_format }}\n      Snapshot functionality requires file_format be set to 'delta' or 'hudi'\n    {%- endset %}\n    {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n  {% endif %}\n\n  {%- if target_relation_exists -%}\n    {%- if not target_relation.is_delta and not target_relation.is_hudi -%}\n      {% set invalid_format_msg -%}\n        The existing table {{ model.schema }}.{{ target_table }} is in another format than 'delta' or 'hudi'\n      {%- endset %}\n      {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['compiled_sql']) %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = databricks_build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_or_create_relation", "macro.dbt.create_schema", "macro.dbt.run_hooks", "macro.dbt.strategy_dispatch", "macro.dbt.build_snapshot_table", "macro.dbt.create_table_as", "macro.dbt_databricks.databricks_build_snapshot_staging_table", "macro.dbt.create_columns", "macro.dbt.snapshot_merge_sql", "macro.dbt.statement", "macro.dbt.persist_docs", "macro.dbt.post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.072275}, "macro.dbt_databricks.dbt_databricks_validate_get_file_format": {"unique_id": "macro.dbt_databricks.dbt_databricks_validate_get_file_format", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "name": "dbt_databricks_validate_get_file_format", "macro_sql": "{% macro dbt_databricks_validate_get_file_format(raw_file_format) %}\n  {#-- Validate the file format #}\n\n  {% set accepted_formats = ['text', 'csv', 'json', 'jdbc', 'parquet', 'orc', 'hive', 'delta', 'libsvm', 'hudi'] %}\n\n  {% set invalid_file_format_msg -%}\n    Invalid file format provided: {{ raw_file_format }}\n    Expected one of: {{ accepted_formats | join(', ') }}\n  {%- endset %}\n\n  {% if raw_file_format not in accepted_formats %}\n    {% do exceptions.raise_compiler_error(invalid_file_format_msg) %}\n  {% endif %}\n\n  {% do return(raw_file_format) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.0747159}, "macro.dbt_databricks.dbt_databricks_validate_get_incremental_strategy": {"unique_id": "macro.dbt_databricks.dbt_databricks_validate_get_incremental_strategy", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "name": "dbt_databricks_validate_get_incremental_strategy", "macro_sql": "{% macro dbt_databricks_validate_get_incremental_strategy(raw_strategy, file_format) %}\n  {#-- Validate the incremental strategy #}\n\n  {% set invalid_strategy_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    Expected one of: 'append', 'merge', 'insert_overwrite'\n  {%- endset %}\n\n  {% set invalid_merge_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You can only choose this strategy when file_format is set to 'delta' or 'hudi'\n  {%- endset %}\n  \n  {% set invalid_insert_overwrite_delta_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You cannot use this strategy when file_format is set to 'delta'\n    Use the 'append' or 'merge' strategy instead\n  {%- endset %}\n  \n  {% set invalid_insert_overwrite_endpoint_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You cannot use this strategy when connecting via endpoint\n    Use the 'append' or 'merge' strategy instead\n  {%- endset %}\n\n  {% if raw_strategy not in ['append', 'merge', 'insert_overwrite'] %}\n    {% do exceptions.raise_compiler_error(invalid_strategy_msg) %}\n  {%-else %}\n    {% if raw_strategy == 'merge' and file_format not in ['delta', 'hudi'] %}\n      {% do exceptions.raise_compiler_error(invalid_merge_msg) %}\n    {% endif %}\n    {% if raw_strategy == 'insert_overwrite' and file_format == 'delta' %}\n      {% do exceptions.raise_compiler_error(invalid_insert_overwrite_delta_msg) %}\n    {% endif %}\n    {% if raw_strategy == 'insert_overwrite' and target.endpoint %}\n      {% do exceptions.raise_compiler_error(invalid_insert_overwrite_endpoint_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {% do return(raw_strategy) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.076857}, "macro.dbt_databricks.dbt_databricks_get_insert_overwrite_sql": {"unique_id": "macro.dbt_databricks.dbt_databricks_get_insert_overwrite_sql", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "name": "dbt_databricks_get_insert_overwrite_sql", "macro_sql": "{% macro dbt_databricks_get_insert_overwrite_sql(source_relation, target_relation) %}\n\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n    insert overwrite table {{ target_relation }}\n    {{ dbt_databricks_partition_cols(label=\"partition\") }}\n    select {{dest_cols_csv}} from {{ source_relation.include(database=false, schema=false) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_databricks.dbt_databricks_partition_cols"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.07855}, "macro.dbt_databricks.dbt_databricks_get_insert_into_sql": {"unique_id": "macro.dbt_databricks.dbt_databricks_get_insert_into_sql", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "name": "dbt_databricks_get_insert_into_sql", "macro_sql": "{% macro dbt_databricks_get_insert_into_sql(source_relation, target_relation) %}\n\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n    insert into table {{ target_relation }}\n    select {{dest_cols_csv}} from {{ source_relation.include(database=false, schema=false) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.0793128}, "macro.dbt_databricks.dbt_databricks_get_incremental_sql": {"unique_id": "macro.dbt_databricks.dbt_databricks_get_incremental_sql", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "name": "dbt_databricks_get_incremental_sql", "macro_sql": "{% macro dbt_databricks_get_incremental_sql(strategy, source, target, unique_key) %}\n  {%- if strategy == 'append' -%}\n    {#-- insert new records into existing table, without updating or overwriting #}\n    {{ dbt_databricks_get_insert_into_sql(source, target) }}\n  {%- elif strategy == 'insert_overwrite' -%}\n    {#-- insert statements don't like CTEs, so support them via a temp view #}\n    {{ dbt_databricks_get_insert_overwrite_sql(source, target) }}\n  {%- elif strategy == 'merge' -%}\n  {#-- merge all columns with databricks delta - schema changes are handled for us #}\n    {{ get_merge_sql(target, source, unique_key, dest_columns=none, predicates=none) }}\n  {%- else -%}\n    {% set no_sql_for_strategy_msg -%}\n      No known SQL for the incremental strategy provided: {{ strategy }}\n    {%- endset %}\n    {%- do exceptions.raise_compiler_error(no_sql_for_strategy_msg) -%}\n  {%- endif -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_databricks.dbt_databricks_get_insert_into_sql", "macro.dbt_databricks.dbt_databricks_get_insert_overwrite_sql", "macro.dbt.get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.08054}, "macro.dbt_databricks.materialization_incremental_databricks": {"unique_id": "macro.dbt_databricks.materialization_incremental_databricks", "package_name": "dbt_databricks", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/databricks", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "name": "materialization_incremental_databricks", "macro_sql": "{% materialization incremental, adapter='databricks' -%}\n  \n  {#-- Validate early so we don't run SQL if the file_format + strategy combo is invalid --#}\n  {%- set raw_file_format = config.get('file_format', default='delta') -%}\n  {%- set raw_strategy = config.get('incremental_strategy', default='merge') -%}\n  \n  {%- set file_format = dbt_spark_validate_get_file_format(raw_file_format) -%}\n  {%- set strategy = dbt_spark_validate_get_incremental_strategy(raw_strategy, file_format) -%}\n  \n  {%- set unique_key = config.get('unique_key', none) -%}\n  {%- set partition_by = config.get('partition_by', none) -%}\n\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n  \n  {% set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') %}\n\n  {% set target_relation = this %}\n  {% set existing_relation = load_relation(this) %}\n  {% set tmp_relation = make_temp_relation(this) %}\n\n  {% if strategy == 'insert_overwrite' and partition_by %}\n    {% call statement() %}\n      set spark.sql.sources.partitionOverwriteMode = DYNAMIC\n    {% endcall %}\n  {% endif %}\n\n  {{ run_hooks(pre_hooks) }}\n\n  {% if existing_relation is none %}\n    {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view or full_refresh_mode %}\n    {% do adapter.drop_relation(existing_relation) %}\n    {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% else %}\n    {% do run_query(create_table_as(True, tmp_relation, sql)) %}\n    {% do process_schema_changes(on_schema_change, tmp_relation, existing_relation) %}\n    {% set build_sql = dbt_databricks_get_incremental_sql(strategy, tmp_relation, target_relation, unique_key) %}\n  {% endif %}\n\n  {%- call statement('main') -%}\n    {{ build_sql }}\n  {%- endcall -%}\n\n  {% do persist_docs(target_relation, model) %}\n  \n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.dbt_spark_validate_get_file_format", "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy", "macro.dbt.should_full_refresh", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.load_relation", "macro.dbt.make_temp_relation", "macro.dbt.statement", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt.run_query", "macro.dbt.process_schema_changes", "macro.dbt_databricks.dbt_databricks_get_incremental_sql", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.085676}, "macro.dbt_spark.file_format_clause": {"unique_id": "macro.dbt_spark.file_format_clause", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "file_format_clause", "macro_sql": "{% macro file_format_clause() %}\n  {%- set file_format = config.get('file_format', validator=validation.any[basestring]) -%}\n  {%- if file_format is not none %}\n    using {{ file_format }}\n  {%- endif %}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1031098}, "macro.dbt_spark.location_clause": {"unique_id": "macro.dbt_spark.location_clause", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "location_clause", "macro_sql": "{% macro location_clause() %}\n  {%- set location_root = config.get('location_root', validator=validation.any[basestring]) -%}\n  {%- set identifier = model['alias'] -%}\n  {%- if location_root is not none %}\n    location '{{ location_root }}/{{ identifier }}'\n  {%- endif %}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.103795}, "macro.dbt_spark.options_clause": {"unique_id": "macro.dbt_spark.options_clause", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "options_clause", "macro_sql": "{% macro options_clause() -%}\n  {%- set options = config.get('options') -%}\n  {%- if config.get('file_format') == 'hudi' -%}\n    {%- set unique_key = config.get('unique_key') -%}\n    {%- if unique_key is not none and options is none -%}\n      {%- set options = {'primaryKey': config.get('unique_key')} -%}\n    {%- elif unique_key is not none and options is not none and 'primaryKey' not in options -%}\n      {%- set _ = options.update({'primaryKey': config.get('unique_key')}) -%}\n    {%- elif options is not none and 'primaryKey' in options and options['primaryKey'] != unique_key -%}\n      {{ exceptions.raise_compiler_error(\"unique_key and options('primaryKey') should be the same column(s).\") }}\n    {%- endif %}\n  {%- endif %}\n\n  {%- if options is not none %}\n    options (\n      {%- for option in options -%}\n      {{ option }} \"{{ options[option] }}\" {% if not loop.last %}, {% endif %}\n      {%- endfor %}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.105887}, "macro.dbt_spark.comment_clause": {"unique_id": "macro.dbt_spark.comment_clause", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "comment_clause", "macro_sql": "{% macro comment_clause() %}\n  {%- set raw_persist_docs = config.get('persist_docs', {}) -%}\n\n  {%- if raw_persist_docs is mapping -%}\n    {%- set raw_relation = raw_persist_docs.get('relation', false) -%}\n      {%- if raw_relation -%}\n      comment '{{ model.description | replace(\"'\", \"\\\\'\") }}'\n      {% endif %}\n  {%- elif raw_persist_docs -%}\n    {{ exceptions.raise_compiler_error(\"Invalid value provided for 'persist_docs'. Expected dict but got value: \" ~ raw_persist_docs) }}\n  {% endif %}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1068642}, "macro.dbt_spark.partition_cols": {"unique_id": "macro.dbt_spark.partition_cols", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "partition_cols", "macro_sql": "{% macro partition_cols(label, required=false) %}\n  {%- set cols = config.get('partition_by', validator=validation.any[list, basestring]) -%}\n  {%- if cols is not none %}\n    {%- if cols is string -%}\n      {%- set cols = [cols] -%}\n    {%- endif -%}\n    {{ label }} (\n    {%- for item in cols -%}\n      {{ item }}\n      {%- if not loop.last -%},{%- endif -%}\n    {%- endfor -%}\n    )\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.107916}, "macro.dbt_spark.clustered_cols": {"unique_id": "macro.dbt_spark.clustered_cols", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "clustered_cols", "macro_sql": "{% macro clustered_cols(label, required=false) %}\n  {%- set cols = config.get('clustered_by', validator=validation.any[list, basestring]) -%}\n  {%- set buckets = config.get('buckets', validator=validation.any[int]) -%}\n  {%- if (cols is not none) and (buckets is not none) %}\n    {%- if cols is string -%}\n      {%- set cols = [cols] -%}\n    {%- endif -%}\n    {{ label }} (\n    {%- for item in cols -%}\n      {{ item }}\n      {%- if not loop.last -%},{%- endif -%}\n    {%- endfor -%}\n    ) into {{ buckets }} buckets\n  {%- endif %}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.109322}, "macro.dbt_spark.fetch_tbl_properties": {"unique_id": "macro.dbt_spark.fetch_tbl_properties", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "fetch_tbl_properties", "macro_sql": "{% macro fetch_tbl_properties(relation) -%}\n  {% call statement('list_properties', fetch_result=True) -%}\n    SHOW TBLPROPERTIES {{ relation }}\n  {% endcall %}\n  {% do return(load_result('list_properties').table) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1098518}, "macro.dbt_spark.create_temporary_view": {"unique_id": "macro.dbt_spark.create_temporary_view", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "create_temporary_view", "macro_sql": "{% macro create_temporary_view(relation, sql) -%}\n  create temporary view {{ relation.include(schema=false) }} as\n    {{ sql }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.110204}, "macro.dbt_spark.spark__create_table_as": {"unique_id": "macro.dbt_spark.spark__create_table_as", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__create_table_as", "macro_sql": "{% macro spark__create_table_as(temporary, relation, sql) -%}\n  {% if temporary -%}\n    {{ create_temporary_view(relation, sql) }}\n  {%- else -%}\n    {% if config.get('file_format', validator=validation.any[basestring]) == 'delta' %}\n      create or replace table {{ relation }}\n    {% else %}\n      create table {{ relation }}\n    {% endif %}\n    {{ file_format_clause() }}\n    {{ options_clause() }}\n    {{ partition_cols(label=\"partitioned by\") }}\n    {{ clustered_cols(label=\"clustered by\") }}\n    {{ location_clause() }}\n    {{ comment_clause() }}\n    as\n      {{ sql }}\n  {%- endif %}\n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.create_temporary_view", "macro.dbt_spark.file_format_clause", "macro.dbt_spark.options_clause", "macro.dbt_spark.partition_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_spark.location_clause", "macro.dbt_spark.comment_clause"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.111955}, "macro.dbt_spark.spark__create_view_as": {"unique_id": "macro.dbt_spark.spark__create_view_as", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__create_view_as", "macro_sql": "{% macro spark__create_view_as(relation, sql) -%}\n  create or replace view {{ relation }}\n  {{ comment_clause() }}\n  as\n    {{ sql }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.comment_clause"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.112323}, "macro.dbt_spark.spark__create_schema": {"unique_id": "macro.dbt_spark.spark__create_schema", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__create_schema", "macro_sql": "{% macro spark__create_schema(relation) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{relation}}\n  {% endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.112664}, "macro.dbt_spark.spark__drop_schema": {"unique_id": "macro.dbt_spark.spark__drop_schema", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__drop_schema", "macro_sql": "{% macro spark__drop_schema(relation) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ relation }} cascade\n  {%- endcall -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1129978}, "macro.dbt_spark.spark__get_columns_in_relation": {"unique_id": "macro.dbt_spark.spark__get_columns_in_relation", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__get_columns_in_relation", "macro_sql": "{% macro spark__get_columns_in_relation(relation) -%}\n  {% call statement('get_columns_in_relation', fetch_result=True) %}\n      describe extended {{ relation.include(schema=(schema is not none)) }}\n  {% endcall %}\n  {% do return(load_result('get_columns_in_relation').table) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.113653}, "macro.dbt_spark.spark__list_relations_without_caching": {"unique_id": "macro.dbt_spark.spark__list_relations_without_caching", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__list_relations_without_caching", "macro_sql": "{% macro spark__list_relations_without_caching(relation) %}\n  {% call statement('list_relations_without_caching', fetch_result=True) -%}\n    show table extended in {{ relation }} like '*'\n  {% endcall %}\n\n  {% do return(load_result('list_relations_without_caching').table) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.114214}, "macro.dbt_spark.spark__list_schemas": {"unique_id": "macro.dbt_spark.spark__list_schemas", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__list_schemas", "macro_sql": "{% macro spark__list_schemas(database) -%}\n  {% call statement('list_schemas', fetch_result=True, auto_begin=False) %}\n    show databases\n  {% endcall %}\n  {{ return(load_result('list_schemas').table) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.114739}, "macro.dbt_spark.spark__current_timestamp": {"unique_id": "macro.dbt_spark.spark__current_timestamp", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__current_timestamp", "macro_sql": "{% macro spark__current_timestamp() -%}\n  current_timestamp()\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.114903}, "macro.dbt_spark.spark__rename_relation": {"unique_id": "macro.dbt_spark.spark__rename_relation", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__rename_relation", "macro_sql": "{% macro spark__rename_relation(from_relation, to_relation) -%}\n  {% call statement('rename_relation') -%}\n    {% if not from_relation.type %}\n      {% do exceptions.raise_database_error(\"Cannot rename a relation with a blank type: \" ~ from_relation.identifier) %}\n    {% elif from_relation.type in ('table') %}\n        alter table {{ from_relation }} rename to {{ to_relation }}\n    {% elif from_relation.type == 'view' %}\n        alter view {{ from_relation }} rename to {{ to_relation }}\n    {% else %}\n      {% do exceptions.raise_database_error(\"Unknown type '\" ~ from_relation.type ~ \"' for relation: \" ~ from_relation.identifier) %}\n    {% endif %}\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1161091}, "macro.dbt_spark.spark__drop_relation": {"unique_id": "macro.dbt_spark.spark__drop_relation", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__drop_relation", "macro_sql": "{% macro spark__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }}\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.116558}, "macro.dbt_spark.spark__generate_database_name": {"unique_id": "macro.dbt_spark.spark__generate_database_name", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__generate_database_name", "macro_sql": "{% macro spark__generate_database_name(custom_database_name=none, node=none) -%}\n  {% do return(None) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.116877}, "macro.dbt_spark.spark__persist_docs": {"unique_id": "macro.dbt_spark.spark__persist_docs", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__persist_docs", "macro_sql": "{% macro spark__persist_docs(relation, model, for_relation, for_columns) -%}\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {% do alter_column_comment(relation, model.columns) %}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.117435}, "macro.dbt_spark.spark__alter_column_comment": {"unique_id": "macro.dbt_spark.spark__alter_column_comment", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__alter_column_comment", "macro_sql": "{% macro spark__alter_column_comment(relation, column_dict) %}\n  {% if config.get('file_format', validator=validation.any[basestring]) in ['delta', 'hudi'] %}\n    {% for column_name in column_dict %}\n      {% set comment = column_dict[column_name]['description'] %}\n      {% set escaped_comment = comment | replace('\\'', '\\\\\\'') %}\n      {% set comment_query %}\n        alter table {{ relation }} change column \n            {{ adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name }}\n            comment '{{ escaped_comment }}';\n      {% endset %}\n      {% do run_query(comment_query) %}\n    {% endfor %}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1189}, "macro.dbt_spark.spark__make_temp_relation": {"unique_id": "macro.dbt_spark.spark__make_temp_relation", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__make_temp_relation", "macro_sql": "{% macro spark__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(path = {\n        \"identifier\": tmp_identifier,\n        \"schema\": None\n    }) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.119585}, "macro.dbt_spark.spark__alter_column_type": {"unique_id": "macro.dbt_spark.spark__alter_column_type", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__alter_column_type", "macro_sql": "{% macro spark__alter_column_type(relation, column_name, new_column_type) -%}\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} alter column {{ column_name }} type {{ new_column_type }};\n  {% endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.12005}, "macro.dbt_spark.spark__alter_relation_add_remove_columns": {"unique_id": "macro.dbt_spark.spark__alter_relation_add_remove_columns", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/adapters.sql", "original_file_path": "macros/adapters.sql", "name": "spark__alter_relation_add_remove_columns", "macro_sql": "{% macro spark__alter_relation_add_remove_columns(relation, add_columns, remove_columns) %}\n  \n  {% if remove_columns %}\n    {% set platform_name = 'Delta Lake' if relation.is_delta else 'Apache Spark' %}\n    {{ exceptions.raise_compiler_error(platform_name + ' does not support dropping columns from tables') }}\n  {% endif %}\n  \n  {% if add_columns is none %}\n    {% set add_columns = [] %}\n  {% endif %}\n  \n  {% set sql -%}\n     \n     alter {{ relation.type }} {{ relation }}\n       \n       {% if add_columns %} add columns {% endif %}\n            {% for column in add_columns %}\n               {{ column.name }} {{ column.data_type }}{{ ',' if not loop.last }}\n            {% endfor %}\n  \n  {%- endset -%}\n\n  {% do run_query(sql) %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.121526}, "macro.dbt_spark.spark__get_binding_char": {"unique_id": "macro.dbt_spark.spark__get_binding_char", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "name": "spark__get_binding_char", "macro_sql": "{% macro spark__get_binding_char() %}\n  {{ return('?' if target.method == 'odbc' else '%s') }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.124317}, "macro.dbt_spark.spark__reset_csv_table": {"unique_id": "macro.dbt_spark.spark__reset_csv_table", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "name": "spark__reset_csv_table", "macro_sql": "{% macro spark__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% if old_relation %}\n        {{ adapter.drop_relation(old_relation) }}\n    {% endif %}\n    {% set sql = create_csv_table(model, agate_table) %}\n    {{ return(sql) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1249752}, "macro.dbt_spark.spark__load_csv_rows": {"unique_id": "macro.dbt_spark.spark__load_csv_rows", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "name": "spark__load_csv_rows", "macro_sql": "{% macro spark__load_csv_rows(model, agate_table) %}\n\n  {% set batch_size = get_batch_size() %}\n  {% set column_override = model['config'].get('column_types', {}) %}\n\n  {% set statements = [] %}\n\n  {% for chunk in agate_table.rows | batch(batch_size) %}\n      {% set bindings = [] %}\n\n      {% for row in chunk %}\n          {% do bindings.extend(row) %}\n      {% endfor %}\n\n      {% set sql %}\n          insert into {{ this.render() }} values\n          {% for row in chunk -%}\n              ({%- for col_name in agate_table.column_names -%}\n                  {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n                  {%- set type = column_override.get(col_name, inferred_type) -%}\n                    cast({{ get_binding_char() }} as {{type}})\n                  {%- if not loop.last%},{%- endif %}\n              {%- endfor -%})\n              {%- if not loop.last%},{%- endif %}\n          {%- endfor %}\n      {% endset %}\n\n      {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n      {% if loop.index0 == 0 %}\n          {% do statements.append(sql) %}\n      {% endif %}\n  {% endfor %}\n\n  {# Return SQL so we can render it out into the compiled files #}\n  {{ return(statements[0]) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_batch_size", "macro.dbt.get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1277921}, "macro.dbt_spark.spark__create_csv_table": {"unique_id": "macro.dbt_spark.spark__create_csv_table", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/seed.sql", "original_file_path": "macros/materializations/seed.sql", "name": "spark__create_csv_table", "macro_sql": "{% macro spark__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n    {{ file_format_clause() }}\n    {{ partition_cols(label=\"partitioned by\") }}\n    {{ clustered_cols(label=\"clustered by\") }}\n    {{ location_clause() }}\n    {{ comment_clause() }}\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.file_format_clause", "macro.dbt_spark.partition_cols", "macro.dbt_spark.clustered_cols", "macro.dbt_spark.location_clause", "macro.dbt_spark.comment_clause", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.130058}, "macro.dbt_spark.materialization_view_spark": {"unique_id": "macro.dbt_spark.materialization_view_spark", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/view.sql", "original_file_path": "macros/materializations/view.sql", "name": "materialization_view_spark", "macro_sql": "{% materialization view, adapter='spark' -%}\n    {{ return(create_or_replace_view()) }}\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.create_or_replace_view"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.130568}, "macro.dbt_spark.materialization_table_spark": {"unique_id": "macro.dbt_spark.materialization_table_spark", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/table.sql", "original_file_path": "macros/materializations/table.sql", "name": "materialization_table_spark", "macro_sql": "{% materialization table, adapter = 'spark' %}\n\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n\n  {{ run_hooks(pre_hooks) }}\n\n  -- setup: if the target relation already exists, drop it\n  -- in case if the existing and future table is delta, we want to do a\n  -- create or replace table instead of dropping, so we don't have the table unavailable\n  {% if old_relation and not (old_relation.is_delta and config.get('file_format', validator=validation.any[basestring]) == 'delta') -%}\n    {{ adapter.drop_relation(old_relation) }}\n  {%- endif %}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_table_as(False, target_relation, sql) }}\n  {%- endcall %}\n  \n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]})}}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.create_table_as", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.133125}, "macro.dbt_spark.spark__snapshot_hash_arguments": {"unique_id": "macro.dbt_spark.spark__snapshot_hash_arguments", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "name": "spark__snapshot_hash_arguments", "macro_sql": "{% macro spark__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as string ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.144626}, "macro.dbt_spark.spark__snapshot_string_as_time": {"unique_id": "macro.dbt_spark.spark__snapshot_string_as_time", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "name": "spark__snapshot_string_as_time", "macro_sql": "{% macro spark__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"to_timestamp('\" ~ timestamp ~ \"')\" -%}\n    {{ return(result) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.144989}, "macro.dbt_spark.spark__snapshot_merge_sql": {"unique_id": "macro.dbt_spark.spark__snapshot_merge_sql", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "name": "spark__snapshot_merge_sql", "macro_sql": "{% macro spark__snapshot_merge_sql(target, source, insert_cols) -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id\n    when matched\n     and DBT_INTERNAL_DEST.dbt_valid_to is null\n     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')\n        then update\n        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert *\n    ;\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.145312}, "macro.dbt_spark.spark_build_snapshot_staging_table": {"unique_id": "macro.dbt_spark.spark_build_snapshot_staging_table", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "name": "spark_build_snapshot_staging_table", "macro_sql": "{% macro spark_build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_identifier = target_relation.identifier ~ '__dbt_tmp' %}\n                                \n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                                  schema=target_relation.schema,\n                                                  database=none,\n                                                  type='view') -%}\n\n    {% set select = snapshot_staging_table(strategy, sql, target_relation) %}\n\n    {# needs to be a non-temp view so that its columns can be ascertained via `describe` #}\n    {% call statement('build_snapshot_staging_relation') %}\n        {{ create_view_as(tmp_relation, select) }}\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.snapshot_staging_table", "macro.dbt.statement", "macro.dbt.create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.146421}, "macro.dbt_spark.spark__post_snapshot": {"unique_id": "macro.dbt_spark.spark__post_snapshot", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "name": "spark__post_snapshot", "macro_sql": "{% macro spark__post_snapshot(staging_relation) %}\n    {% do adapter.drop_relation(staging_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.146712}, "macro.dbt_spark.spark__create_columns": {"unique_id": "macro.dbt_spark.spark__create_columns", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "name": "spark__create_columns", "macro_sql": "{% macro spark__create_columns(relation, columns) %}\n    {% if columns|length > 0 %}\n    {% call statement() %}\n      alter table {{ relation }} add columns (\n        {% for column in columns %}\n          `{{ column.name }}` {{ column.data_type }} {{- ',' if not loop.last -}}\n        {% endfor %}\n      );\n    {% endcall %}\n    {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.147501}, "macro.dbt_spark.materialization_snapshot_spark": {"unique_id": "macro.dbt_spark.materialization_snapshot_spark", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/snapshot.sql", "original_file_path": "macros/materializations/snapshot.sql", "name": "materialization_snapshot_spark", "macro_sql": "{% materialization snapshot, adapter='spark' %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n  {%- set file_format = config.get('file_format', 'parquet') -%}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=none,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if file_format not in ['delta', 'hudi'] -%}\n    {% set invalid_format_msg -%}\n      Invalid file format: {{ file_format }}\n      Snapshot functionality requires file_format be set to 'delta' or 'hudi'\n    {%- endset %}\n    {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n  {% endif %}\n\n  {%- if target_relation_exists -%}\n    {%- if not target_relation.is_delta and not target_relation.is_hudi -%}\n      {% set invalid_format_msg -%}\n        The existing table {{ model.schema }}.{{ target_table }} is in another format than 'delta' or 'hudi'\n      {%- endset %}\n      {% do exceptions.raise_compiler_error(invalid_format_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['compiled_sql']) %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = spark_build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_or_create_relation", "macro.dbt.create_schema", "macro.dbt.run_hooks", "macro.dbt.strategy_dispatch", "macro.dbt.build_snapshot_table", "macro.dbt.create_table_as", "macro.dbt_spark.spark_build_snapshot_staging_table", "macro.dbt.create_columns", "macro.dbt.snapshot_merge_sql", "macro.dbt.statement", "macro.dbt.persist_docs", "macro.dbt.post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.154869}, "macro.dbt_spark.dbt_spark_validate_get_file_format": {"unique_id": "macro.dbt_spark.dbt_spark_validate_get_file_format", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "name": "dbt_spark_validate_get_file_format", "macro_sql": "{% macro dbt_spark_validate_get_file_format(raw_file_format) %}\n  {#-- Validate the file format #}\n\n  {% set accepted_formats = ['text', 'csv', 'json', 'jdbc', 'parquet', 'orc', 'hive', 'delta', 'libsvm', 'hudi'] %}\n\n  {% set invalid_file_format_msg -%}\n    Invalid file format provided: {{ raw_file_format }}\n    Expected one of: {{ accepted_formats | join(', ') }}\n  {%- endset %}\n\n  {% if raw_file_format not in accepted_formats %}\n    {% do exceptions.raise_compiler_error(invalid_file_format_msg) %}\n  {% endif %}\n\n  {% do return(raw_file_format) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.157454}, "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy": {"unique_id": "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/incremental/validate.sql", "original_file_path": "macros/materializations/incremental/validate.sql", "name": "dbt_spark_validate_get_incremental_strategy", "macro_sql": "{% macro dbt_spark_validate_get_incremental_strategy(raw_strategy, file_format) %}\n  {#-- Validate the incremental strategy #}\n\n  {% set invalid_strategy_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    Expected one of: 'append', 'merge', 'insert_overwrite'\n  {%- endset %}\n\n  {% set invalid_merge_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You can only choose this strategy when file_format is set to 'delta' or 'hudi'\n  {%- endset %}\n  \n  {% set invalid_insert_overwrite_delta_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You cannot use this strategy when file_format is set to 'delta'\n    Use the 'append' or 'merge' strategy instead\n  {%- endset %}\n  \n  {% set invalid_insert_overwrite_endpoint_msg -%}\n    Invalid incremental strategy provided: {{ raw_strategy }}\n    You cannot use this strategy when connecting via endpoint\n    Use the 'append' or 'merge' strategy instead\n  {%- endset %}\n\n  {% if raw_strategy not in ['append', 'merge', 'insert_overwrite'] %}\n    {% do exceptions.raise_compiler_error(invalid_strategy_msg) %}\n  {%-else %}\n    {% if raw_strategy == 'merge' and file_format not in ['delta', 'hudi'] %}\n      {% do exceptions.raise_compiler_error(invalid_merge_msg) %}\n    {% endif %}\n    {% if raw_strategy == 'insert_overwrite' and file_format == 'delta' %}\n      {% do exceptions.raise_compiler_error(invalid_insert_overwrite_delta_msg) %}\n    {% endif %}\n    {% if raw_strategy == 'insert_overwrite' and target.endpoint %}\n      {% do exceptions.raise_compiler_error(invalid_insert_overwrite_endpoint_msg) %}\n    {% endif %}\n  {% endif %}\n\n  {% do return(raw_strategy) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.159522}, "macro.dbt_spark.get_insert_overwrite_sql": {"unique_id": "macro.dbt_spark.get_insert_overwrite_sql", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "name": "get_insert_overwrite_sql", "macro_sql": "{% macro get_insert_overwrite_sql(source_relation, target_relation) %}\n    \n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n    insert overwrite table {{ target_relation }}\n    {{ partition_cols(label=\"partition\") }}\n    select {{dest_cols_csv}} from {{ source_relation.include(database=false, schema=false) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.partition_cols"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.161737}, "macro.dbt_spark.get_insert_into_sql": {"unique_id": "macro.dbt_spark.get_insert_into_sql", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "name": "get_insert_into_sql", "macro_sql": "{% macro get_insert_into_sql(source_relation, target_relation) %}\n\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n    insert into table {{ target_relation }}\n    select {{dest_cols_csv}} from {{ source_relation.include(database=false, schema=false) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.162473}, "macro.dbt_spark.spark__get_merge_sql": {"unique_id": "macro.dbt_spark.spark__get_merge_sql", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "name": "spark__get_merge_sql", "macro_sql": "{% macro spark__get_merge_sql(target, source, unique_key, dest_columns, predicates=none) %}\n  {# skip dest_columns, use merge_update_columns config if provided, otherwise use \"*\" #}\n  {%- set update_columns = config.get(\"merge_update_columns\") -%}\n  \n  {% set merge_condition %}\n    {% if unique_key %}\n        on DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n    {% else %}\n        on false\n    {% endif %}\n  {% endset %}\n  \n    merge into {{ target }} as DBT_INTERNAL_DEST\n      using {{ source.include(schema=false) }} as DBT_INTERNAL_SOURCE\n      \n      {{ merge_condition }}\n      \n      when matched then update set\n        {% if update_columns -%}{%- for column_name in update_columns %}\n            {{ column_name }} = DBT_INTERNAL_SOURCE.{{ column_name }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n        {%- else %} * {% endif %}\n    \n      when not matched then insert *\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.163779}, "macro.dbt_spark.dbt_spark_get_incremental_sql": {"unique_id": "macro.dbt_spark.dbt_spark_get_incremental_sql", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/incremental/strategies.sql", "original_file_path": "macros/materializations/incremental/strategies.sql", "name": "dbt_spark_get_incremental_sql", "macro_sql": "{% macro dbt_spark_get_incremental_sql(strategy, source, target, unique_key) %}\n  {%- if strategy == 'append' -%}\n    {#-- insert new records into existing table, without updating or overwriting #}\n    {{ get_insert_into_sql(source, target) }}\n  {%- elif strategy == 'insert_overwrite' -%}\n    {#-- insert statements don't like CTEs, so support them via a temp view #}\n    {{ get_insert_overwrite_sql(source, target) }}\n  {%- elif strategy == 'merge' -%}\n  {#-- merge all columns with databricks delta - schema changes are handled for us #}\n    {{ get_merge_sql(target, source, unique_key, dest_columns=none, predicates=none) }}\n  {%- else -%}\n    {% set no_sql_for_strategy_msg -%}\n      No known SQL for the incremental strategy provided: {{ strategy }}\n    {%- endset %}\n    {%- do exceptions.raise_compiler_error(no_sql_for_strategy_msg) -%}\n  {%- endif -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.get_insert_into_sql", "macro.dbt_spark.get_insert_overwrite_sql", "macro.dbt.get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.164968}, "macro.dbt_spark.materialization_incremental_spark": {"unique_id": "macro.dbt_spark.materialization_incremental_spark", "package_name": "dbt_spark", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/spark", "path": "macros/materializations/incremental/incremental.sql", "original_file_path": "macros/materializations/incremental/incremental.sql", "name": "materialization_incremental_spark", "macro_sql": "{% materialization incremental, adapter='spark' -%}\n  \n  {#-- Validate early so we don't run SQL if the file_format + strategy combo is invalid --#}\n  {%- set raw_file_format = config.get('file_format', default='parquet') -%}\n  {%- set raw_strategy = config.get('incremental_strategy', default='append') -%}\n  \n  {%- set file_format = dbt_spark_validate_get_file_format(raw_file_format) -%}\n  {%- set strategy = dbt_spark_validate_get_incremental_strategy(raw_strategy, file_format) -%}\n  \n  {%- set unique_key = config.get('unique_key', none) -%}\n  {%- set partition_by = config.get('partition_by', none) -%}\n\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n  \n  {% set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') %}\n\n  {% set target_relation = this %}\n  {% set existing_relation = load_relation(this) %}\n  {% set tmp_relation = make_temp_relation(this) %}\n\n  {% if strategy == 'insert_overwrite' and partition_by %}\n    {% call statement() %}\n      set spark.sql.sources.partitionOverwriteMode = DYNAMIC\n    {% endcall %}\n  {% endif %}\n\n  {{ run_hooks(pre_hooks) }}\n\n  {% if existing_relation is none %}\n    {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view or full_refresh_mode %}\n    {% do adapter.drop_relation(existing_relation) %}\n    {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% else %}\n    {% do run_query(create_table_as(True, tmp_relation, sql)) %}\n    {% do process_schema_changes(on_schema_change, tmp_relation, existing_relation) %}\n    {% set build_sql = dbt_spark_get_incremental_sql(strategy, tmp_relation, target_relation, unique_key) %}\n  {% endif %}\n\n  {%- call statement('main') -%}\n    {{ build_sql }}\n  {%- endcall -%}\n\n  {% do persist_docs(target_relation, model) %}\n  \n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.dbt_spark_validate_get_file_format", "macro.dbt_spark.dbt_spark_validate_get_incremental_strategy", "macro.dbt.should_full_refresh", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.load_relation", "macro.dbt.make_temp_relation", "macro.dbt.statement", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt.run_query", "macro.dbt.process_schema_changes", "macro.dbt_spark.dbt_spark_get_incremental_sql", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.169908}, "macro.dbt.run_hooks": {"unique_id": "macro.dbt.run_hooks", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "name": "run_hooks", "macro_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.171964}, "macro.dbt.make_hook_config": {"unique_id": "macro.dbt.make_hook_config", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "name": "make_hook_config", "macro_sql": "{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.172351}, "macro.dbt.before_begin": {"unique_id": "macro.dbt.before_begin", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "name": "before_begin", "macro_sql": "{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1726441}, "macro.dbt.in_transaction": {"unique_id": "macro.dbt.in_transaction", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "name": "in_transaction", "macro_sql": "{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1729321}, "macro.dbt.after_commit": {"unique_id": "macro.dbt.after_commit", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/hooks.sql", "original_file_path": "macros/materializations/hooks.sql", "name": "after_commit", "macro_sql": "{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.make_hook_config"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1732202}, "macro.dbt.set_sql_header": {"unique_id": "macro.dbt.set_sql_header", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "name": "set_sql_header", "macro_sql": "{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.174144}, "macro.dbt.should_full_refresh": {"unique_id": "macro.dbt.should_full_refresh", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "name": "should_full_refresh", "macro_sql": "{% macro should_full_refresh() %}\n  {% set config_full_refresh = config.get('full_refresh') %}\n  {% if config_full_refresh is none %}\n    {% set config_full_refresh = flags.FULL_REFRESH %}\n  {% endif %}\n  {% do return(config_full_refresh) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.174751}, "macro.dbt.should_store_failures": {"unique_id": "macro.dbt.should_store_failures", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/configs.sql", "original_file_path": "macros/materializations/configs.sql", "name": "should_store_failures", "macro_sql": "{% macro should_store_failures() %}\n  {% set config_store_failures = config.get('store_failures') %}\n  {% if config_store_failures is none %}\n    {% set config_store_failures = flags.STORE_FAILURES %}\n  {% endif %}\n  {% do return(config_store_failures) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.175359}, "macro.dbt.snapshot_merge_sql": {"unique_id": "macro.dbt.snapshot_merge_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshots/snapshot_merge.sql", "name": "snapshot_merge_sql", "macro_sql": "{% macro snapshot_merge_sql(target, source, insert_cols) -%}\n  {{ adapter.dispatch('snapshot_merge_sql', 'dbt')(target, source, insert_cols) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__snapshot_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.176662}, "macro.dbt.default__snapshot_merge_sql": {"unique_id": "macro.dbt.default__snapshot_merge_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/snapshot_merge.sql", "original_file_path": "macros/materializations/snapshots/snapshot_merge.sql", "name": "default__snapshot_merge_sql", "macro_sql": "{% macro default__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id\n\n    when matched\n     and DBT_INTERNAL_DEST.dbt_valid_to is null\n     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')\n        then update\n        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert ({{ insert_cols_csv }})\n        values ({{ insert_cols_csv }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.177193}, "macro.dbt.strategy_dispatch": {"unique_id": "macro.dbt.strategy_dispatch", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "strategy_dispatch", "macro_sql": "{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.18299}, "macro.dbt.snapshot_hash_arguments": {"unique_id": "macro.dbt.snapshot_hash_arguments", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "snapshot_hash_arguments", "macro_sql": "{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter.dispatch('snapshot_hash_arguments', 'dbt')(args) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.183328}, "macro.dbt.default__snapshot_hash_arguments": {"unique_id": "macro.dbt.default__snapshot_hash_arguments", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "default__snapshot_hash_arguments", "macro_sql": "{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.183778}, "macro.dbt.snapshot_get_time": {"unique_id": "macro.dbt.snapshot_get_time", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "snapshot_get_time", "macro_sql": "{% macro snapshot_get_time() -%}\n  {{ adapter.dispatch('snapshot_get_time', 'dbt')() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__snapshot_get_time"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.184065}, "macro.dbt.default__snapshot_get_time": {"unique_id": "macro.dbt.default__snapshot_get_time", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "default__snapshot_get_time", "macro_sql": "{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.184268}, "macro.dbt.snapshot_timestamp_strategy": {"unique_id": "macro.dbt.snapshot_timestamp_strategy", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "snapshot_timestamp_strategy", "macro_sql": "{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n    {% set invalidate_hard_deletes = config.get('invalidate_hard_deletes', false) %}\n\n    {#/*\n        The snapshot relation might not have an {{ updated_at }} value if the\n        snapshot strategy is changed from `check` to `timestamp`. We\n        should use a dbt-created column for the comparison in the snapshot\n        table instead of assuming that the user-supplied {{ updated_at }}\n        will be present in the historical data.\n\n        See https://github.com/dbt-labs/dbt-core/issues/2350\n    */ #}\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.dbt_valid_from < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr,\n        \"invalidate_hard_deletes\": invalidate_hard_deletes\n    }) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1856692}, "macro.dbt.snapshot_string_as_time": {"unique_id": "macro.dbt.snapshot_string_as_time", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "snapshot_string_as_time", "macro_sql": "{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter.dispatch('snapshot_string_as_time', 'dbt')(timestamp) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__snapshot_string_as_time"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.186006}, "macro.dbt.default__snapshot_string_as_time": {"unique_id": "macro.dbt.default__snapshot_string_as_time", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "default__snapshot_string_as_time", "macro_sql": "{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.186351}, "macro.dbt.snapshot_check_all_get_existing_columns": {"unique_id": "macro.dbt.snapshot_check_all_get_existing_columns", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "snapshot_check_all_get_existing_columns", "macro_sql": "{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['compiled_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_columns_in_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.188266}, "macro.dbt.snapshot_check_strategy": {"unique_id": "macro.dbt.snapshot_check_strategy", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/strategies.sql", "original_file_path": "macros/materializations/snapshots/strategies.sql", "name": "snapshot_check_strategy", "macro_sql": "{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set invalidate_hard_deletes = config.get('invalidate_hard_deletes', false) %}\n    \n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {#-- don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = config.get('updated_at', snapshot_string_as_time(now)) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        (\n            (({{ snapshotted_rel }}.{{ col }} is null) and not ({{ current_rel }}.{{ col }} is null))\n            or\n            ((not {{ snapshotted_rel }}.{{ col }} is null) and ({{ current_rel }}.{{ col }} is null))\n        )\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr,\n        \"invalidate_hard_deletes\": invalidate_hard_deletes\n    }) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.snapshot_get_time", "macro.dbt.run_query", "macro.dbt.snapshot_string_as_time", "macro.dbt.snapshot_check_all_get_existing_columns", "macro.dbt.snapshot_hash_arguments"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.191943}, "macro.dbt.create_columns": {"unique_id": "macro.dbt.create_columns", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "create_columns", "macro_sql": "{% macro create_columns(relation, columns) %}\n  {{ adapter.dispatch('create_columns', 'dbt')(relation, columns) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__create_columns"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.196835}, "macro.dbt.default__create_columns": {"unique_id": "macro.dbt.default__create_columns", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "default__create_columns", "macro_sql": "{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1974049}, "macro.dbt.post_snapshot": {"unique_id": "macro.dbt.post_snapshot", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "post_snapshot", "macro_sql": "{% macro post_snapshot(staging_relation) %}\n  {{ adapter.dispatch('post_snapshot', 'dbt')(staging_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.197742}, "macro.dbt.default__post_snapshot": {"unique_id": "macro.dbt.default__post_snapshot", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "default__post_snapshot", "macro_sql": "{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1979258}, "macro.dbt.snapshot_staging_table": {"unique_id": "macro.dbt.snapshot_staging_table", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "snapshot_staging_table", "macro_sql": "{% macro snapshot_staging_table(strategy, source_sql, target_relation) -%}\n  {{ adapter.dispatch('snapshot_staging_table', 'dbt')(strategy, source_sql, target_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__snapshot_staging_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.1983309}, "macro.dbt.default__snapshot_staging_table": {"unique_id": "macro.dbt.default__snapshot_staging_table", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "default__snapshot_staging_table", "macro_sql": "{% macro default__snapshot_staging_table(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n        where dbt_valid_to is null\n\n    ),\n\n    insertions_source_data as (\n\n        select\n            *,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to,\n            {{ strategy.scd_id }} as dbt_scd_id\n\n        from snapshot_query\n    ),\n\n    updates_source_data as (\n\n        select\n            *,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            {{ strategy.updated_at }} as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    {%- if strategy.invalidate_hard_deletes %}\n\n    deletes_source_data as (\n\n        select \n            *,\n            {{ strategy.unique_key }} as dbt_unique_key\n        from snapshot_query\n    ),\n    {% endif %}\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from insertions_source_data as source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            source_data.*,\n            snapshotted_data.dbt_scd_id\n\n        from updates_source_data as source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where (\n            {{ strategy.row_changed }}\n        )\n    )\n\n    {%- if strategy.invalidate_hard_deletes -%}\n    ,\n\n    deletes as (\n    \n        select\n            'delete' as dbt_change_type,\n            source_data.*,\n            {{ snapshot_get_time() }} as dbt_valid_from,\n            {{ snapshot_get_time() }} as dbt_updated_at,\n            {{ snapshot_get_time() }} as dbt_valid_to,\n            snapshotted_data.dbt_scd_id\n    \n        from snapshotted_data\n        left join deletes_source_data as source_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where source_data.dbt_unique_key is null\n    )\n    {%- endif %}\n\n    select * from insertions\n    union all\n    select * from updates\n    {%- if strategy.invalidate_hard_deletes %}\n    union all\n    select * from deletes\n    {%- endif %}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.snapshot_get_time"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.199997}, "macro.dbt.build_snapshot_table": {"unique_id": "macro.dbt.build_snapshot_table", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "build_snapshot_table", "macro_sql": "{% macro build_snapshot_table(strategy, sql) -%}\n  {{ adapter.dispatch('build_snapshot_table', 'dbt')(strategy, sql) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__build_snapshot_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.2003782}, "macro.dbt.default__build_snapshot_table": {"unique_id": "macro.dbt.default__build_snapshot_table", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "default__build_snapshot_table", "macro_sql": "{% macro default__build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.2008882}, "macro.dbt.build_snapshot_staging_table": {"unique_id": "macro.dbt.build_snapshot_staging_table", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/helpers.sql", "original_file_path": "macros/materializations/snapshots/helpers.sql", "name": "build_snapshot_staging_table", "macro_sql": "{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set select = snapshot_staging_table(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation') %}\n        {{ create_table_as(True, tmp_relation, select) }}\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.make_temp_relation", "macro.dbt.snapshot_staging_table", "macro.dbt.statement", "macro.dbt.create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.20174}, "macro.dbt.materialization_snapshot_default": {"unique_id": "macro.dbt.materialization_snapshot_default", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/snapshots/snapshot.sql", "original_file_path": "macros/materializations/snapshots/snapshot.sql", "name": "materialization_snapshot_default", "macro_sql": "{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['compiled_sql']) %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% if not target_relation_exists %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.create_schema", "macro.dbt.get_or_create_relation", "macro.dbt.run_hooks", "macro.dbt.strategy_dispatch", "macro.dbt.build_snapshot_table", "macro.dbt.create_table_as", "macro.dbt.build_snapshot_staging_table", "macro.dbt.create_columns", "macro.dbt.snapshot_merge_sql", "macro.dbt.statement", "macro.dbt.persist_docs", "macro.dbt.create_indexes", "macro.dbt.post_snapshot"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.212039}, "macro.dbt.materialization_test_default": {"unique_id": "macro.dbt.materialization_test_default", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/tests/test.sql", "original_file_path": "macros/materializations/tests/test.sql", "name": "materialization_test_default", "macro_sql": "{%- materialization test, default -%}\n\n  {% set relations = [] %}\n\n  {% if should_store_failures() %}\n\n    {% set identifier = model['alias'] %}\n    {% set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n    {% set target_relation = api.Relation.create(\n        identifier=identifier, schema=schema, database=database, type='table') -%} %}\n    \n    {% if old_relation %}\n        {% do adapter.drop_relation(old_relation) %}\n    {% endif %}\n    \n    {% call statement(auto_begin=True) %}\n        {{ create_table_as(False, target_relation, sql) }}\n    {% endcall %}\n    \n    {% do relations.append(target_relation) %}\n  \n    {% set main_sql %}\n        select *\n        from {{ target_relation }}\n    {% endset %}\n    \n    {{ adapter.commit() }}\n  \n  {% else %}\n\n      {% set main_sql = sql %}\n  \n  {% endif %}\n\n  {% set limit = config.get('limit') %}\n  {% set fail_calc = config.get('fail_calc') %}\n  {% set warn_if = config.get('warn_if') %}\n  {% set error_if = config.get('error_if') %}\n\n  {% call statement('main', fetch_result=True) -%}\n\n    {{ get_test_sql(main_sql, fail_calc, warn_if, error_if, limit)}}\n\n  {%- endcall %}\n  \n  {{ return({'relations': relations}) }}\n\n{%- endmaterialization -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.should_store_failures", "macro.dbt.statement", "macro.dbt.create_table_as", "macro.dbt.get_test_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.2159302}, "macro.dbt.get_test_sql": {"unique_id": "macro.dbt.get_test_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "name": "get_test_sql", "macro_sql": "{% macro get_test_sql(main_sql, fail_calc, warn_if, error_if, limit) -%}\n  {{ adapter.dispatch('get_test_sql', 'dbt')(main_sql, fail_calc, warn_if, error_if, limit) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_test_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.216852}, "macro.dbt.default__get_test_sql": {"unique_id": "macro.dbt.default__get_test_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/tests/helpers.sql", "original_file_path": "macros/materializations/tests/helpers.sql", "name": "default__get_test_sql", "macro_sql": "{% macro default__get_test_sql(main_sql, fail_calc, warn_if, error_if, limit) -%}\n    select\n      {{ fail_calc }} as failures,\n      {{ fail_calc }} {{ warn_if }} as should_warn,\n      {{ fail_calc }} {{ error_if }} as should_error\n    from (\n      {{ main_sql }}\n      {{ \"limit \" ~ limit if limit != none }}\n    ) dbt_internal_test\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.2174652}, "macro.dbt.get_where_subquery": {"unique_id": "macro.dbt.get_where_subquery", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/tests/where_subquery.sql", "original_file_path": "macros/materializations/tests/where_subquery.sql", "name": "get_where_subquery", "macro_sql": "{% macro get_where_subquery(relation) -%}\n    {% do return(adapter.dispatch('get_where_subquery', 'dbt')(relation)) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_where_subquery"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.218299}, "macro.dbt.default__get_where_subquery": {"unique_id": "macro.dbt.default__get_where_subquery", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/tests/where_subquery.sql", "original_file_path": "macros/materializations/tests/where_subquery.sql", "name": "default__get_where_subquery", "macro_sql": "{% macro default__get_where_subquery(relation) -%}\n    {% set where = config.get('where', '') %}\n    {% if where %}\n        {%- set filtered -%}\n            (select * from {{ relation }} where {{ where }}) dbt_subquery\n        {%- endset -%}\n        {% do return(filtered) %}\n    {%- else -%}\n        {% do return(relation) %}\n    {%- endif -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.2190568}, "macro.dbt.get_quoted_csv": {"unique_id": "macro.dbt.get_quoted_csv", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "name": "get_quoted_csv", "macro_sql": "{% macro get_quoted_csv(column_names) %}\n    \n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.220587}, "macro.dbt.diff_columns": {"unique_id": "macro.dbt.diff_columns", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "name": "diff_columns", "macro_sql": "{% macro diff_columns(source_columns, target_columns) %}\n\n  {% set result = [] %}\n  {% set source_names = source_columns | map(attribute = 'column') | list %}\n  {% set target_names = target_columns | map(attribute = 'column') | list %}\n   \n   {# --check whether the name attribute exists in the target - this does not perform a data type check #}\n   {% for sc in source_columns %}\n     {% if sc.name not in target_names %}\n        {{ result.append(sc) }}\n     {% endif %}\n   {% endfor %}\n  \n  {{ return(result) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.221667}, "macro.dbt.diff_column_data_types": {"unique_id": "macro.dbt.diff_column_data_types", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/column_helpers.sql", "original_file_path": "macros/materializations/models/incremental/column_helpers.sql", "name": "diff_column_data_types", "macro_sql": "{% macro diff_column_data_types(source_columns, target_columns) %}\n  \n  {% set result = [] %}\n  {% for sc in source_columns %}\n    {% set tc = target_columns | selectattr(\"name\", \"equalto\", sc.name) | list | first %}\n    {% if tc %}\n      {% if sc.data_type != tc.data_type %}\n        {{ result.append( { 'column_name': tc.name, 'new_type': sc.data_type } ) }} \n      {% endif %}\n    {% endif %}\n  {% endfor %}\n\n  {{ return(result) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.2228632}, "macro.dbt.get_merge_sql": {"unique_id": "macro.dbt.get_merge_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "name": "get_merge_sql", "macro_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter.dispatch('get_merge_sql', 'dbt')(target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__get_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.227436}, "macro.dbt.default__get_merge_sql": {"unique_id": "macro.dbt.default__get_merge_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "name": "default__get_merge_sql", "macro_sql": "{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set update_columns = config.get('merge_update_columns', default = dest_columns | map(attribute=\"quoted\") | list) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    {{ sql_header if sql_header is not none }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column_name in update_columns -%}\n            {{ column_name }} = DBT_INTERNAL_SOURCE.{{ column_name }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.229694}, "macro.dbt.get_delete_insert_merge_sql": {"unique_id": "macro.dbt.get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "name": "get_delete_insert_merge_sql", "macro_sql": "{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter.dispatch('get_delete_insert_merge_sql', 'dbt')(target, source, unique_key, dest_columns) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_delete_insert_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.230161}, "macro.dbt.default__get_delete_insert_merge_sql": {"unique_id": "macro.dbt.default__get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "name": "default__get_delete_insert_merge_sql", "macro_sql": "{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    )\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.231005}, "macro.dbt.get_insert_overwrite_merge_sql": {"unique_id": "macro.dbt.get_insert_overwrite_merge_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "name": "get_insert_overwrite_merge_sql", "macro_sql": "{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header=false) -%}\n  {{ adapter.dispatch('get_insert_overwrite_merge_sql', 'dbt')(target, source, dest_columns, predicates, include_sql_header) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_insert_overwrite_merge_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.231565}, "macro.dbt.default__get_insert_overwrite_merge_sql": {"unique_id": "macro.dbt.default__get_insert_overwrite_merge_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/merge.sql", "original_file_path": "macros/materializations/models/incremental/merge.sql", "name": "default__get_insert_overwrite_merge_sql", "macro_sql": "{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {{ sql_header if sql_header is not none and include_sql_header }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n\n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_quoted_csv"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.232803}, "macro.dbt.is_incremental": {"unique_id": "macro.dbt.is_incremental", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/is_incremental.sql", "original_file_path": "macros/materializations/models/incremental/is_incremental.sql", "name": "is_incremental", "macro_sql": "{% macro is_incremental() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n        {{ return(relation is not none\n                  and relation.type == 'table'\n                  and model.config.materialized == 'incremental'\n                  and not should_full_refresh()) }}\n    {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.should_full_refresh"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.234103}, "macro.dbt.materialization_incremental_default": {"unique_id": "macro.dbt.materialization_incremental_default", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/incremental.sql", "original_file_path": "macros/materializations/models/incremental/incremental.sql", "name": "materialization_incremental_default", "macro_sql": "{% materialization incremental, default -%}\n\n  {% set unique_key = config.get('unique_key') %}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {% set existing_relation = load_relation(this) %}\n  {% set tmp_relation = make_temp_relation(target_relation) %}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {% set on_schema_change = incremental_validate_on_schema_change(config.get('on_schema_change'), default='ignore') %}\n\n  {% set tmp_identifier = model['name'] + '__dbt_tmp' %}\n  {% set backup_identifier = model['name'] + \"__dbt_backup\" %}\n\n  -- the intermediate_ and backup_ relations should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation. This has to happen before\n  -- BEGIN, in a separate transaction\n  {% set preexisting_intermediate_relation = adapter.get_relation(identifier=tmp_identifier, \n                                                                  schema=schema,\n                                                                  database=database) %}                                               \n  {% set preexisting_backup_relation = adapter.get_relation(identifier=backup_identifier,\n                                                            schema=schema,\n                                                            database=database) %}\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set to_drop = [] %}\n\n  {# -- first check whether we want to full refresh for source view or config reasons #}\n  {% set trigger_full_refresh = (full_refresh_mode or existing_relation.is_view) %}\n\n  {% if existing_relation is none %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n{% elif trigger_full_refresh %}\n      {#-- Make sure the backup doesn't exist so we don't encounter issues with the rename below #}\n      {% set tmp_identifier = model['name'] + '__dbt_tmp' %}\n      {% set backup_identifier = model['name'] + '__dbt_backup' %}\n      {% set intermediate_relation = existing_relation.incorporate(path={\"identifier\": tmp_identifier}) %}\n      {% set backup_relation = existing_relation.incorporate(path={\"identifier\": backup_identifier}) %}\n\n      {% set build_sql = create_table_as(False, intermediate_relation, sql) %}\n      {% set need_swap = true %}\n      {% do to_drop.append(backup_relation) %}\n  {% else %}\n    {% do run_query(create_table_as(True, tmp_relation, sql)) %}\n    {% do adapter.expand_target_column_types(\n             from_relation=tmp_relation,\n             to_relation=target_relation) %}\n    {#-- Process schema changes. Returns dict of changes if successful. Use source columns for upserting/merging --#}\n    {% set dest_columns = process_schema_changes(on_schema_change, tmp_relation, existing_relation) %}\n    {% if not dest_columns %}\n      {% set dest_columns = adapter.get_columns_in_relation(existing_relation) %}\n    {% endif %}\n    {% set build_sql = get_delete_insert_merge_sql(target_relation, tmp_relation, unique_key, dest_columns) %}\n  \n  {% endif %}\n\n  {% call statement(\"main\") %}\n      {{ build_sql }}\n  {% endcall %}\n\n  {% if need_swap %} \n      {% do adapter.rename_relation(target_relation, backup_relation) %} \n      {% do adapter.rename_relation(intermediate_relation, target_relation) %} \n  {% endif %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% if existing_relation is none or existing_relation.is_view or should_full_refresh() %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {% do adapter.commit() %}\n\n  {% for rel in to_drop %}\n      {% do adapter.drop_relation(rel) %}\n  {% endfor %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.load_relation", "macro.dbt.make_temp_relation", "macro.dbt.should_full_refresh", "macro.dbt.incremental_validate_on_schema_change", "macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt.run_query", "macro.dbt.process_schema_changes", "macro.dbt.get_delete_insert_merge_sql", "macro.dbt.statement", "macro.dbt.persist_docs", "macro.dbt.create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.243101}, "macro.dbt.incremental_validate_on_schema_change": {"unique_id": "macro.dbt.incremental_validate_on_schema_change", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "name": "incremental_validate_on_schema_change", "macro_sql": "{% macro incremental_validate_on_schema_change(on_schema_change, default='ignore') %}\n   \n   {% if on_schema_change not in ['sync_all_columns', 'append_new_columns', 'fail', 'ignore'] %}\n     \n     {% set log_message = 'Invalid value for on_schema_change (%s) specified. Setting default value of %s.' % (on_schema_change, default) %}\n     {% do log(log_message) %}\n     \n     {{ return(default) }}\n\n   {% else %}\n\n     {{ return(on_schema_change) }}\n   \n   {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.250626}, "macro.dbt.check_for_schema_changes": {"unique_id": "macro.dbt.check_for_schema_changes", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "name": "check_for_schema_changes", "macro_sql": "{% macro check_for_schema_changes(source_relation, target_relation) %}\n  \n  {% set schema_changed = False %}\n  \n  {%- set source_columns = adapter.get_columns_in_relation(source_relation) -%}\n  {%- set target_columns = adapter.get_columns_in_relation(target_relation) -%}\n  {%- set source_not_in_target = diff_columns(source_columns, target_columns) -%}\n  {%- set target_not_in_source = diff_columns(target_columns, source_columns) -%}\n\n  {% set new_target_types = diff_column_data_types(source_columns, target_columns) %}\n\n  {% if source_not_in_target != [] %}\n    {% set schema_changed = True %}\n  {% elif target_not_in_source != [] or new_target_types != [] %}\n    {% set schema_changed = True %}\n  {% elif new_target_types != [] %}\n    {% set schema_changed = True %}\n  {% endif %}\n  \n  {% set changes_dict = {\n    'schema_changed': schema_changed,\n    'source_not_in_target': source_not_in_target,\n    'target_not_in_source': target_not_in_source,\n    'source_columns': source_columns,\n    'target_columns': target_columns,\n    'new_target_types': new_target_types\n  } %}\n\n  {% set msg %}\n    In {{ target_relation }}:\n        Schema changed: {{ schema_changed }}\n        Source columns not in target: {{ source_not_in_target }}\n        Target columns not in source: {{ target_not_in_source }}\n        New column types: {{ new_target_types }}\n  {% endset %}\n  \n  {% do log(msg) %}\n\n  {{ return(changes_dict) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.diff_columns", "macro.dbt.diff_column_data_types"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.253004}, "macro.dbt.sync_column_schemas": {"unique_id": "macro.dbt.sync_column_schemas", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "name": "sync_column_schemas", "macro_sql": "{% macro sync_column_schemas(on_schema_change, target_relation, schema_changes_dict) %}\n  \n  {%- set add_to_target_arr = schema_changes_dict['source_not_in_target'] -%}\n\n  {%- if on_schema_change == 'append_new_columns'-%}\n     {%- if add_to_target_arr | length > 0 -%}\n       {%- do alter_relation_add_remove_columns(target_relation, add_to_target_arr, none) -%}\n     {%- endif -%}\n  \n  {% elif on_schema_change == 'sync_all_columns' %}\n     {%- set remove_from_target_arr = schema_changes_dict['target_not_in_source'] -%}\n     {%- set new_target_types = schema_changes_dict['new_target_types'] -%}\n  \n     {% if add_to_target_arr | length > 0 or remove_from_target_arr | length > 0 %} \n       {%- do alter_relation_add_remove_columns(target_relation, add_to_target_arr, remove_from_target_arr) -%}\n     {% endif %}\n\n     {% if new_target_types != [] %}\n       {% for ntt in new_target_types %}\n         {% set column_name = ntt['column_name'] %}\n         {% set new_type = ntt['new_type'] %}\n         {% do alter_column_type(target_relation, column_name, new_type) %}\n       {% endfor %}\n     {% endif %}\n  \n  {% endif %}\n\n  {% set schema_change_message %}\n    In {{ target_relation }}:\n        Schema change approach: {{ on_schema_change }}\n        Columns added: {{ add_to_target_arr }}\n        Columns removed: {{ remove_from_target_arr }}\n        Data types changed: {{ new_target_types }}\n  {% endset %}\n  \n  {% do log(schema_change_message) %}\n  \n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.alter_relation_add_remove_columns", "macro.dbt.alter_column_type"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.255426}, "macro.dbt.process_schema_changes": {"unique_id": "macro.dbt.process_schema_changes", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/incremental/on_schema_change.sql", "original_file_path": "macros/materializations/models/incremental/on_schema_change.sql", "name": "process_schema_changes", "macro_sql": "{% macro process_schema_changes(on_schema_change, source_relation, target_relation) %}\n    \n    {% if on_schema_change == 'ignore' %}\n\n     {{ return({}) }}\n\n    {% else %}\n    \n      {% set schema_changes_dict = check_for_schema_changes(source_relation, target_relation) %}\n      \n      {% if schema_changes_dict['schema_changed'] %}\n    \n        {% if on_schema_change == 'fail' %}\n        \n          {% set fail_msg %}\n              The source and target schemas on this incremental model are out of sync!\n              They can be reconciled in several ways: \n                - set the `on_schema_change` config to either append_new_columns or sync_all_columns, depending on your situation.\n                - Re-run the incremental model with `full_refresh: True` to update the target schema.\n                - update the schema manually and re-run the process.\n          {% endset %}\n          \n          {% do exceptions.raise_compiler_error(fail_msg) %}\n        \n        {# -- unless we ignore, run the sync operation per the config #}\n        {% else %}\n          \n          {% do sync_column_schemas(on_schema_change, target_relation, schema_changes_dict) %}\n        \n        {% endif %}\n      \n      {% endif %}\n\n      {{ return(schema_changes_dict['source_columns']) }}\n    \n    {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.check_for_schema_changes", "macro.dbt.sync_column_schemas"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.256845}, "macro.dbt.materialization_table_default": {"unique_id": "macro.dbt.materialization_table_default", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/table/table.sql", "original_file_path": "macros/materializations/models/table/table.sql", "name": "materialization_table_default", "macro_sql": "{% materialization table, default %}\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema,\n                                                      database=database,\n                                                      type='table') -%}\n  -- the intermediate_relation should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation\n  {%- set preexisting_intermediate_relation = adapter.get_relation(identifier=tmp_identifier, \n                                                                   schema=schema,\n                                                                   database=database) -%}\n  /*\n      See ../view/view.sql for more information about this relation.\n  */\n  {%- set backup_relation_type = 'table' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type=backup_relation_type) -%}\n  -- as above, the backup_relation should not already exist\n  {%- set preexisting_backup_relation = adapter.get_relation(identifier=backup_identifier,\n                                                             schema=schema,\n                                                             database=database) -%}\n\n\n  -- drop the temp relations if they exist already in the database\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ get_create_table_as_sql(False, intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  {% if old_relation is not none %}\n      {{ adapter.rename_relation(old_relation, backup_relation) }}\n  {% endif %}\n\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {% do create_indexes(target_relation) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {% do persist_docs(target_relation, model) %}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  -- finally, drop the existing/backup relation after the commit\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.drop_relation_if_exists", "macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.get_create_table_as_sql", "macro.dbt.create_indexes", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.263249}, "macro.dbt.get_create_table_as_sql": {"unique_id": "macro.dbt.get_create_table_as_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "name": "get_create_table_as_sql", "macro_sql": "{% macro get_create_table_as_sql(temporary, relation, sql) -%}\n  {{ adapter.dispatch('get_create_table_as_sql', 'dbt')(temporary, relation, sql) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_create_table_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.264145}, "macro.dbt.default__get_create_table_as_sql": {"unique_id": "macro.dbt.default__get_create_table_as_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "name": "default__get_create_table_as_sql", "macro_sql": "{% macro default__get_create_table_as_sql(temporary, relation, sql) -%}\n  {{ return(create_table_as(temporary, relation, sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.264516}, "macro.dbt.create_table_as": {"unique_id": "macro.dbt.create_table_as", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "name": "create_table_as", "macro_sql": "{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter.dispatch('create_table_as', 'dbt')(temporary, relation, sql) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_table_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.2649229}, "macro.dbt.default__create_table_as": {"unique_id": "macro.dbt.default__create_table_as", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/table/create_table_as.sql", "original_file_path": "macros/materializations/models/table/create_table_as.sql", "name": "default__create_table_as", "macro_sql": "{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n  \n  {{ sql_header if sql_header is not none }}\n  \n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.265732}, "macro.dbt.materialization_view_default": {"unique_id": "macro.dbt.materialization_view_default", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/view.sql", "original_file_path": "macros/materializations/models/view/view.sql", "name": "materialization_view_default", "macro_sql": "{%- materialization view, default -%}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, database=database,\n                                                type='view') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema, database=database, type='view') -%}\n  -- the intermediate_relation should not already exist in the database; get_relation\n  -- will return None in that case. Otherwise, we get a relation that we can drop\n  -- later, before we try to use this name for the current operation\n  {%- set preexisting_intermediate_relation = adapter.get_relation(identifier=tmp_identifier, \n                                                                   schema=schema,\n                                                                   database=database) -%}\n  /*\n     This relation (probably) doesn't exist yet. If it does exist, it's a leftover from\n     a previous run, and we're going to try to drop it immediately. At the end of this\n     materialization, we're going to rename the \"old_relation\" to this identifier,\n     and then we're going to drop it. In order to make sure we run the correct one of:\n       - drop view ...\n       - drop table ...\n\n     We need to set the type of this relation to be the type of the old_relation, if it exists,\n     or else \"view\" as a sane default if it does not. Note that if the old_relation does not\n     exist, then there is nothing to move out of the way and subsequentally drop. In that case,\n     this relation will be effectively unused.\n  */\n  {%- set backup_relation_type = 'view' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema, database=database,\n                                                type=backup_relation_type) -%}\n  -- as above, the backup_relation should not already exist\n  {%- set preexisting_backup_relation = adapter.get_relation(identifier=backup_identifier,\n                                                             schema=schema,\n                                                             database=database) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- drop the temp relations if they exist already in the database\n  {{ drop_relation_if_exists(preexisting_intermediate_relation) }}\n  {{ drop_relation_if_exists(preexisting_backup_relation) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  -- move the existing view out of the way\n  {% if old_relation is not none %}\n    {{ adapter.rename_relation(old_relation, backup_relation) }}\n  {% endif %}\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.drop_relation_if_exists", "macro.dbt.statement", "macro.dbt.create_view_as", "macro.dbt.persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.2718809}, "macro.dbt.handle_existing_table": {"unique_id": "macro.dbt.handle_existing_table", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/helpers.sql", "original_file_path": "macros/materializations/models/view/helpers.sql", "name": "handle_existing_table", "macro_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.dispatch('handle_existing_table', 'dbt')(full_refresh, old_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__handle_existing_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.272584}, "macro.dbt.default__handle_existing_table": {"unique_id": "macro.dbt.default__handle_existing_table", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/helpers.sql", "original_file_path": "macros/materializations/models/view/helpers.sql", "name": "default__handle_existing_table", "macro_sql": "{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ log(\"Dropping relation \" ~ old_relation ~ \" because it is of type \" ~ old_relation.type) }}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.273023}, "macro.dbt.create_or_replace_view": {"unique_id": "macro.dbt.create_or_replace_view", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/create_or_replace_view.sql", "original_file_path": "macros/materializations/models/view/create_or_replace_view.sql", "name": "create_or_replace_view", "macro_sql": "{% macro create_or_replace_view() %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n\n  {{ run_hooks(pre_hooks) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(should_full_refresh(), old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ get_create_view_as_sql(target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.handle_existing_table", "macro.dbt.should_full_refresh", "macro.dbt.statement", "macro.dbt.get_create_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.27533}, "macro.dbt.get_create_view_as_sql": {"unique_id": "macro.dbt.get_create_view_as_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/create_view_as.sql", "original_file_path": "macros/materializations/models/view/create_view_as.sql", "name": "get_create_view_as_sql", "macro_sql": "{% macro get_create_view_as_sql(relation, sql) -%}\n  {{ adapter.dispatch('get_create_view_as_sql', 'dbt')(relation, sql) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_create_view_as_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.27612}, "macro.dbt.default__get_create_view_as_sql": {"unique_id": "macro.dbt.default__get_create_view_as_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/create_view_as.sql", "original_file_path": "macros/materializations/models/view/create_view_as.sql", "name": "default__get_create_view_as_sql", "macro_sql": "{% macro default__get_create_view_as_sql(relation, sql) -%}\n  {{ return(create_view_as(relation, sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.276452}, "macro.dbt.create_view_as": {"unique_id": "macro.dbt.create_view_as", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/create_view_as.sql", "original_file_path": "macros/materializations/models/view/create_view_as.sql", "name": "create_view_as", "macro_sql": "{% macro create_view_as(relation, sql) -%}\n  {{ adapter.dispatch('create_view_as', 'dbt')(relation, sql) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_view_as"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.276818}, "macro.dbt.default__create_view_as": {"unique_id": "macro.dbt.default__create_view_as", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/models/view/create_view_as.sql", "original_file_path": "macros/materializations/models/view/create_view_as.sql", "name": "default__create_view_as", "macro_sql": "{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.277338}, "macro.dbt.materialization_seed_default": {"unique_id": "macro.dbt.materialization_seed_default", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/seed.sql", "original_file_path": "macros/materializations/seeds/seed.sql", "name": "materialization_seed_default", "macro_sql": "{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', response='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set code = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set rows_affected = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', code ~ ' ' ~ rows_affected, code, rows_affected) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {% do persist_docs(target_relation, model) %}\n\n  {% if full_refresh_mode or not exists_as_table %}\n    {% do create_indexes(target_relation) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.run_hooks", "macro.dbt.reset_csv_table", "macro.dbt.create_csv_table", "macro.dbt.load_csv_rows", "macro.dbt.noop_statement", "macro.dbt.persist_docs", "macro.dbt.create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.2826161}, "macro.dbt.create_csv_table": {"unique_id": "macro.dbt.create_csv_table", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "create_csv_table", "macro_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter.dispatch('create_csv_table', 'dbt')(model, agate_table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_databricks.databricks__create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.2889879}, "macro.dbt.default__create_csv_table": {"unique_id": "macro.dbt.default__create_csv_table", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "default__create_csv_table", "macro_sql": "{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.29075}, "macro.dbt.reset_csv_table": {"unique_id": "macro.dbt.reset_csv_table", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "reset_csv_table", "macro_sql": "{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter.dispatch('reset_csv_table', 'dbt')(model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__reset_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.291208}, "macro.dbt.default__reset_csv_table": {"unique_id": "macro.dbt.default__reset_csv_table", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "default__reset_csv_table", "macro_sql": "{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.create_csv_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.292162}, "macro.dbt.get_binding_char": {"unique_id": "macro.dbt.get_binding_char", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "get_binding_char", "macro_sql": "{% macro get_binding_char() -%}\n  {{ adapter.dispatch('get_binding_char', 'dbt')() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_databricks.databricks__get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.292455}, "macro.dbt.default__get_binding_char": {"unique_id": "macro.dbt.default__get_binding_char", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "default__get_binding_char", "macro_sql": "{% macro default__get_binding_char() %}\n  {{ return('%s') }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.292696}, "macro.dbt.get_batch_size": {"unique_id": "macro.dbt.get_batch_size", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "get_batch_size", "macro_sql": "{% macro get_batch_size() -%}\n  {{ return(adapter.dispatch('get_batch_size', 'dbt')()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_batch_size"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.293024}, "macro.dbt.default__get_batch_size": {"unique_id": "macro.dbt.default__get_batch_size", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "default__get_batch_size", "macro_sql": "{% macro default__get_batch_size() %}\n  {{ return(10000) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.293264}, "macro.dbt.get_seed_column_quoted_csv": {"unique_id": "macro.dbt.get_seed_column_quoted_csv", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "get_seed_column_quoted_csv", "macro_sql": "{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.294227}, "macro.dbt.load_csv_rows": {"unique_id": "macro.dbt.load_csv_rows", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "load_csv_rows", "macro_sql": "{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter.dispatch('load_csv_rows', 'dbt')(model, agate_table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__load_csv_rows"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.294697}, "macro.dbt.default__load_csv_rows": {"unique_id": "macro.dbt.default__load_csv_rows", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/materializations/seeds/helpers.sql", "original_file_path": "macros/materializations/seeds/helpers.sql", "name": "default__load_csv_rows", "macro_sql": "{% macro default__load_csv_rows(model, agate_table) %}\n\n  {% set batch_size = get_batch_size() %}\n\n  {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n  {% set bindings = [] %}\n\n  {% set statements = [] %}\n\n  {% for chunk in agate_table.rows | batch(batch_size) %}\n      {% set bindings = [] %}\n\n      {% for row in chunk %}\n          {% do bindings.extend(row) %}\n      {% endfor %}\n\n      {% set sql %}\n          insert into {{ this.render() }} ({{ cols_sql }}) values\n          {% for row in chunk -%}\n              ({%- for column in agate_table.column_names -%}\n                  {{ get_binding_char() }}\n                  {%- if not loop.last%},{%- endif %}\n              {%- endfor -%})\n              {%- if not loop.last%},{%- endif %}\n          {%- endfor %}\n      {% endset %}\n\n      {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n      {% if loop.index0 == 0 %}\n          {% do statements.append(sql) %}\n      {% endif %}\n  {% endfor %}\n\n  {# Return SQL so we can render it out into the compiled files #}\n  {{ return(statements[0]) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_batch_size", "macro.dbt.get_seed_column_quoted_csv", "macro.dbt.get_binding_char"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.297088}, "macro.dbt.generate_alias_name": {"unique_id": "macro.dbt.generate_alias_name", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_alias.sql", "original_file_path": "macros/get_custom_name/get_custom_alias.sql", "name": "generate_alias_name", "macro_sql": "{% macro generate_alias_name(custom_alias_name=none, node=none) -%}\n    {% do return(adapter.dispatch('generate_alias_name', 'dbt')(custom_alias_name, node)) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__generate_alias_name"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.297924}, "macro.dbt.default__generate_alias_name": {"unique_id": "macro.dbt.default__generate_alias_name", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_alias.sql", "original_file_path": "macros/get_custom_name/get_custom_alias.sql", "name": "default__generate_alias_name", "macro_sql": "{% macro default__generate_alias_name(custom_alias_name=none, node=none) -%}\n\n    {%- if custom_alias_name is none -%}\n\n        {{ node.name }}\n\n    {%- else -%}\n\n        {{ custom_alias_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.298388}, "macro.dbt.generate_schema_name": {"unique_id": "macro.dbt.generate_schema_name", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "name": "generate_schema_name", "macro_sql": "{% macro generate_schema_name(custom_schema_name=none, node=none) -%}\n    {{ return(adapter.dispatch('generate_schema_name', 'dbt')(custom_schema_name, node)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__generate_schema_name"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.299414}, "macro.dbt.default__generate_schema_name": {"unique_id": "macro.dbt.default__generate_schema_name", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "name": "default__generate_schema_name", "macro_sql": "{% macro default__generate_schema_name(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n\n        {{ default_schema }}\n\n    {%- else -%}\n\n        {{ default_schema }}_{{ custom_schema_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.29994}, "macro.dbt.generate_schema_name_for_env": {"unique_id": "macro.dbt.generate_schema_name_for_env", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_schema.sql", "original_file_path": "macros/get_custom_name/get_custom_schema.sql", "name": "generate_schema_name_for_env", "macro_sql": "{% macro generate_schema_name_for_env(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if target.name == 'prod' and custom_schema_name is not none -%}\n\n        {{ custom_schema_name | trim }}\n\n    {%- else -%}\n\n        {{ default_schema }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.300716}, "macro.dbt.generate_database_name": {"unique_id": "macro.dbt.generate_database_name", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_database.sql", "original_file_path": "macros/get_custom_name/get_custom_database.sql", "name": "generate_database_name", "macro_sql": "{% macro generate_database_name(custom_database_name=none, node=none) -%}\n    {% do return(adapter.dispatch('generate_database_name', 'dbt')(custom_database_name, node)) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__generate_database_name"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.301568}, "macro.dbt.default__generate_database_name": {"unique_id": "macro.dbt.default__generate_database_name", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/get_custom_name/get_custom_database.sql", "original_file_path": "macros/get_custom_name/get_custom_database.sql", "name": "default__generate_database_name", "macro_sql": "{% macro default__generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n\n        {{ default_database }}\n\n    {%- else -%}\n\n        {{ custom_database_name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.302253}, "macro.dbt.default__test_relationships": {"unique_id": "macro.dbt.default__test_relationships", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/generic_test_sql/relationships.sql", "original_file_path": "macros/generic_test_sql/relationships.sql", "name": "default__test_relationships", "macro_sql": "{% macro default__test_relationships(model, column_name, to, field) %}\n\nwith child as (\n    select {{ column_name }} as from_field\n    from {{ model }}\n    where {{ column_name }} is not null\n),\n\nparent as (\n    select {{ field }} as to_field\n    from {{ to }}\n)\n\nselect\n    from_field\n\nfrom child\nleft join parent\n    on child.from_field = parent.to_field\n\nwhere parent.to_field is null\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.30303}, "macro.dbt.default__test_not_null": {"unique_id": "macro.dbt.default__test_not_null", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/generic_test_sql/not_null.sql", "original_file_path": "macros/generic_test_sql/not_null.sql", "name": "default__test_not_null", "macro_sql": "{% macro default__test_not_null(model, column_name) %}\n\nselect *\nfrom {{ model }}\nwhere {{ column_name }} is null\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.303523}, "macro.dbt.default__test_unique": {"unique_id": "macro.dbt.default__test_unique", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/generic_test_sql/unique.sql", "original_file_path": "macros/generic_test_sql/unique.sql", "name": "default__test_unique", "macro_sql": "{% macro default__test_unique(model, column_name) %}\n\nselect\n    {{ column_name }} as unique_field,\n    count(*) as n_records\n\nfrom {{ model }}\nwhere {{ column_name }} is not null\ngroup by {{ column_name }}\nhaving count(*) > 1\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.304139}, "macro.dbt.default__test_accepted_values": {"unique_id": "macro.dbt.default__test_accepted_values", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/generic_test_sql/accepted_values.sql", "original_file_path": "macros/generic_test_sql/accepted_values.sql", "name": "default__test_accepted_values", "macro_sql": "{% macro default__test_accepted_values(model, column_name, values, quote=True) %}\n\nwith all_values as (\n\n    select\n        {{ column_name }} as value_field,\n        count(*) as n_records\n\n    from {{ model }}\n    group by {{ column_name }}\n\n)\n\nselect *\nfrom all_values\nwhere value_field not in (\n    {% for value in values -%}\n        {% if quote -%}\n        '{{ value }}'\n        {%- else -%}\n        {{ value }}\n        {%- endif -%}\n        {%- if not loop.last -%},{%- endif %}\n    {%- endfor %}\n)\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.305446}, "macro.dbt.statement": {"unique_id": "macro.dbt.statement", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "name": "statement", "macro_sql": "{% macro statement(name=None, fetch_result=False, auto_begin=True) -%}\n  {%- if execute: -%}\n    {%- set sql = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n      {{ write(sql) }}\n    {%- endif -%}\n\n    {%- set res, table = adapter.execute(sql, auto_begin=auto_begin, fetch=fetch_result) -%}\n    {%- if name is not none -%}\n      {{ store_result(name, response=res, agate_table=table) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.307691}, "macro.dbt.noop_statement": {"unique_id": "macro.dbt.noop_statement", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "name": "noop_statement", "macro_sql": "{% macro noop_statement(name=None, message=None, code=None, rows_affected=None, res=None) -%}\n  {%- set sql = caller() -%}\n\n  {%- if name == 'main' -%}\n    {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n    {{ write(sql) }}\n  {%- endif -%}\n\n  {%- if name is not none -%}\n    {{ store_raw_result(name, message=message, code=code, rows_affected=rows_affected, agate_table=res) }}\n  {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.308825}, "macro.dbt.run_query": {"unique_id": "macro.dbt.run_query", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/etc/statement.sql", "original_file_path": "macros/etc/statement.sql", "name": "run_query", "macro_sql": "{% macro run_query(sql) %}\n  {% call statement(\"run_query_statement\", fetch_result=true, auto_begin=false) %}\n    {{ sql }}\n  {% endcall %}\n\n  {% do return(load_result(\"run_query_statement\").table) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3094132}, "macro.dbt.convert_datetime": {"unique_id": "macro.dbt.convert_datetime", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "name": "convert_datetime", "macro_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.312423}, "macro.dbt.dates_in_range": {"unique_id": "macro.dbt.dates_in_range", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "name": "dates_in_range", "macro_sql": "{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.convert_datetime"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.31506}, "macro.dbt.partition_range": {"unique_id": "macro.dbt.partition_range", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "name": "partition_range", "macro_sql": "{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.dates_in_range"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.316531}, "macro.dbt.py_current_timestring": {"unique_id": "macro.dbt.py_current_timestring", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/etc/datetime.sql", "original_file_path": "macros/etc/datetime.sql", "name": "py_current_timestring", "macro_sql": "{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.316994}, "macro.dbt.create_schema": {"unique_id": "macro.dbt.create_schema", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "name": "create_schema", "macro_sql": "{% macro create_schema(relation) -%}\n  {{ adapter.dispatch('create_schema', 'dbt')(relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__create_schema"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3178089}, "macro.dbt.default__create_schema": {"unique_id": "macro.dbt.default__create_schema", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "name": "default__create_schema", "macro_sql": "{% macro default__create_schema(relation) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ relation.without_identifier() }}\n  {% endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3181849}, "macro.dbt.drop_schema": {"unique_id": "macro.dbt.drop_schema", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "name": "drop_schema", "macro_sql": "{% macro drop_schema(relation) -%}\n  {{ adapter.dispatch('drop_schema', 'dbt')(relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__drop_schema"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3185139}, "macro.dbt.default__drop_schema": {"unique_id": "macro.dbt.default__drop_schema", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/schema.sql", "original_file_path": "macros/adapters/schema.sql", "name": "default__drop_schema", "macro_sql": "{% macro default__drop_schema(relation) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ relation.without_identifier() }} cascade\n  {% endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.31889}, "macro.dbt.get_create_index_sql": {"unique_id": "macro.dbt.get_create_index_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "name": "get_create_index_sql", "macro_sql": "{% macro get_create_index_sql(relation, index_dict) -%}\n  {{ return(adapter.dispatch('get_create_index_sql', 'dbt')(relation, index_dict)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_create_index_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.319828}, "macro.dbt.default__get_create_index_sql": {"unique_id": "macro.dbt.default__get_create_index_sql", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "name": "default__get_create_index_sql", "macro_sql": "{% macro default__get_create_index_sql(relation, index_dict) -%}\n  {% do return(None) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.320111}, "macro.dbt.create_indexes": {"unique_id": "macro.dbt.create_indexes", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "name": "create_indexes", "macro_sql": "{% macro create_indexes(relation) -%}\n  {{ adapter.dispatch('create_indexes', 'dbt')(relation) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__create_indexes"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3204322}, "macro.dbt.default__create_indexes": {"unique_id": "macro.dbt.default__create_indexes", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/indexes.sql", "original_file_path": "macros/adapters/indexes.sql", "name": "default__create_indexes", "macro_sql": "{% macro default__create_indexes(relation) -%}\n  {%- set _indexes = config.get('indexes', default=[]) -%}\n\n  {% for _index_dict in _indexes %}\n    {% set create_index_sql = get_create_index_sql(relation, _index_dict) %}\n    {% if create_index_sql %}\n      {% do run_query(create_index_sql) %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.get_create_index_sql", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.321215}, "macro.dbt.make_temp_relation": {"unique_id": "macro.dbt.make_temp_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "make_temp_relation", "macro_sql": "{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter.dispatch('make_temp_relation', 'dbt')(base_relation, suffix))}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__make_temp_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.323895}, "macro.dbt.default__make_temp_relation": {"unique_id": "macro.dbt.default__make_temp_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "default__make_temp_relation", "macro_sql": "{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3245}, "macro.dbt.drop_relation": {"unique_id": "macro.dbt.drop_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "drop_relation", "macro_sql": "{% macro drop_relation(relation) -%}\n  {{ return(adapter.dispatch('drop_relation', 'dbt')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__drop_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3248699}, "macro.dbt.default__drop_relation": {"unique_id": "macro.dbt.default__drop_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "default__drop_relation", "macro_sql": "{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.325303}, "macro.dbt.truncate_relation": {"unique_id": "macro.dbt.truncate_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "truncate_relation", "macro_sql": "{% macro truncate_relation(relation) -%}\n  {{ return(adapter.dispatch('truncate_relation', 'dbt')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__truncate_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.32567}, "macro.dbt.default__truncate_relation": {"unique_id": "macro.dbt.default__truncate_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "default__truncate_relation", "macro_sql": "{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.326004}, "macro.dbt.rename_relation": {"unique_id": "macro.dbt.rename_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "rename_relation", "macro_sql": "{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter.dispatch('rename_relation', 'dbt')(from_relation, to_relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__rename_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.326412}, "macro.dbt.default__rename_relation": {"unique_id": "macro.dbt.default__rename_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "default__rename_relation", "macro_sql": "{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.326978}, "macro.dbt.get_or_create_relation": {"unique_id": "macro.dbt.get_or_create_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "get_or_create_relation", "macro_sql": "{% macro get_or_create_relation(database, schema, identifier, type) -%}\n  {{ return(adapter.dispatch('get_or_create_relation', 'dbt')(database, schema, identifier, type)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_or_create_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3274722}, "macro.dbt.default__get_or_create_relation": {"unique_id": "macro.dbt.default__get_or_create_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "default__get_or_create_relation", "macro_sql": "{% macro default__get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.328662}, "macro.dbt.load_relation": {"unique_id": "macro.dbt.load_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "load_relation", "macro_sql": "{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3291168}, "macro.dbt.drop_relation_if_exists": {"unique_id": "macro.dbt.drop_relation_if_exists", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/relation.sql", "original_file_path": "macros/adapters/relation.sql", "name": "drop_relation_if_exists", "macro_sql": "{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.329549}, "macro.dbt.current_timestamp": {"unique_id": "macro.dbt.current_timestamp", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "name": "current_timestamp", "macro_sql": "{% macro current_timestamp() -%}\n  {{ adapter.dispatch('current_timestamp', 'dbt')() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3305259}, "macro.dbt.default__current_timestamp": {"unique_id": "macro.dbt.default__current_timestamp", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "name": "default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.330827}, "macro.dbt.collect_freshness": {"unique_id": "macro.dbt.collect_freshness", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "name": "collect_freshness", "macro_sql": "{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter.dispatch('collect_freshness', 'dbt')(source, loaded_at_field, filter))}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__collect_freshness"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3312829}, "macro.dbt.default__collect_freshness": {"unique_id": "macro.dbt.default__collect_freshness", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/freshness.sql", "original_file_path": "macros/adapters/freshness.sql", "name": "default__collect_freshness", "macro_sql": "{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement", "macro.dbtvault.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.332117}, "macro.dbt.alter_column_comment": {"unique_id": "macro.dbt.alter_column_comment", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "name": "alter_column_comment", "macro_sql": "{% macro alter_column_comment(relation, column_dict) -%}\n  {{ return(adapter.dispatch('alter_column_comment', 'dbt')(relation, column_dict)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_databricks.databricks__alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.333374}, "macro.dbt.default__alter_column_comment": {"unique_id": "macro.dbt.default__alter_column_comment", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "name": "default__alter_column_comment", "macro_sql": "{% macro default__alter_column_comment(relation, column_dict) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_column_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.333715}, "macro.dbt.alter_relation_comment": {"unique_id": "macro.dbt.alter_relation_comment", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "name": "alter_relation_comment", "macro_sql": "{% macro alter_relation_comment(relation, relation_comment) -%}\n  {{ return(adapter.dispatch('alter_relation_comment', 'dbt')(relation, relation_comment)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__alter_relation_comment"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.334125}, "macro.dbt.default__alter_relation_comment": {"unique_id": "macro.dbt.default__alter_relation_comment", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "name": "default__alter_relation_comment", "macro_sql": "{% macro default__alter_relation_comment(relation, relation_comment) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_relation_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.334461}, "macro.dbt.persist_docs": {"unique_id": "macro.dbt.persist_docs", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "name": "persist_docs", "macro_sql": "{% macro persist_docs(relation, model, for_relation=true, for_columns=true) -%}\n  {{ return(adapter.dispatch('persist_docs', 'dbt')(relation, model, for_relation, for_columns)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__persist_docs"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.335027}, "macro.dbt.default__persist_docs": {"unique_id": "macro.dbt.default__persist_docs", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/persist_docs.sql", "original_file_path": "macros/adapters/persist_docs.sql", "name": "default__persist_docs", "macro_sql": "{% macro default__persist_docs(relation, model, for_relation, for_columns) -%}\n  {% if for_relation and config.persist_relation_docs() and model.description %}\n    {% do run_query(alter_relation_comment(relation, model.description)) %}\n  {% endif %}\n\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {% do run_query(alter_column_comment(relation, model.columns)) %}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_query", "macro.dbt.alter_relation_comment", "macro.dbt.alter_column_comment"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.335972}, "macro.dbt.get_catalog": {"unique_id": "macro.dbt.get_catalog", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "get_catalog", "macro_sql": "{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter.dispatch('get_catalog', 'dbt')(information_schema, schemas)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_catalog"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.338455}, "macro.dbt.default__get_catalog": {"unique_id": "macro.dbt.default__get_catalog", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "default__get_catalog", "macro_sql": "{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.338985}, "macro.dbt.information_schema_name": {"unique_id": "macro.dbt.information_schema_name", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "information_schema_name", "macro_sql": "{% macro information_schema_name(database) %}\n  {{ return(adapter.dispatch('information_schema_name', 'dbt')(database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__information_schema_name"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3393621}, "macro.dbt.default__information_schema_name": {"unique_id": "macro.dbt.default__information_schema_name", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "default__information_schema_name", "macro_sql": "{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ database }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.339682}, "macro.dbt.list_schemas": {"unique_id": "macro.dbt.list_schemas", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "list_schemas", "macro_sql": "{% macro list_schemas(database) -%}\n  {{ return(adapter.dispatch('list_schemas', 'dbt')(database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__list_schemas"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.340043}, "macro.dbt.default__list_schemas": {"unique_id": "macro.dbt.default__list_schemas", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "default__list_schemas", "macro_sql": "{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.information_schema_name", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.340545}, "macro.dbt.check_schema_exists": {"unique_id": "macro.dbt.check_schema_exists", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "check_schema_exists", "macro_sql": "{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter.dispatch('check_schema_exists', 'dbt')(information_schema, schema)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__check_schema_exists"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.340957}, "macro.dbt.default__check_schema_exists": {"unique_id": "macro.dbt.default__check_schema_exists", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "default__check_schema_exists", "macro_sql": "{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.replace", "macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.341674}, "macro.dbt.list_relations_without_caching": {"unique_id": "macro.dbt.list_relations_without_caching", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "list_relations_without_caching", "macro_sql": "{% macro list_relations_without_caching(schema_relation) %}\n  {{ return(adapter.dispatch('list_relations_without_caching', 'dbt')(schema_relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__list_relations_without_caching"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.342054}, "macro.dbt.default__list_relations_without_caching": {"unique_id": "macro.dbt.default__list_relations_without_caching", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/metadata.sql", "original_file_path": "macros/adapters/metadata.sql", "name": "default__list_relations_without_caching", "macro_sql": "{% macro default__list_relations_without_caching(schema_relation) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3423822}, "macro.dbt.get_columns_in_relation": {"unique_id": "macro.dbt.get_columns_in_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "get_columns_in_relation", "macro_sql": "{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter.dispatch('get_columns_in_relation', 'dbt')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__get_columns_in_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.345147}, "macro.dbt.default__get_columns_in_relation": {"unique_id": "macro.dbt.default__get_columns_in_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "default__get_columns_in_relation", "macro_sql": "{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3454778}, "macro.dbt.sql_convert_columns_in_relation": {"unique_id": "macro.dbt.sql_convert_columns_in_relation", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "sql_convert_columns_in_relation", "macro_sql": "{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.346097}, "macro.dbt.get_columns_in_query": {"unique_id": "macro.dbt.get_columns_in_query", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "get_columns_in_query", "macro_sql": "{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter.dispatch('get_columns_in_query', 'dbt')(select_sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__get_columns_in_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3464692}, "macro.dbt.default__get_columns_in_query": {"unique_id": "macro.dbt.default__get_columns_in_query", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "default__get_columns_in_query", "macro_sql": "{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.347135}, "macro.dbt.alter_column_type": {"unique_id": "macro.dbt.alter_column_type", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "alter_column_type", "macro_sql": "{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter.dispatch('alter_column_type', 'dbt')(relation, column_name, new_column_type)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__alter_column_type"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.347593}, "macro.dbt.default__alter_column_type": {"unique_id": "macro.dbt.default__alter_column_type", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "default__alter_column_type", "macro_sql": "{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.348778}, "macro.dbt.alter_relation_add_remove_columns": {"unique_id": "macro.dbt.alter_relation_add_remove_columns", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "alter_relation_add_remove_columns", "macro_sql": "{% macro alter_relation_add_remove_columns(relation, add_columns = none, remove_columns = none) -%}\n  {{ return(adapter.dispatch('alter_relation_add_remove_columns', 'dbt')(relation, add_columns, remove_columns)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_spark.spark__alter_relation_add_remove_columns"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.349288}, "macro.dbt.default__alter_relation_add_remove_columns": {"unique_id": "macro.dbt.default__alter_relation_add_remove_columns", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "macros/adapters/columns.sql", "original_file_path": "macros/adapters/columns.sql", "name": "default__alter_relation_add_remove_columns", "macro_sql": "{% macro default__alter_relation_add_remove_columns(relation, add_columns, remove_columns) %}\n  \n  {% if add_columns is none %}\n    {% set add_columns = [] %}\n  {% endif %}\n  {% if remove_columns is none %}\n    {% set remove_columns = [] %}\n  {% endif %}\n  \n  {% set sql -%}\n     \n     alter {{ relation.type }} {{ relation }}\n       \n            {% for column in add_columns %}\n               add column {{ column.name }} {{ column.data_type }}{{ ',' if not loop.last }}\n            {% endfor %}{{ ',' if add_columns and remove_columns }}\n            \n            {% for column in remove_columns %}\n                drop column {{ column.name }}{{ ',' if not loop.last }}\n            {% endfor %}\n  \n  {%- endset -%}\n\n  {% do run_query(sql) %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.350828}, "macro.dbt.test_unique": {"unique_id": "macro.dbt.test_unique", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "name": "test_unique", "macro_sql": "{% test unique(model, column_name) %}\n    {% set macro = adapter.dispatch('test_unique', 'dbt') %}\n    {{ macro(model, column_name) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__test_unique"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.352031}, "macro.dbt.test_not_null": {"unique_id": "macro.dbt.test_not_null", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "name": "test_not_null", "macro_sql": "{% test not_null(model, column_name) %}\n    {% set macro = adapter.dispatch('test_not_null', 'dbt') %}\n    {{ macro(model, column_name) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__test_not_null"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3525}, "macro.dbt.test_accepted_values": {"unique_id": "macro.dbt.test_accepted_values", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "name": "test_accepted_values", "macro_sql": "{% test accepted_values(model, column_name, values, quote=True) %}\n    {% set macro = adapter.dispatch('test_accepted_values', 'dbt') %}\n    {{ macro(model, column_name, values, quote) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__test_accepted_values"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.353067}, "macro.dbt.test_relationships": {"unique_id": "macro.dbt.test_relationships", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "tests/generic/builtin.sql", "original_file_path": "tests/generic/builtin.sql", "name": "test_relationships", "macro_sql": "{% test relationships(model, column_name, to, field) %}\n    {% set macro = adapter.dispatch('test_relationships', 'dbt') %}\n    {{ macro(model, column_name, to, field) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__test_relationships"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.353651}, "macro.dbt_utils.except": {"unique_id": "macro.dbt_utils.except", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/except.sql", "original_file_path": "macros/cross_db_utils/except.sql", "name": "except", "macro_sql": "{% macro except() %}\n  {{ return(adapter.dispatch('except', 'dbt_utils')()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__except"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3542771}, "macro.dbt_utils.default__except": {"unique_id": "macro.dbt_utils.default__except", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/except.sql", "original_file_path": "macros/cross_db_utils/except.sql", "name": "default__except", "macro_sql": "{% macro default__except() %}\n\n    except\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.354439}, "macro.dbt_utils.bigquery__except": {"unique_id": "macro.dbt_utils.bigquery__except", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/except.sql", "original_file_path": "macros/cross_db_utils/except.sql", "name": "bigquery__except", "macro_sql": "{% macro bigquery__except() %}\n\n    except distinct\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.354591}, "macro.dbt_utils.replace": {"unique_id": "macro.dbt_utils.replace", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/replace.sql", "original_file_path": "macros/cross_db_utils/replace.sql", "name": "replace", "macro_sql": "{% macro replace(field, old_chars, new_chars) -%}\n    {{ return(adapter.dispatch('replace', 'dbt_utils') (field, old_chars, new_chars)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__replace"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3553438}, "macro.dbt_utils.default__replace": {"unique_id": "macro.dbt_utils.default__replace", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/replace.sql", "original_file_path": "macros/cross_db_utils/replace.sql", "name": "default__replace", "macro_sql": "{% macro default__replace(field, old_chars, new_chars) %}\n\n    replace(\n        {{ field }},\n        {{ old_chars }},\n        {{ new_chars }}\n    )\n    \n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.355676}, "macro.dbt_utils.concat": {"unique_id": "macro.dbt_utils.concat", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "name": "concat", "macro_sql": "{% macro concat(fields) -%}\n  {{ return(adapter.dispatch('concat', 'dbt_utils')(fields)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__concat"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.356291}, "macro.dbt_utils.default__concat": {"unique_id": "macro.dbt_utils.default__concat", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/concat.sql", "original_file_path": "macros/cross_db_utils/concat.sql", "name": "default__concat", "macro_sql": "{% macro default__concat(fields) -%}\n    {{ fields|join(' || ') }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3566568}, "macro.dbt_utils.type_string": {"unique_id": "macro.dbt_utils.type_string", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "type_string", "macro_sql": "\n\n{%- macro type_string() -%}\n  {{ return(adapter.dispatch('type_string', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.357904}, "macro.dbt_utils.default__type_string": {"unique_id": "macro.dbt_utils.default__type_string", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "default__type_string", "macro_sql": "{% macro default__type_string() %}\n    string\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3580601}, "macro.dbt_utils.redshift__type_string": {"unique_id": "macro.dbt_utils.redshift__type_string", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "redshift__type_string", "macro_sql": "\n\n{%- macro redshift__type_string() -%}\n    varchar\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3582132}, "macro.dbt_utils.postgres__type_string": {"unique_id": "macro.dbt_utils.postgres__type_string", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "postgres__type_string", "macro_sql": "{% macro postgres__type_string() %}\n    varchar\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.358363}, "macro.dbt_utils.snowflake__type_string": {"unique_id": "macro.dbt_utils.snowflake__type_string", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "snowflake__type_string", "macro_sql": "{% macro snowflake__type_string() %}\n    varchar\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3585122}, "macro.dbt_utils.type_timestamp": {"unique_id": "macro.dbt_utils.type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "type_timestamp", "macro_sql": "\n\n{%- macro type_timestamp() -%}\n  {{ return(adapter.dispatch('type_timestamp', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.35883}, "macro.dbt_utils.default__type_timestamp": {"unique_id": "macro.dbt_utils.default__type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "default__type_timestamp", "macro_sql": "{% macro default__type_timestamp() %}\n    timestamp\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.359072}, "macro.dbt_utils.postgres__type_timestamp": {"unique_id": "macro.dbt_utils.postgres__type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "postgres__type_timestamp", "macro_sql": "{% macro postgres__type_timestamp() %}\n    timestamp without time zone\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3592231}, "macro.dbt_utils.snowflake__type_timestamp": {"unique_id": "macro.dbt_utils.snowflake__type_timestamp", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "snowflake__type_timestamp", "macro_sql": "{% macro snowflake__type_timestamp() %}\n    timestamp_ntz\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.359373}, "macro.dbt_utils.type_float": {"unique_id": "macro.dbt_utils.type_float", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "type_float", "macro_sql": "\n\n{%- macro type_float() -%}\n  {{ return(adapter.dispatch('type_float', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__type_float"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.359691}, "macro.dbt_utils.default__type_float": {"unique_id": "macro.dbt_utils.default__type_float", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "default__type_float", "macro_sql": "{% macro default__type_float() %}\n    float\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3598468}, "macro.dbt_utils.bigquery__type_float": {"unique_id": "macro.dbt_utils.bigquery__type_float", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "bigquery__type_float", "macro_sql": "{% macro bigquery__type_float() %}\n    float64\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.359997}, "macro.dbt_utils.type_numeric": {"unique_id": "macro.dbt_utils.type_numeric", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "type_numeric", "macro_sql": "\n\n{%- macro type_numeric() -%}\n  {{ return(adapter.dispatch('type_numeric', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__type_numeric"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3603132}, "macro.dbt_utils.default__type_numeric": {"unique_id": "macro.dbt_utils.default__type_numeric", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "default__type_numeric", "macro_sql": "{% macro default__type_numeric() %}\n    numeric(28, 6)\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.360466}, "macro.dbt_utils.bigquery__type_numeric": {"unique_id": "macro.dbt_utils.bigquery__type_numeric", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "bigquery__type_numeric", "macro_sql": "{% macro bigquery__type_numeric() %}\n    numeric\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3606138}, "macro.dbt_utils.type_bigint": {"unique_id": "macro.dbt_utils.type_bigint", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "type_bigint", "macro_sql": "\n\n{%- macro type_bigint() -%}\n  {{ return(adapter.dispatch('type_bigint', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__type_bigint"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.36093}, "macro.dbt_utils.default__type_bigint": {"unique_id": "macro.dbt_utils.default__type_bigint", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "default__type_bigint", "macro_sql": "{% macro default__type_bigint() %}\n    bigint\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.361086}, "macro.dbt_utils.bigquery__type_bigint": {"unique_id": "macro.dbt_utils.bigquery__type_bigint", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "bigquery__type_bigint", "macro_sql": "{% macro bigquery__type_bigint() %}\n    int64\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.361233}, "macro.dbt_utils.type_int": {"unique_id": "macro.dbt_utils.type_int", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "type_int", "macro_sql": "\n\n{%- macro type_int() -%}\n  {{ return(adapter.dispatch('type_int', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__type_int"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.361641}, "macro.dbt_utils.default__type_int": {"unique_id": "macro.dbt_utils.default__type_int", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "default__type_int", "macro_sql": "{% macro default__type_int() %}\n    int\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.361815}, "macro.dbt_utils.bigquery__type_int": {"unique_id": "macro.dbt_utils.bigquery__type_int", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datatypes.sql", "original_file_path": "macros/cross_db_utils/datatypes.sql", "name": "bigquery__type_int", "macro_sql": "{% macro bigquery__type_int() %}\n    int64\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.361965}, "macro.dbt_utils._is_relation": {"unique_id": "macro.dbt_utils._is_relation", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/_is_relation.sql", "original_file_path": "macros/cross_db_utils/_is_relation.sql", "name": "_is_relation", "macro_sql": "{% macro _is_relation(obj, macro) %}\n    {%- if not (obj is mapping and obj.get('metadata', {}).get('type', '').endswith('Relation')) -%}\n        {%- do exceptions.raise_compiler_error(\"Macro \" ~ macro ~ \" expected a Relation but received the value: \" ~ obj) -%}\n    {%- endif -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.362936}, "macro.dbt_utils.length": {"unique_id": "macro.dbt_utils.length", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/length.sql", "original_file_path": "macros/cross_db_utils/length.sql", "name": "length", "macro_sql": "{% macro length(expression) -%}\n    {{ return(adapter.dispatch('length', 'dbt_utils') (expression)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__length"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3636239}, "macro.dbt_utils.default__length": {"unique_id": "macro.dbt_utils.default__length", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/length.sql", "original_file_path": "macros/cross_db_utils/length.sql", "name": "default__length", "macro_sql": "{% macro default__length(expression) %}\n    \n    length(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.363848}, "macro.dbt_utils.redshift__length": {"unique_id": "macro.dbt_utils.redshift__length", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/length.sql", "original_file_path": "macros/cross_db_utils/length.sql", "name": "redshift__length", "macro_sql": "{% macro redshift__length(expression) %}\n\n    len(\n        {{ expression }}\n    )\n    \n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.364063}, "macro.dbt_utils.dateadd": {"unique_id": "macro.dbt_utils.dateadd", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "name": "dateadd", "macro_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\n  {{ return(adapter.dispatch('dateadd', 'dbt_utils')(datepart, interval, from_date_or_timestamp)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__dateadd"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.365134}, "macro.dbt_utils.default__dateadd": {"unique_id": "macro.dbt_utils.default__dateadd", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "name": "default__dateadd", "macro_sql": "{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    dateadd(\n        {{ datepart }},\n        {{ interval }},\n        {{ from_date_or_timestamp }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.365471}, "macro.dbt_utils.bigquery__dateadd": {"unique_id": "macro.dbt_utils.bigquery__dateadd", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "name": "bigquery__dateadd", "macro_sql": "{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n        datetime_add(\n            cast( {{ from_date_or_timestamp }} as datetime),\n        interval {{ interval }} {{ datepart }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.365802}, "macro.dbt_utils.postgres__dateadd": {"unique_id": "macro.dbt_utils.postgres__dateadd", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "name": "postgres__dateadd", "macro_sql": "{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.366127}, "macro.dbt_utils.redshift__dateadd": {"unique_id": "macro.dbt_utils.redshift__dateadd", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/dateadd.sql", "original_file_path": "macros/cross_db_utils/dateadd.sql", "name": "redshift__dateadd", "macro_sql": "{% macro redshift__dateadd(datepart, interval, from_date_or_timestamp) %}\n\n    {{ return(dbt_utils.default__dateadd(datepart, interval, from_date_or_timestamp)) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__dateadd"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.366511}, "macro.dbt_utils.intersect": {"unique_id": "macro.dbt_utils.intersect", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/intersect.sql", "original_file_path": "macros/cross_db_utils/intersect.sql", "name": "intersect", "macro_sql": "{% macro intersect() %}\n  {{ return(adapter.dispatch('intersect', 'dbt_utils')()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__intersect"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.367126}, "macro.dbt_utils.default__intersect": {"unique_id": "macro.dbt_utils.default__intersect", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/intersect.sql", "original_file_path": "macros/cross_db_utils/intersect.sql", "name": "default__intersect", "macro_sql": "{% macro default__intersect() %}\n\n    intersect\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.367286}, "macro.dbt_utils.bigquery__intersect": {"unique_id": "macro.dbt_utils.bigquery__intersect", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/intersect.sql", "original_file_path": "macros/cross_db_utils/intersect.sql", "name": "bigquery__intersect", "macro_sql": "{% macro bigquery__intersect() %}\n\n    intersect distinct\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3674371}, "macro.dbt_utils.escape_single_quotes": {"unique_id": "macro.dbt_utils.escape_single_quotes", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/escape_single_quotes.sql", "original_file_path": "macros/cross_db_utils/escape_single_quotes.sql", "name": "escape_single_quotes", "macro_sql": "{% macro escape_single_quotes(expression) %}\n      {{ return(adapter.dispatch('escape_single_quotes', 'dbt_utils') (expression)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__escape_single_quotes"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3681831}, "macro.dbt_utils.default__escape_single_quotes": {"unique_id": "macro.dbt_utils.default__escape_single_quotes", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/escape_single_quotes.sql", "original_file_path": "macros/cross_db_utils/escape_single_quotes.sql", "name": "default__escape_single_quotes", "macro_sql": "{% macro default__escape_single_quotes(expression) -%}\n{{ expression | replace(\"'\",\"''\") }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3684669}, "macro.dbt_utils.snowflake__escape_single_quotes": {"unique_id": "macro.dbt_utils.snowflake__escape_single_quotes", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/escape_single_quotes.sql", "original_file_path": "macros/cross_db_utils/escape_single_quotes.sql", "name": "snowflake__escape_single_quotes", "macro_sql": "{% macro snowflake__escape_single_quotes(expression) -%}\n{{ expression | replace(\"'\", \"\\\\'\") }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.368748}, "macro.dbt_utils.bigquery__escape_single_quotes": {"unique_id": "macro.dbt_utils.bigquery__escape_single_quotes", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/escape_single_quotes.sql", "original_file_path": "macros/cross_db_utils/escape_single_quotes.sql", "name": "bigquery__escape_single_quotes", "macro_sql": "{% macro bigquery__escape_single_quotes(expression) -%}\n{{ expression | replace(\"'\", \"\\\\'\") }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.36909}, "macro.dbt_utils.right": {"unique_id": "macro.dbt_utils.right", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "name": "right", "macro_sql": "{% macro right(string_text, length_expression) -%}\n    {{ return(adapter.dispatch('right', 'dbt_utils') (string_text, length_expression)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__right"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3701398}, "macro.dbt_utils.default__right": {"unique_id": "macro.dbt_utils.default__right", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "name": "default__right", "macro_sql": "{% macro default__right(string_text, length_expression) %}\n\n    right(\n        {{ string_text }},\n        {{ length_expression }}\n    )\n    \n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.37042}, "macro.dbt_utils.bigquery__right": {"unique_id": "macro.dbt_utils.bigquery__right", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "name": "bigquery__right", "macro_sql": "{% macro bigquery__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        substr(\n            {{ string_text }},\n            -1 * ({{ length_expression }})\n        )\n    end\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3707368}, "macro.dbt_utils.snowflake__right": {"unique_id": "macro.dbt_utils.snowflake__right", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/right.sql", "original_file_path": "macros/cross_db_utils/right.sql", "name": "snowflake__right", "macro_sql": "{% macro snowflake__right(string_text, length_expression) %}\n\n    case when {{ length_expression }} = 0 \n        then ''\n    else \n        right(\n            {{ string_text }},\n            {{ length_expression }}\n        )\n    end\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.37116}, "macro.dbt_utils.datediff": {"unique_id": "macro.dbt_utils.datediff", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "name": "datediff", "macro_sql": "{% macro datediff(first_date, second_date, datepart) %}\n  {{ return(adapter.dispatch('datediff', 'dbt_utils')(first_date, second_date, datepart)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__datediff"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.375296}, "macro.dbt_utils.default__datediff": {"unique_id": "macro.dbt_utils.default__datediff", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "name": "default__datediff", "macro_sql": "{% macro default__datediff(first_date, second_date, datepart) %}\n\n    datediff(\n        {{ datepart }},\n        {{ first_date }},\n        {{ second_date }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.375633}, "macro.dbt_utils.bigquery__datediff": {"unique_id": "macro.dbt_utils.bigquery__datediff", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "name": "bigquery__datediff", "macro_sql": "{% macro bigquery__datediff(first_date, second_date, datepart) %}\n\n    datetime_diff(\n        cast({{second_date}} as datetime),\n        cast({{first_date}} as datetime),\n        {{datepart}}\n    )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3760169}, "macro.dbt_utils.postgres__datediff": {"unique_id": "macro.dbt_utils.postgres__datediff", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "name": "postgres__datediff", "macro_sql": "{% macro postgres__datediff(first_date, second_date, datepart) %}\n\n    {% if datepart == 'year' %}\n        (date_part('year', ({{second_date}})::date) - date_part('year', ({{first_date}})::date))\n    {% elif datepart == 'quarter' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 4 + date_part('quarter', ({{second_date}})::date) - date_part('quarter', ({{first_date}})::date))\n    {% elif datepart == 'month' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 12 + date_part('month', ({{second_date}})::date) - date_part('month', ({{first_date}})::date))\n    {% elif datepart == 'day' %}\n        (({{second_date}})::date - ({{first_date}})::date)\n    {% elif datepart == 'week' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} / 7 + case\n            when date_part('dow', ({{first_date}})::timestamp) <= date_part('dow', ({{second_date}})::timestamp) then\n                case when {{first_date}} <= {{second_date}} then 0 else -1 end\n            else\n                case when {{first_date}} <= {{second_date}} then 1 else 0 end\n        end)\n    {% elif datepart == 'hour' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} * 24 + date_part('hour', ({{second_date}})::timestamp) - date_part('hour', ({{first_date}})::timestamp))\n    {% elif datepart == 'minute' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'hour') }} * 60 + date_part('minute', ({{second_date}})::timestamp) - date_part('minute', ({{first_date}})::timestamp))\n    {% elif datepart == 'second' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60 + floor(date_part('second', ({{second_date}})::timestamp)) - floor(date_part('second', ({{first_date}})::timestamp)))\n    {% elif datepart == 'millisecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000 + floor(date_part('millisecond', ({{second_date}})::timestamp)) - floor(date_part('millisecond', ({{first_date}})::timestamp)))\n    {% elif datepart == 'microsecond' %}\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000000 + floor(date_part('microsecond', ({{second_date}})::timestamp)) - floor(date_part('microsecond', ({{first_date}})::timestamp)))\n    {% else %}\n        {{ exceptions.raise_compiler_error(\"Unsupported datepart for macro datediff in postgres: {!r}\".format(datepart)) }}\n    {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.datediff"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.379406}, "macro.dbt_utils.redshift__datediff": {"unique_id": "macro.dbt_utils.redshift__datediff", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/datediff.sql", "original_file_path": "macros/cross_db_utils/datediff.sql", "name": "redshift__datediff", "macro_sql": "{% macro redshift__datediff(first_date, second_date, datepart) %}\n\n    {{ return(dbt_utils.default__datediff(first_date, second_date, datepart)) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__datediff"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3801239}, "macro.dbt_utils.safe_cast": {"unique_id": "macro.dbt_utils.safe_cast", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "name": "safe_cast", "macro_sql": "{% macro safe_cast(field, type) %}\n  {{ return(adapter.dispatch('safe_cast', 'dbt_utils') (field, type)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__safe_cast"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.380928}, "macro.dbt_utils.default__safe_cast": {"unique_id": "macro.dbt_utils.default__safe_cast", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "name": "default__safe_cast", "macro_sql": "{% macro default__safe_cast(field, type) %}\n    {# most databases don't support this function yet\n    so we just need to use cast #}\n    cast({{field}} as {{type}})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3812149}, "macro.dbt_utils.snowflake__safe_cast": {"unique_id": "macro.dbt_utils.snowflake__safe_cast", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "name": "snowflake__safe_cast", "macro_sql": "{% macro snowflake__safe_cast(field, type) %}\n    try_cast({{field}} as {{type}})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.38148}, "macro.dbt_utils.bigquery__safe_cast": {"unique_id": "macro.dbt_utils.bigquery__safe_cast", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/safe_cast.sql", "original_file_path": "macros/cross_db_utils/safe_cast.sql", "name": "bigquery__safe_cast", "macro_sql": "{% macro bigquery__safe_cast(field, type) %}\n    safe_cast({{field}} as {{type}})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.381742}, "macro.dbt_utils.hash": {"unique_id": "macro.dbt_utils.hash", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/hash.sql", "original_file_path": "macros/cross_db_utils/hash.sql", "name": "hash", "macro_sql": "{% macro hash(field) -%}\n  {{ return(adapter.dispatch('hash', 'dbt_utils') (field)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__hash"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.382423}, "macro.dbt_utils.default__hash": {"unique_id": "macro.dbt_utils.default__hash", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/hash.sql", "original_file_path": "macros/cross_db_utils/hash.sql", "name": "default__hash", "macro_sql": "{% macro default__hash(field) -%}\n    md5(cast({{field}} as {{dbt_utils.type_string()}}))\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.382711}, "macro.dbt_utils.bigquery__hash": {"unique_id": "macro.dbt_utils.bigquery__hash", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/hash.sql", "original_file_path": "macros/cross_db_utils/hash.sql", "name": "bigquery__hash", "macro_sql": "{% macro bigquery__hash(field) -%}\n    to_hex({{dbt_utils.default__hash(field)}})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__hash"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.382974}, "macro.dbt_utils.cast_bool_to_text": {"unique_id": "macro.dbt_utils.cast_bool_to_text", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/cast_bool_to_text.sql", "original_file_path": "macros/cross_db_utils/cast_bool_to_text.sql", "name": "cast_bool_to_text", "macro_sql": "{% macro cast_bool_to_text(field) %}\n  {{ adapter.dispatch('cast_bool_to_text', 'dbt_utils') (field) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__cast_bool_to_text"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3836741}, "macro.dbt_utils.default__cast_bool_to_text": {"unique_id": "macro.dbt_utils.default__cast_bool_to_text", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/cast_bool_to_text.sql", "original_file_path": "macros/cross_db_utils/cast_bool_to_text.sql", "name": "default__cast_bool_to_text", "macro_sql": "{% macro default__cast_bool_to_text(field) %}\n    cast({{ field }} as {{ dbt_utils.type_string() }})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.383967}, "macro.dbt_utils.redshift__cast_bool_to_text": {"unique_id": "macro.dbt_utils.redshift__cast_bool_to_text", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/cast_bool_to_text.sql", "original_file_path": "macros/cross_db_utils/cast_bool_to_text.sql", "name": "redshift__cast_bool_to_text", "macro_sql": "{% macro redshift__cast_bool_to_text(field) %}\n    case\n        when {{ field }} is true then 'true'\n        when {{ field }} is false then 'false'\n    end::text\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3842251}, "macro.dbt_utils.identifier": {"unique_id": "macro.dbt_utils.identifier", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/identifier.sql", "original_file_path": "macros/cross_db_utils/identifier.sql", "name": "identifier", "macro_sql": "{% macro identifier(value) %}\t\n  {%- set error_message = '\n    Warning: the `identifier` macro is no longer supported and will be deprecated in a future release of dbt-utils. \\\n    Use `adapter.quote` instead. The {}.{} model triggered this warning. \\\n    '.format(model.package_name, model.name) -%}\n  {%- do exceptions.warn(error_message) -%}\n  {{ return(adapter.dispatch('identifier', 'dbt_utils') (value)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__identifier"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.385225}, "macro.dbt_utils.default__identifier": {"unique_id": "macro.dbt_utils.default__identifier", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/identifier.sql", "original_file_path": "macros/cross_db_utils/identifier.sql", "name": "default__identifier", "macro_sql": "{% macro default__identifier(value) -%}\t\n    \"{{ value }}\"\t\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.385445}, "macro.dbt_utils.bigquery__identifier": {"unique_id": "macro.dbt_utils.bigquery__identifier", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/identifier.sql", "original_file_path": "macros/cross_db_utils/identifier.sql", "name": "bigquery__identifier", "macro_sql": "{% macro bigquery__identifier(value) -%}\t\n    `{{ value }}`\t\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.38566}, "macro.dbt_utils.any_value": {"unique_id": "macro.dbt_utils.any_value", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/any_value.sql", "original_file_path": "macros/cross_db_utils/any_value.sql", "name": "any_value", "macro_sql": "{% macro any_value(expression) -%}\n    {{ return(adapter.dispatch('any_value', 'dbt_utils') (expression)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__any_value"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3863401}, "macro.dbt_utils.default__any_value": {"unique_id": "macro.dbt_utils.default__any_value", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/any_value.sql", "original_file_path": "macros/cross_db_utils/any_value.sql", "name": "default__any_value", "macro_sql": "{% macro default__any_value(expression) -%}\n    \n    any_value({{ expression }})\n    \n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.386656}, "macro.dbt_utils.postgres__any_value": {"unique_id": "macro.dbt_utils.postgres__any_value", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/any_value.sql", "original_file_path": "macros/cross_db_utils/any_value.sql", "name": "postgres__any_value", "macro_sql": "{% macro postgres__any_value(expression) -%}\n    {#- /*Postgres doesn't support any_value, so we're using min() to get the same result*/ -#}\n    min({{ expression }})\n    \n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.386881}, "macro.dbt_utils.position": {"unique_id": "macro.dbt_utils.position", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/position.sql", "original_file_path": "macros/cross_db_utils/position.sql", "name": "position", "macro_sql": "{% macro position(substring_text, string_text) -%}\n    {{ return(adapter.dispatch('position', 'dbt_utils') (substring_text, string_text)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__position"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.387672}, "macro.dbt_utils.default__position": {"unique_id": "macro.dbt_utils.default__position", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/position.sql", "original_file_path": "macros/cross_db_utils/position.sql", "name": "default__position", "macro_sql": "{% macro default__position(substring_text, string_text) %}\n\n    position(\n        {{ substring_text }} in {{ string_text }}\n    )\n    \n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.387952}, "macro.dbt_utils.bigquery__position": {"unique_id": "macro.dbt_utils.bigquery__position", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/position.sql", "original_file_path": "macros/cross_db_utils/position.sql", "name": "bigquery__position", "macro_sql": "{% macro bigquery__position(substring_text, string_text) %}\n\n    strpos(\n        {{ string_text }},\n        {{ substring_text }}\n        \n    )\n    \n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3882291}, "macro.dbt_utils.string_literal": {"unique_id": "macro.dbt_utils.string_literal", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/literal.sql", "original_file_path": "macros/cross_db_utils/literal.sql", "name": "string_literal", "macro_sql": "{%- macro string_literal(value) -%}\n  {{ return(adapter.dispatch('string_literal', 'dbt_utils') (value)) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__string_literal"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.388844}, "macro.dbt_utils.default__string_literal": {"unique_id": "macro.dbt_utils.default__string_literal", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/literal.sql", "original_file_path": "macros/cross_db_utils/literal.sql", "name": "default__string_literal", "macro_sql": "{% macro default__string_literal(value) -%}\n    '{{ value }}'\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.389066}, "macro.dbt_utils.current_timestamp": {"unique_id": "macro.dbt_utils.current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "current_timestamp", "macro_sql": "{% macro current_timestamp() -%}\n  {{ return(adapter.dispatch('current_timestamp', 'dbt_utils')()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.390141}, "macro.dbt_utils.default__current_timestamp": {"unique_id": "macro.dbt_utils.default__current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() %}\n    current_timestamp::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3903759}, "macro.dbt_utils.redshift__current_timestamp": {"unique_id": "macro.dbt_utils.redshift__current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "redshift__current_timestamp", "macro_sql": "{% macro redshift__current_timestamp() %}\n    getdate()\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.390532}, "macro.dbt_utils.bigquery__current_timestamp": {"unique_id": "macro.dbt_utils.bigquery__current_timestamp", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "bigquery__current_timestamp", "macro_sql": "{% macro bigquery__current_timestamp() %}\n    current_timestamp\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.390683}, "macro.dbt_utils.current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "current_timestamp_in_utc", "macro_sql": "{% macro current_timestamp_in_utc() -%}\n  {{ return(adapter.dispatch('current_timestamp_in_utc', 'dbt_utils')()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__current_timestamp_in_utc"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.391}, "macro.dbt_utils.default__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.default__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "default__current_timestamp_in_utc", "macro_sql": "{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp()}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3912299}, "macro.dbt_utils.snowflake__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.snowflake__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "snowflake__current_timestamp_in_utc", "macro_sql": "{% macro snowflake__current_timestamp_in_utc() %}\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.current_timestamp", "macro.dbt_utils.type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.391528}, "macro.dbt_utils.postgres__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.postgres__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "postgres__current_timestamp_in_utc", "macro_sql": "{% macro postgres__current_timestamp_in_utc() %}\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3917592}, "macro.dbt_utils.redshift__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.redshift__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/current_timestamp.sql", "original_file_path": "macros/cross_db_utils/current_timestamp.sql", "name": "redshift__current_timestamp_in_utc", "macro_sql": "{% macro redshift__current_timestamp_in_utc() %}\n    {{ return(dbt_utils.default__current_timestamp_in_utc()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__current_timestamp_in_utc"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.392025}, "macro.dbt_utils.width_bucket": {"unique_id": "macro.dbt_utils.width_bucket", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "name": "width_bucket", "macro_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\n  {{ return(adapter.dispatch('width_bucket', 'dbt_utils') (expr, min_value, max_value, num_buckets)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__width_bucket"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.394312}, "macro.dbt_utils.default__width_bucket": {"unique_id": "macro.dbt_utils.default__width_bucket", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "name": "default__width_bucket", "macro_sql": "{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is eaxtly at the bucket egde\n        case\n            when\n                mod(\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                ) = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.safe_cast", "macro.dbt_utils.type_numeric"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.395217}, "macro.dbt_utils.redshift__width_bucket": {"unique_id": "macro.dbt_utils.redshift__width_bucket", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "name": "redshift__width_bucket", "macro_sql": "{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\n\n    {% set bin_size -%}\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\n    {%- endset %}\n    (\n        -- to break ties when the amount is exactly at the bucket edge\n        case\n            when\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\n                 = 0\n            then 1\n            else 0\n        end\n    ) +\n      -- Anything over max_value goes the N+1 bucket\n    least(\n        ceil(\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\n        ),\n        {{ num_buckets }} + 1\n    )\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.safe_cast", "macro.dbt_utils.type_numeric"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.396215}, "macro.dbt_utils.snowflake__width_bucket": {"unique_id": "macro.dbt_utils.snowflake__width_bucket", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/width_bucket.sql", "original_file_path": "macros/cross_db_utils/width_bucket.sql", "name": "snowflake__width_bucket", "macro_sql": "{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3966029}, "macro.dbt_utils.bool_or": {"unique_id": "macro.dbt_utils.bool_or", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/bool_or.sql", "original_file_path": "macros/cross_db_utils/bool_or.sql", "name": "bool_or", "macro_sql": "{% macro bool_or(expression) -%}\n    {{ return(adapter.dispatch('bool_or', 'dbt_utils') (expression)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__bool_or"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3973398}, "macro.dbt_utils.default__bool_or": {"unique_id": "macro.dbt_utils.default__bool_or", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/bool_or.sql", "original_file_path": "macros/cross_db_utils/bool_or.sql", "name": "default__bool_or", "macro_sql": "{% macro default__bool_or(expression) -%}\n    \n    bool_or({{ expression }})\n    \n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.3975549}, "macro.dbt_utils.snowflake__bool_or": {"unique_id": "macro.dbt_utils.snowflake__bool_or", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/bool_or.sql", "original_file_path": "macros/cross_db_utils/bool_or.sql", "name": "snowflake__bool_or", "macro_sql": "{% macro snowflake__bool_or(expression) -%}\n    \n    boolor_agg({{ expression }})\n    \n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.397763}, "macro.dbt_utils.bigquery__bool_or": {"unique_id": "macro.dbt_utils.bigquery__bool_or", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/bool_or.sql", "original_file_path": "macros/cross_db_utils/bool_or.sql", "name": "bigquery__bool_or", "macro_sql": "{% macro bigquery__bool_or(expression) -%}\n    \n    logical_or({{ expression }})\n    \n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.397971}, "macro.dbt_utils.last_day": {"unique_id": "macro.dbt_utils.last_day", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "name": "last_day", "macro_sql": "{% macro last_day(date, datepart) %}\n  {{ return(adapter.dispatch('last_day', 'dbt_utils') (date, datepart)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__last_day"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.399053}, "macro.dbt_utils.default_last_day": {"unique_id": "macro.dbt_utils.default_last_day", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "name": "default_last_day", "macro_sql": "\n\n\n{%- macro default_last_day(date, datepart) -%}\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbt_utils.date_trunc"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.399576}, "macro.dbt_utils.default__last_day": {"unique_id": "macro.dbt_utils.default__last_day", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "name": "default__last_day", "macro_sql": "{% macro default__last_day(date, datepart) -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default_last_day"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.399876}, "macro.dbt_utils.postgres__last_day": {"unique_id": "macro.dbt_utils.postgres__last_day", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "name": "postgres__last_day", "macro_sql": "{% macro postgres__last_day(date, datepart) -%}\n\n    {%- if datepart == 'quarter' -%}\n    -- postgres dateadd does not support quarter interval.\n    cast(\n        {{dbt_utils.dateadd('day', '-1',\n        dbt_utils.dateadd('month', '3', dbt_utils.date_trunc(datepart, date))\n        )}}\n        as date)\n    {%- else -%}\n    {{dbt_utils.default_last_day(date, datepart)}}\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbt_utils.date_trunc", "macro.dbt_utils.default_last_day"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.400644}, "macro.dbt_utils.redshift__last_day": {"unique_id": "macro.dbt_utils.redshift__last_day", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/last_day.sql", "original_file_path": "macros/cross_db_utils/last_day.sql", "name": "redshift__last_day", "macro_sql": "{% macro redshift__last_day(date, datepart) %}\n\n    {{ return(dbt_utils.default__last_day(date, datepart)) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__last_day"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4009962}, "macro.dbt_utils.split_part": {"unique_id": "macro.dbt_utils.split_part", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/split_part.sql", "original_file_path": "macros/cross_db_utils/split_part.sql", "name": "split_part", "macro_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\n  {{ return(adapter.dispatch('split_part', 'dbt_utils') (string_text, delimiter_text, part_number)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__split_part"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.402005}, "macro.dbt_utils.default__split_part": {"unique_id": "macro.dbt_utils.default__split_part", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/split_part.sql", "original_file_path": "macros/cross_db_utils/split_part.sql", "name": "default__split_part", "macro_sql": "{% macro default__split_part(string_text, delimiter_text, part_number) %}\n\n    split_part(\n        {{ string_text }},\n        {{ delimiter_text }},\n        {{ part_number }}\n        )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.402347}, "macro.dbt_utils.bigquery__split_part": {"unique_id": "macro.dbt_utils.bigquery__split_part", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/split_part.sql", "original_file_path": "macros/cross_db_utils/split_part.sql", "name": "bigquery__split_part", "macro_sql": "{% macro bigquery__split_part(string_text, delimiter_text, part_number) %}\n\n    split(\n        {{ string_text }},\n        {{ delimiter_text }}\n        )[safe_offset({{ part_number - 1 }})]\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4027011}, "macro.dbt_utils.date_trunc": {"unique_id": "macro.dbt_utils.date_trunc", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/date_trunc.sql", "original_file_path": "macros/cross_db_utils/date_trunc.sql", "name": "date_trunc", "macro_sql": "{% macro date_trunc(datepart, date) -%}\n  {{ return(adapter.dispatch('date_trunc', 'dbt_utils') (datepart, date)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__date_trunc"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.403459}, "macro.dbt_utils.default__date_trunc": {"unique_id": "macro.dbt_utils.default__date_trunc", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/date_trunc.sql", "original_file_path": "macros/cross_db_utils/date_trunc.sql", "name": "default__date_trunc", "macro_sql": "{% macro default__date_trunc(datepart, date) %}\n    date_trunc('{{datepart}}', {{date}})\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4037278}, "macro.dbt_utils.bigquery__date_trunc": {"unique_id": "macro.dbt_utils.bigquery__date_trunc", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/date_trunc.sql", "original_file_path": "macros/cross_db_utils/date_trunc.sql", "name": "bigquery__date_trunc", "macro_sql": "{% macro bigquery__date_trunc(datepart, date) %}\n    timestamp_trunc(\n        cast({{date}} as timestamp),\n        {{datepart}}\n    )\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.403996}, "macro.dbt_utils._is_ephemeral": {"unique_id": "macro.dbt_utils._is_ephemeral", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/cross_db_utils/_is_ephemeral.sql", "original_file_path": "macros/cross_db_utils/_is_ephemeral.sql", "name": "_is_ephemeral", "macro_sql": "{% macro _is_ephemeral(obj, macro) %}\n    {%- if obj.is_cte -%}\n        {% set ephemeral_prefix = api.Relation.add_ephemeral_prefix('') %}\n        {% if obj.name.startswith(ephemeral_prefix) %}\n            {% set model_name = obj.name[(ephemeral_prefix|length):] %}\n        {% else %}\n            {% set model_name = obj.name %}\n        {%- endif -%}\n        {% set error_message %}\nThe `{{ macro }}` macro cannot be used with ephemeral models, as it relies on the information schema.\n\n`{{ model_name }}` is an ephemeral model. Consider making it a view or table instead.\n        {% endset %}\n        {%- do exceptions.raise_compiler_error(error_message) -%}\n    {%- endif -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.405709}, "macro.dbt_utils.get_period_boundaries": {"unique_id": "macro.dbt_utils.get_period_boundaries", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "name": "get_period_boundaries", "macro_sql": "{% macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n    {{ return(adapter.dispatch('get_period_boundaries', 'dbt_utils')(target_schema, target_table, timestamp_field, start_date, stop_date, period)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_period_boundaries"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.414452}, "macro.dbt_utils.default__get_period_boundaries": {"unique_id": "macro.dbt_utils.default__get_period_boundaries", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "name": "default__get_period_boundaries", "macro_sql": "{% macro default__get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n  {% call statement('period_boundaries', fetch_result=True) -%}\n    with data as (\n      select\n          coalesce(max(\"{{timestamp_field}}\"), '{{start_date}}')::timestamp as start_timestamp,\n          coalesce(\n            {{dbt_utils.dateadd('millisecond',\n                                -1,\n                                \"nullif('\" ~ stop_date ~ \"','')::timestamp\")}},\n            {{dbt_utils.current_timestamp()}}\n          ) as stop_timestamp\n      from \"{{target_schema}}\".\"{{target_table}}\"\n    )\n\n    select\n      start_timestamp,\n      stop_timestamp,\n      {{dbt_utils.datediff('start_timestamp',\n                           'stop_timestamp',\n                           period)}}  + 1 as num_periods\n    from data\n  {%- endcall %}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_utils.dateadd", "macro.dbt_utils.current_timestamp", "macro.dbt_utils.datediff"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.415551}, "macro.dbt_utils.get_period_sql": {"unique_id": "macro.dbt_utils.get_period_sql", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "name": "get_period_sql", "macro_sql": "{% macro get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n    {{ return(adapter.dispatch('get_period_sql', 'dbt_utils')(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_period_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.416163}, "macro.dbt_utils.default__get_period_sql": {"unique_id": "macro.dbt_utils.default__get_period_sql", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "name": "default__get_period_sql", "macro_sql": "{% macro default__get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n  {%- set period_filter -%}\n    (\"{{timestamp_field}}\" >  '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' and\n     \"{{timestamp_field}}\" <= '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' + interval '1 {{period}}' and\n     \"{{timestamp_field}}\" <  '{{stop_timestamp}}'::timestamp)\n  {%- endset -%}\n\n  {%- set filtered_sql = sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n  select\n    {{target_cols_csv}}\n  from (\n    {{filtered_sql}}\n  )\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.417137}, "macro.dbt_utils.materialization_insert_by_period_default": {"unique_id": "macro.dbt_utils.materialization_insert_by_period_default", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/materializations/insert_by_period_materialization.sql", "original_file_path": "macros/materializations/insert_by_period_materialization.sql", "name": "materialization_insert_by_period_default", "macro_sql": "{% materialization insert_by_period, default -%}\n  {%- set timestamp_field = config.require('timestamp_field') -%}\n  {%- set start_date = config.require('start_date') -%}\n  {%- set stop_date = config.get('stop_date') or '' -%}\n  {%- set period = config.get('period') or 'week' -%}\n\n  {%- if sql.find('__PERIOD_FILTER__') == -1 -%}\n    {%- set error_message -%}\n      Model '{{ model.unique_id }}' does not include the required string '__PERIOD_FILTER__' in its sql\n    {%- endset -%}\n    {{ exceptions.raise_compiler_error(error_message) }}\n  {%- endif -%}\n\n  {%- set identifier = model['name'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, type='table') -%}\n\n  {%- set non_destructive_mode = (flags.NON_DESTRUCTIVE == True) -%}\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\n\n  {%- set should_truncate = (non_destructive_mode and full_refresh_mode and exists_as_table) -%}\n  {%- set should_drop = (not should_truncate and (full_refresh_mode or exists_not_as_table)) -%}\n  {%- set force_create = (flags.FULL_REFRESH and not flags.NON_DESTRUCTIVE) -%}\n\n  -- setup\n  {% if old_relation is none -%}\n    -- noop\n  {%- elif should_truncate -%}\n    {{adapter.truncate_relation(old_relation)}}\n  {%- elif should_drop -%}\n    {{adapter.drop_relation(old_relation)}}\n    {%- set old_relation = none -%}\n  {%- endif %}\n\n  {{run_hooks(pre_hooks, inside_transaction=False)}}\n\n  -- `begin` happens here, so `commit` after it to finish the transaction\n  {{run_hooks(pre_hooks, inside_transaction=True)}}\n  {% call statement() -%}\n    begin; -- make extra sure we've closed out the transaction\n    commit;\n  {%- endcall %}\n\n  -- build model\n  {% if force_create or old_relation is none -%}\n    {# Create an empty target table -#}\n    {% call statement('main') -%}\n      {%- set empty_sql = sql | replace(\"__PERIOD_FILTER__\", 'false') -%}\n      {{create_table_as(False, target_relation, empty_sql)}}\n    {%- endcall %}\n  {%- endif %}\n\n  {% set _ = dbt_utils.get_period_boundaries(schema,\n                                              identifier,\n                                              timestamp_field,\n                                              start_date,\n                                              stop_date,\n                                              period) %}\n  {%- set start_timestamp = load_result('period_boundaries')['data'][0][0] | string -%}\n  {%- set stop_timestamp = load_result('period_boundaries')['data'][0][1] | string -%}\n  {%- set num_periods = load_result('period_boundaries')['data'][0][2] | int -%}\n\n  {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n  {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n  {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n  -- commit each period as a separate transaction\n  {% for i in range(num_periods) -%}\n    {%- set msg = \"Running for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) -%}\n    {{ dbt_utils.log_info(msg) }}\n\n    {%- set tmp_identifier = model['name'] ~ '__dbt_incremental_period' ~ i ~ '_tmp' -%}\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\n                                               schema=schema, type='table') -%}\n    {% call statement() -%}\n      {% set tmp_table_sql = dbt_utils.get_period_sql(target_cols_csv,\n                                                       sql,\n                                                       timestamp_field,\n                                                       period,\n                                                       start_timestamp,\n                                                       stop_timestamp,\n                                                       i) %}\n      {{dbt.create_table_as(True, tmp_relation, tmp_table_sql)}}\n    {%- endcall %}\n\n    {{adapter.expand_target_column_types(from_relation=tmp_relation,\n                                         to_relation=target_relation)}}\n    {%- set name = 'main-' ~ i -%}\n    {% call statement(name, fetch_result=True) -%}\n      insert into {{target_relation}} ({{target_cols_csv}})\n      (\n          select\n              {{target_cols_csv}}\n          from {{tmp_relation.include(schema=False)}}\n      );\n    {%- endcall %}\n    {% set result = load_result('main-' ~ i) %}\n    {% if 'response' in result.keys() %} {# added in v0.19.0 #}\n        {% set rows_inserted = result['response']['rows_affected'] %}\n    {% else %} {# older versions #}\n        {% set rows_inserted = result['status'].split(\" \")[2] | int %}\n    {% endif %}\n    \n    {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n    {%- if loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %} {% endif -%}\n\n    {%- set msg = \"Ran for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) ~ \"; \" ~ rows_inserted ~ \" records inserted\" -%}\n    {{ dbt_utils.log_info(msg) }}\n\n  {%- endfor %}\n\n  {% call statement() -%}\n    begin;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=True)}}\n\n  {% call statement() -%}\n    commit;\n  {%- endcall %}\n\n  {{run_hooks(post_hooks, inside_transaction=False)}}\n\n  {%- set status_string = \"INSERT \" ~ loop_vars['sum_rows_inserted'] -%}\n\n  {% call noop_statement('main', status_string) -%}\n    -- no-op\n  {%- endcall %}\n\n  -- Return the relations created in this materialization\n  {{ return({'relations': [target_relation]}) }}  \n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_hooks", "macro.dbt.statement", "macro.dbt.create_table_as", "macro.dbt_utils.get_period_boundaries", "macro.dbt_utils.log_info", "macro.dbt_utils.get_period_sql", "macro.dbt.noop_statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.42703}, "macro.dbt_utils.get_url_host": {"unique_id": "macro.dbt_utils.get_url_host", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/web/get_url_host.sql", "original_file_path": "macros/web/get_url_host.sql", "name": "get_url_host", "macro_sql": "{% macro get_url_host(field) -%}\n    {{ return(adapter.dispatch('get_url_host', 'dbt_utils')(field)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_url_host"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.427914}, "macro.dbt_utils.default__get_url_host": {"unique_id": "macro.dbt_utils.default__get_url_host", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/web/get_url_host.sql", "original_file_path": "macros/web/get_url_host.sql", "name": "default__get_url_host", "macro_sql": "{% macro default__get_url_host(field) -%}\n\n{%- set parsed =\n    dbt_utils.split_part(\n        dbt_utils.split_part(\n            dbt_utils.replace(\n                dbt_utils.replace(\n                    dbt_utils.replace(field, \"'android-app://'\", \"''\"\n                    ), \"'http://'\", \"''\"\n                ), \"'https://'\", \"''\"\n            ), \"'/'\", 1\n        ), \"'?'\", 1\n    )\n\n-%}\n\n\n    {{ dbt_utils.safe_cast(\n        parsed,\n        dbt_utils.type_string()\n        )}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.split_part", "macro.dbt_utils.replace", "macro.dbt_utils.safe_cast", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.428826}, "macro.dbt_utils.get_url_path": {"unique_id": "macro.dbt_utils.get_url_path", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/web/get_url_path.sql", "original_file_path": "macros/web/get_url_path.sql", "name": "get_url_path", "macro_sql": "{% macro get_url_path(field) -%}\n    {{ return(adapter.dispatch('get_url_path', 'dbt_utils')(field)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_url_path"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.429777}, "macro.dbt_utils.default__get_url_path": {"unique_id": "macro.dbt_utils.default__get_url_path", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/web/get_url_path.sql", "original_file_path": "macros/web/get_url_path.sql", "name": "default__get_url_path", "macro_sql": "{% macro default__get_url_path(field) -%}\n\n    {%- set stripped_url = \n        dbt_utils.replace(\n            dbt_utils.replace(field, \"'http://'\", \"''\"), \"'https://'\", \"''\")\n    -%}\n\n    {%- set first_slash_pos -%}\n        coalesce(\n            nullif({{dbt_utils.position(\"'/'\", stripped_url)}}, 0),\n            {{dbt_utils.position(\"'?'\", stripped_url)}} - 1\n            )\n    {%- endset -%}\n\n    {%- set parsed_path =\n        dbt_utils.split_part(\n            dbt_utils.right(\n                stripped_url, \n                dbt_utils.length(stripped_url) ~ \"-\" ~ first_slash_pos\n                ), \n            \"'?'\", 1\n            )\n    -%}\n\n    {{ dbt_utils.safe_cast(\n        parsed_path,\n        dbt_utils.type_string()\n    )}}\n    \n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.replace", "macro.dbt_utils.position", "macro.dbt_utils.split_part", "macro.dbt_utils.right", "macro.dbt_utils.length", "macro.dbt_utils.safe_cast", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.431085}, "macro.dbt_utils.get_url_parameter": {"unique_id": "macro.dbt_utils.get_url_parameter", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/web/get_url_parameter.sql", "original_file_path": "macros/web/get_url_parameter.sql", "name": "get_url_parameter", "macro_sql": "{% macro get_url_parameter(field, url_parameter) -%}\n    {{ return(adapter.dispatch('get_url_parameter', 'dbt_utils')(field, url_parameter)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_url_parameter"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4319181}, "macro.dbt_utils.default__get_url_parameter": {"unique_id": "macro.dbt_utils.default__get_url_parameter", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/web/get_url_parameter.sql", "original_file_path": "macros/web/get_url_parameter.sql", "name": "default__get_url_parameter", "macro_sql": "{% macro default__get_url_parameter(field, url_parameter) -%}\n\n{%- set formatted_url_parameter = \"'\" + url_parameter + \"='\" -%}\n\n{%- set split = dbt_utils.split_part(dbt_utils.split_part(field, formatted_url_parameter, 2), \"'&'\", 1) -%}\n\nnullif({{ split }},'')\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.split_part"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.432551}, "macro.dbt_utils.pretty_log_format": {"unique_id": "macro.dbt_utils.pretty_log_format", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/pretty_log_format.sql", "original_file_path": "macros/jinja_helpers/pretty_log_format.sql", "name": "pretty_log_format", "macro_sql": "{% macro pretty_log_format(message) %}\n    {{ return(adapter.dispatch('pretty_log_format', 'dbt_utils')(message)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__pretty_log_format"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.433194}, "macro.dbt_utils.default__pretty_log_format": {"unique_id": "macro.dbt_utils.default__pretty_log_format", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/pretty_log_format.sql", "original_file_path": "macros/jinja_helpers/pretty_log_format.sql", "name": "default__pretty_log_format", "macro_sql": "{% macro default__pretty_log_format(message) %}\n    {{ return( dbt_utils.pretty_time() ~ ' + ' ~ message) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.pretty_time"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.433524}, "macro.dbt_utils.pretty_time": {"unique_id": "macro.dbt_utils.pretty_time", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/pretty_time.sql", "original_file_path": "macros/jinja_helpers/pretty_time.sql", "name": "pretty_time", "macro_sql": "{% macro pretty_time(format='%H:%M:%S') %}\n    {{ return(adapter.dispatch('pretty_time', 'dbt_utils')(format)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__pretty_time"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.434196}, "macro.dbt_utils.default__pretty_time": {"unique_id": "macro.dbt_utils.default__pretty_time", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/pretty_time.sql", "original_file_path": "macros/jinja_helpers/pretty_time.sql", "name": "default__pretty_time", "macro_sql": "{% macro default__pretty_time(format='%H:%M:%S') %}\n    {{ return(modules.datetime.datetime.now().strftime(format)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.434591}, "macro.dbt_utils.log_info": {"unique_id": "macro.dbt_utils.log_info", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/log_info.sql", "original_file_path": "macros/jinja_helpers/log_info.sql", "name": "log_info", "macro_sql": "{% macro log_info(message) %}\n    {{ return(adapter.dispatch('log_info', 'dbt_utils')(message)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__log_info"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.435232}, "macro.dbt_utils.default__log_info": {"unique_id": "macro.dbt_utils.default__log_info", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/log_info.sql", "original_file_path": "macros/jinja_helpers/log_info.sql", "name": "default__log_info", "macro_sql": "{% macro default__log_info(message) %}\n    {{ log(dbt_utils.pretty_log_format(message), info=True) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.pretty_log_format"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.43558}, "macro.dbt_utils.slugify": {"unique_id": "macro.dbt_utils.slugify", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/jinja_helpers/slugify.sql", "original_file_path": "macros/jinja_helpers/slugify.sql", "name": "slugify", "macro_sql": "{% macro slugify(string) %}\n\n{#- Lower case the string -#}\n{% set string = string | lower %}\n{#- Replace spaces and dashes with underscores -#}\n{% set string = modules.re.sub('[ -]+', '_', string) %}\n{#- Only take letters, numbers, and underscores -#}\n{% set string = modules.re.sub('[^a-z0-9_]+', '', string) %}\n\n{{ return(string) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.436608}, "macro.dbt_utils.test_fewer_rows_than": {"unique_id": "macro.dbt_utils.test_fewer_rows_than", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/fewer_rows_than.sql", "original_file_path": "macros/schema_tests/fewer_rows_than.sql", "name": "test_fewer_rows_than", "macro_sql": "{% test fewer_rows_than(model, compare_model) %}\n  {{ return(adapter.dispatch('test_fewer_rows_than', 'dbt_utils')(model, compare_model)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_fewer_rows_than"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.437622}, "macro.dbt_utils.default__test_fewer_rows_than": {"unique_id": "macro.dbt_utils.default__test_fewer_rows_than", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/fewer_rows_than.sql", "original_file_path": "macros/schema_tests/fewer_rows_than.sql", "name": "default__test_fewer_rows_than", "macro_sql": "{% macro default__test_fewer_rows_than(model, compare_model) %}\n\n{{ config(fail_calc = 'coalesce(row_count_delta, 0)') }}\n\nwith a as (\n\n    select count(*) as count_our_model from {{ model }}\n\n),\nb as (\n\n    select count(*) as count_comparison_model from {{ compare_model }}\n\n),\ncounts as (\n\n    select\n        count_our_model,\n        count_comparison_model\n    from a\n    cross join b\n\n),\nfinal as (\n\n    select *,\n        case\n            -- fail the test if we have more rows than the reference model and return the row count delta\n            when count_our_model > count_comparison_model then (count_our_model - count_comparison_model)\n            -- fail the test if they are the same number\n            when count_our_model = count_comparison_model then 1\n            -- pass the test if the delta is positive (i.e. return the number 0)\n            else 0\n    end as row_count_delta\n    from counts\n\n)\n\nselect * from final\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.438066}, "macro.dbt_utils.test_equal_rowcount": {"unique_id": "macro.dbt_utils.test_equal_rowcount", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/equal_rowcount.sql", "original_file_path": "macros/schema_tests/equal_rowcount.sql", "name": "test_equal_rowcount", "macro_sql": "{% test equal_rowcount(model, compare_model) %}\n  {{ return(adapter.dispatch('test_equal_rowcount', 'dbt_utils')(model, compare_model)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_equal_rowcount"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4388921}, "macro.dbt_utils.default__test_equal_rowcount": {"unique_id": "macro.dbt_utils.default__test_equal_rowcount", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/equal_rowcount.sql", "original_file_path": "macros/schema_tests/equal_rowcount.sql", "name": "default__test_equal_rowcount", "macro_sql": "{% macro default__test_equal_rowcount(model, compare_model) %}\n\n{#-- Needs to be set at parse time, before we return '' below --#}\n{{ config(fail_calc = 'coalesce(diff_count, 0)') }}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\nwith a as (\n\n    select count(*) as count_a from {{ model }}\n\n),\nb as (\n\n    select count(*) as count_b from {{ compare_model }}\n\n),\nfinal as (\n\n    select\n        count_a,\n        count_b,\n        abs(count_a - count_b) as diff_count\n    from a\n    cross join b\n\n)\n\nselect * from final\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.439487}, "macro.dbt_utils.test_relationships_where": {"unique_id": "macro.dbt_utils.test_relationships_where", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/relationships_where.sql", "original_file_path": "macros/schema_tests/relationships_where.sql", "name": "test_relationships_where", "macro_sql": "{% test relationships_where(model, column_name, to, field, from_condition=\"1=1\", to_condition=\"1=1\") %}\n  {{ return(adapter.dispatch('test_relationships_where', 'dbt_utils')(model, column_name, to, field, from_condition, to_condition)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_relationships_where"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.440701}, "macro.dbt_utils.default__test_relationships_where": {"unique_id": "macro.dbt_utils.default__test_relationships_where", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/relationships_where.sql", "original_file_path": "macros/schema_tests/relationships_where.sql", "name": "default__test_relationships_where", "macro_sql": "{% macro default__test_relationships_where(model, column_name, to, field, from_condition=\"1=1\", to_condition=\"1=1\") %}\n\n{# T-SQL has no boolean data type so we use 1=1 which returns TRUE #}\n{# ref https://stackoverflow.com/a/7170753/3842610 #}\n\nwith left_table as (\n\n  select\n    {{column_name}} as id\n\n  from {{model}}\n\n  where {{column_name}} is not null\n    and {{from_condition}}\n\n),\n\nright_table as (\n\n  select\n    {{field}} as id\n\n  from {{to}}\n\n  where {{field}} is not null\n    and {{to_condition}}\n\n),\n\nexceptions as (\n\n  select\n    left_table.id,\n    right_table.id as right_id\n\n  from left_table\n\n  left join right_table\n         on left_table.id = right_table.id\n\n  where right_table.id is null\n\n)\n\nselect * from exceptions\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.441462}, "macro.dbt_utils.test_recency": {"unique_id": "macro.dbt_utils.test_recency", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/recency.sql", "original_file_path": "macros/schema_tests/recency.sql", "name": "test_recency", "macro_sql": "{% test recency(model, field, datepart, interval) %}\n  {{ return(adapter.dispatch('test_recency', 'dbt_utils')(model, field, datepart, interval)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_recency"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.442328}, "macro.dbt_utils.default__test_recency": {"unique_id": "macro.dbt_utils.default__test_recency", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/recency.sql", "original_file_path": "macros/schema_tests/recency.sql", "name": "default__test_recency", "macro_sql": "{% macro default__test_recency(model, field, datepart, interval) %}\n\n{% set threshold = dbt_utils.dateadd(datepart, interval * -1, dbt_utils.current_timestamp()) %}\n\nwith recency as (\n\n    select max({{field}}) as most_recent\n    from {{ model }}\n\n)\n\nselect\n\n    most_recent,\n    {{ threshold }} as threshold\n\nfrom recency\nwhere most_recent < {{ threshold }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbt_utils.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4429781}, "macro.dbt_utils.test_not_constant": {"unique_id": "macro.dbt_utils.test_not_constant", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/not_constant.sql", "original_file_path": "macros/schema_tests/not_constant.sql", "name": "test_not_constant", "macro_sql": "{% test not_constant(model, column_name) %}\n  {{ return(adapter.dispatch('test_not_constant', 'dbt_utils')(model, column_name)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_not_constant"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4437041}, "macro.dbt_utils.default__test_not_constant": {"unique_id": "macro.dbt_utils.default__test_not_constant", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/not_constant.sql", "original_file_path": "macros/schema_tests/not_constant.sql", "name": "default__test_not_constant", "macro_sql": "{% macro default__test_not_constant(model, column_name) %}\n\n\nselect\n    {# In TSQL, subquery aggregate columns need aliases #}\n    {# thus: a filler col name, 'filler_column' #}\n    count(distinct {{ column_name }}) as filler_column\n\nfrom {{ model }}\n\nhaving count(distinct {{ column_name }}) = 1\n\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.444059}, "macro.dbt_utils.test_accepted_range": {"unique_id": "macro.dbt_utils.test_accepted_range", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/accepted_range.sql", "original_file_path": "macros/schema_tests/accepted_range.sql", "name": "test_accepted_range", "macro_sql": "{% test accepted_range(model, column_name, min_value=none, max_value=none, inclusive=true) %}\n  {{ return(adapter.dispatch('test_accepted_range', 'dbt_utils')(model, column_name, min_value, max_value, inclusive)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_accepted_range"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.445238}, "macro.dbt_utils.default__test_accepted_range": {"unique_id": "macro.dbt_utils.default__test_accepted_range", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/accepted_range.sql", "original_file_path": "macros/schema_tests/accepted_range.sql", "name": "default__test_accepted_range", "macro_sql": "{% macro default__test_accepted_range(model, column_name, min_value=none, max_value=none, inclusive=true) %}\n\nwith meet_condition as(\n  select *\n  from {{ model }}\n),\n\nvalidation_errors as (\n  select *\n  from meet_condition\n  where\n    -- never true, defaults to an empty result set. Exists to ensure any combo of the `or` clauses below succeeds\n    1 = 2\n\n  {%- if min_value is not none %}\n    -- records with a value >= min_value are permitted. The `not` flips this to find records that don't meet the rule.\n    or not {{ column_name }} > {{- \"=\" if inclusive }} {{ min_value }}\n  {%- endif %}\n\n  {%- if max_value is not none %}\n    -- records with a value <= max_value are permitted. The `not` flips this to find records that don't meet the rule.\n    or not {{ column_name }} < {{- \"=\" if inclusive }} {{ max_value }}\n  {%- endif %}\n)\n\nselect *\nfrom validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.446163}, "macro.dbt_utils.test_not_accepted_values": {"unique_id": "macro.dbt_utils.test_not_accepted_values", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/not_accepted_values.sql", "original_file_path": "macros/schema_tests/not_accepted_values.sql", "name": "test_not_accepted_values", "macro_sql": "{% test not_accepted_values(model, column_name, values, quote=True) %}\n  {{ return(adapter.dispatch('test_not_accepted_values', 'dbt_utils')(model, column_name, values, quote)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_not_accepted_values"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.447233}, "macro.dbt_utils.default__test_not_accepted_values": {"unique_id": "macro.dbt_utils.default__test_not_accepted_values", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/not_accepted_values.sql", "original_file_path": "macros/schema_tests/not_accepted_values.sql", "name": "default__test_not_accepted_values", "macro_sql": "{% macro default__test_not_accepted_values(model, column_name, values, quote=True) %}\nwith all_values as (\n\n    select distinct\n        {{ column_name }} as value_field\n\n    from {{ model }}\n\n),\n\nvalidation_errors as (\n\n    select\n        value_field\n\n    from all_values\n    where value_field in (\n        {% for value in values -%}\n            {% if quote -%}\n            '{{ value }}'\n            {%- else -%}\n            {{ value }}\n            {%- endif -%}\n            {%- if not loop.last -%},{%- endif %}\n        {%- endfor %}\n        )\n\n)\n\nselect *\nfrom validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.447996}, "macro.dbt_utils.test_unique_where": {"unique_id": "macro.dbt_utils.test_unique_where", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/test_unique_where.sql", "original_file_path": "macros/schema_tests/test_unique_where.sql", "name": "test_unique_where", "macro_sql": "{% test unique_where(model, column_name) %}\r\n  {%- set deprecation_warning = '\r\n    Warning: `dbt_utils.unique_where` is no longer supported.\r\n    Starting in dbt v0.20.0, the built-in `unique` test supports a `where` config.\r\n    ' -%}\r\n  {%- do exceptions.warn(deprecation_warning) -%}\r\n  {{ return(adapter.dispatch('test_unique_where', 'dbt_utils')(model, column_name)) }}\r\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_unique_where"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.448971}, "macro.dbt_utils.default__test_unique_where": {"unique_id": "macro.dbt_utils.default__test_unique_where", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/test_unique_where.sql", "original_file_path": "macros/schema_tests/test_unique_where.sql", "name": "default__test_unique_where", "macro_sql": "{% macro default__test_unique_where(model, column_name) %}\r\n  {{ return(test_unique(model, column_name)) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.test_unique"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4493089}, "macro.dbt_utils.test_at_least_one": {"unique_id": "macro.dbt_utils.test_at_least_one", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/at_least_one.sql", "original_file_path": "macros/schema_tests/at_least_one.sql", "name": "test_at_least_one", "macro_sql": "{% test at_least_one(model, column_name) %}\n  {{ return(adapter.dispatch('test_at_least_one', 'dbt_utils')(model, column_name)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_at_least_one"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.450048}, "macro.dbt_utils.default__test_at_least_one": {"unique_id": "macro.dbt_utils.default__test_at_least_one", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/at_least_one.sql", "original_file_path": "macros/schema_tests/at_least_one.sql", "name": "default__test_at_least_one", "macro_sql": "{% macro default__test_at_least_one(model, column_name) %}\n\nselect *\nfrom (\n    select\n        {# In TSQL, subquery aggregate columns need aliases #}\n        {# thus: a filler col name, 'filler_column' #}\n      count({{ column_name }}) as filler_column\n\n    from {{ model }}\n\n    having count({{ column_name }}) = 0\n\n) validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4504042}, "macro.dbt_utils.test_unique_combination_of_columns": {"unique_id": "macro.dbt_utils.test_unique_combination_of_columns", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/unique_combination_of_columns.sql", "original_file_path": "macros/schema_tests/unique_combination_of_columns.sql", "name": "test_unique_combination_of_columns", "macro_sql": "{% test unique_combination_of_columns(model, combination_of_columns, quote_columns=false) %}\n  {{ return(adapter.dispatch('test_unique_combination_of_columns', 'dbt_utils')(model, combination_of_columns, quote_columns)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_unique_combination_of_columns"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.451575}, "macro.dbt_utils.default__test_unique_combination_of_columns": {"unique_id": "macro.dbt_utils.default__test_unique_combination_of_columns", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/unique_combination_of_columns.sql", "original_file_path": "macros/schema_tests/unique_combination_of_columns.sql", "name": "default__test_unique_combination_of_columns", "macro_sql": "{% macro default__test_unique_combination_of_columns(model, combination_of_columns, quote_columns=false) %}\n\n{% if not quote_columns %}\n    {%- set column_list=combination_of_columns %}\n{% elif quote_columns %}\n    {%- set column_list=[] %}\n        {% for column in combination_of_columns -%}\n            {% set column_list = column_list.append( adapter.quote(column) ) %}\n        {%- endfor %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`quote_columns` argument for unique_combination_of_columns test must be one of [True, False] Got: '\" ~ quote ~\"'.'\"\n    ) }}\n{% endif %}\n\n{%- set columns_csv=column_list | join(', ') %}\n\n\nwith validation_errors as (\n\n    select\n        {{ columns_csv }}\n    from {{ model }}\n    group by {{ columns_csv }}\n    having count(*) > 1\n\n)\n\nselect *\nfrom validation_errors\n\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.452836}, "macro.dbt_utils.test_cardinality_equality": {"unique_id": "macro.dbt_utils.test_cardinality_equality", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/cardinality_equality.sql", "original_file_path": "macros/schema_tests/cardinality_equality.sql", "name": "test_cardinality_equality", "macro_sql": "{% test cardinality_equality(model, column_name, to, field) %}\n    {{ return(adapter.dispatch('test_cardinality_equality', 'dbt_utils')(model, column_name, to, field)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_cardinality_equality"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.453883}, "macro.dbt_utils.default__test_cardinality_equality": {"unique_id": "macro.dbt_utils.default__test_cardinality_equality", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/cardinality_equality.sql", "original_file_path": "macros/schema_tests/cardinality_equality.sql", "name": "default__test_cardinality_equality", "macro_sql": "{% macro default__test_cardinality_equality(model, column_name, to, field) %}\n\n{# T-SQL does not let you use numbers as aliases for columns #}\n{# Thus, no \"GROUP BY 1\" #}\n\nwith table_a as (\nselect\n  {{ column_name }},\n  count(*) as num_rows\nfrom {{ model }}\ngroup by {{ column_name }}\n),\n\ntable_b as (\nselect\n  {{ field }},\n  count(*) as num_rows\nfrom {{ to }}\ngroup by {{ field }}\n),\n\nexcept_a as (\n  select *\n  from table_a\n  {{ dbt_utils.except() }}\n  select *\n  from table_b\n),\n\nexcept_b as (\n  select *\n  from table_b\n  {{ dbt_utils.except() }}\n  select *\n  from table_a\n),\n\nunioned as (\n  select *\n  from except_a\n  union all\n  select *\n  from except_b\n)\n\nselect *\nfrom unioned\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.except"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4545548}, "macro.dbt_utils.test_expression_is_true": {"unique_id": "macro.dbt_utils.test_expression_is_true", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/expression_is_true.sql", "original_file_path": "macros/schema_tests/expression_is_true.sql", "name": "test_expression_is_true", "macro_sql": "{% test expression_is_true(model, expression, column_name=None, condition='1=1') %}\n{# T-SQL has no boolean data type so we use 1=1 which returns TRUE #}\n{# ref https://stackoverflow.com/a/7170753/3842610 #}\n  {{ return(adapter.dispatch('test_expression_is_true', 'dbt_utils')(model, expression, column_name, condition)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_expression_is_true"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4555929}, "macro.dbt_utils.default__test_expression_is_true": {"unique_id": "macro.dbt_utils.default__test_expression_is_true", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/expression_is_true.sql", "original_file_path": "macros/schema_tests/expression_is_true.sql", "name": "default__test_expression_is_true", "macro_sql": "{% macro default__test_expression_is_true(model, expression, column_name, condition) %}\n\nwith meet_condition as (\n    select * from {{ model }} where {{ condition }}\n)\n\nselect\n    *\nfrom meet_condition\n{% if column_name is none %}\nwhere not({{ expression }})\n{%- else %}\nwhere not({{ column_name }} {{ expression }})\n{%- endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.456276}, "macro.dbt_utils.test_not_null_proportion": {"unique_id": "macro.dbt_utils.test_not_null_proportion", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/not_null_proportion.sql", "original_file_path": "macros/schema_tests/not_null_proportion.sql", "name": "test_not_null_proportion", "macro_sql": "{% macro test_not_null_proportion(model) %}\n  {{ return(adapter.dispatch('test_not_null_proportion', 'dbt_utils')(model, **kwargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_not_null_proportion"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.457165}, "macro.dbt_utils.default__test_not_null_proportion": {"unique_id": "macro.dbt_utils.default__test_not_null_proportion", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/not_null_proportion.sql", "original_file_path": "macros/schema_tests/not_null_proportion.sql", "name": "default__test_not_null_proportion", "macro_sql": "{% macro default__test_not_null_proportion(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n{% set at_least = kwargs.get('at_least', kwargs.get('arg')) %}\n{% set at_most = kwargs.get('at_most', kwargs.get('arg', 1)) %}\n\nwith validation as (\n  select\n    sum(case when {{ column_name }} is null then 0 else 1 end) / cast(count(*) as numeric) as not_null_proportion\n  from {{ model }}\n),\nvalidation_errors as (\n  select\n    not_null_proportion\n  from validation\n  where not_null_proportion < {{ at_least }} or not_null_proportion > {{ at_most }}\n)\nselect\n  *\nfrom validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.458169}, "macro.dbt_utils.test_sequential_values": {"unique_id": "macro.dbt_utils.test_sequential_values", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/sequential_values.sql", "original_file_path": "macros/schema_tests/sequential_values.sql", "name": "test_sequential_values", "macro_sql": "{% test sequential_values(model, column_name, interval=1, datepart=None) %}\n\n  {{ return(adapter.dispatch('test_sequential_values', 'dbt_utils')(model, column_name, interval, datepart)) }}\n\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_sequential_values"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.459407}, "macro.dbt_utils.default__test_sequential_values": {"unique_id": "macro.dbt_utils.default__test_sequential_values", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/sequential_values.sql", "original_file_path": "macros/schema_tests/sequential_values.sql", "name": "default__test_sequential_values", "macro_sql": "{% macro default__test_sequential_values(model, column_name, interval=1, datepart=None) %}\n\n{% set previous_column_name = \"previous_\" ~ dbt_utils.slugify(column_name) %}\n\nwith windowed as (\n\n    select\n        {{ column_name }},\n        lag({{ column_name }}) over (\n            order by {{ column_name }}\n        ) as {{ previous_column_name }}\n    from {{ model }}\n),\n\nvalidation_errors as (\n    select\n        *\n    from windowed\n    {% if datepart %}\n    where not(cast({{ column_name }} as {{ dbt_utils.type_timestamp() }})= cast({{ dbt_utils.dateadd(datepart, interval, previous_column_name) }} as {{ dbt_utils.type_timestamp() }}))\n    {% else %}\n    where not({{ column_name }} = {{ previous_column_name }} + {{ interval }})\n    {% endif %}\n)\n\nselect *\nfrom validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.slugify", "macro.dbt_utils.type_timestamp", "macro.dbt_utils.dateadd"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.460609}, "macro.dbt_utils.test_not_null_where": {"unique_id": "macro.dbt_utils.test_not_null_where", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/test_not_null_where.sql", "original_file_path": "macros/schema_tests/test_not_null_where.sql", "name": "test_not_null_where", "macro_sql": "{% test not_null_where(model, column_name) %}\r\n  {%- set deprecation_warning = '\r\n    Warning: `dbt_utils.not_null_where` is no longer supported.\r\n    Starting in dbt v0.20.0, the built-in `not_null` test supports a `where` config.\r\n    ' -%}\r\n  {%- do exceptions.warn(deprecation_warning) -%}\r\n  {{ return(adapter.dispatch('test_not_null_where', 'dbt_utils')(model, column_name)) }}\r\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_not_null_where"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.461518}, "macro.dbt_utils.default__test_not_null_where": {"unique_id": "macro.dbt_utils.default__test_not_null_where", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/test_not_null_where.sql", "original_file_path": "macros/schema_tests/test_not_null_where.sql", "name": "default__test_not_null_where", "macro_sql": "{% macro default__test_not_null_where(model, column_name) %}\r\n  {{ return(test_not_null(model, column_name)) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.test_not_null"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.461859}, "macro.dbt_utils.test_equality": {"unique_id": "macro.dbt_utils.test_equality", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/equality.sql", "original_file_path": "macros/schema_tests/equality.sql", "name": "test_equality", "macro_sql": "{% test equality(model, compare_model, compare_columns=None) %}\n  {{ return(adapter.dispatch('test_equality', 'dbt_utils')(model, compare_model, compare_columns)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_equality"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4631512}, "macro.dbt_utils.default__test_equality": {"unique_id": "macro.dbt_utils.default__test_equality", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/equality.sql", "original_file_path": "macros/schema_tests/equality.sql", "name": "default__test_equality", "macro_sql": "{% macro default__test_equality(model, compare_model, compare_columns=None) %}\n\n{% set set_diff %}\n    count(*) + coalesce(abs(\n        sum(case when which_diff = 'a_minus_b' then 1 else 0 end) -\n        sum(case when which_diff = 'b_minus_a' then 1 else 0 end)\n    ), 0)\n{% endset %}\n\n{#-- Needs to be set at parse time, before we return '' below --#}\n{{ config(fail_calc = set_diff) }}\n\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n{%- if not execute -%}\n    {{ return('') }}\n{% endif %}\n\n-- setup\n{%- do dbt_utils._is_relation(model, 'test_equality') -%}\n\n{#-\nIf the compare_cols arg is provided, we can run this test without querying the\ninformation schema\u00a0\u2014 this allows the model to be an ephemeral model\n-#}\n\n{%- if not compare_columns -%}\n    {%- do dbt_utils._is_ephemeral(model, 'test_equality') -%}\n    {%- set compare_columns = adapter.get_columns_in_relation(model) | map(attribute='quoted') -%}\n{%- endif -%}\n\n{% set compare_cols_csv = compare_columns | join(', ') %}\n\nwith a as (\n\n    select * from {{ model }}\n\n),\n\nb as (\n\n    select * from {{ compare_model }}\n\n),\n\na_minus_b as (\n\n    select {{compare_cols_csv}} from a\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from b\n\n),\n\nb_minus_a as (\n\n    select {{compare_cols_csv}} from b\n    {{ dbt_utils.except() }}\n    select {{compare_cols_csv}} from a\n\n),\n\nunioned as (\n\n    select 'a_minus_b' as which_diff, a_minus_b.* from a_minus_b\n    union all\n    select 'b_minus_a' as which_diff, b_minus_a.* from b_minus_a\n\n)\n\nselect * from unioned\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils._is_relation", "macro.dbt_utils._is_ephemeral", "macro.dbt_utils.except"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.464843}, "macro.dbt_utils.test_mutually_exclusive_ranges": {"unique_id": "macro.dbt_utils.test_mutually_exclusive_ranges", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/mutually_exclusive_ranges.sql", "original_file_path": "macros/schema_tests/mutually_exclusive_ranges.sql", "name": "test_mutually_exclusive_ranges", "macro_sql": "{% test mutually_exclusive_ranges(model, lower_bound_column, upper_bound_column, partition_by=None, gaps='allowed', zero_length_range_allowed=False) %}\n  {{ return(adapter.dispatch('test_mutually_exclusive_ranges', 'dbt_utils')(model, lower_bound_column, upper_bound_column, partition_by, gaps, zero_length_range_allowed)) }}\n{% endtest %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__test_mutually_exclusive_ranges"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.469606}, "macro.dbt_utils.default__test_mutually_exclusive_ranges": {"unique_id": "macro.dbt_utils.default__test_mutually_exclusive_ranges", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/schema_tests/mutually_exclusive_ranges.sql", "original_file_path": "macros/schema_tests/mutually_exclusive_ranges.sql", "name": "default__test_mutually_exclusive_ranges", "macro_sql": "{% macro default__test_mutually_exclusive_ranges(model, lower_bound_column, upper_bound_column, partition_by=None, gaps='allowed', zero_length_range_allowed=False) %}\n{% if gaps == 'not_allowed' %}\n    {% set allow_gaps_operator='=' %}\n    {% set allow_gaps_operator_in_words='equal_to' %}\n{% elif gaps == 'allowed' %}\n    {% set allow_gaps_operator='<=' %}\n    {% set allow_gaps_operator_in_words='less_than_or_equal_to' %}\n{% elif gaps == 'required' %}\n    {% set allow_gaps_operator='<' %}\n    {% set allow_gaps_operator_in_words='less_than' %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`gaps` argument for mutually_exclusive_ranges test must be one of ['not_allowed', 'allowed', 'required'] Got: '\" ~ gaps ~\"'.'\"\n    ) }}\n{% endif %}\n{% if not zero_length_range_allowed %}\n    {% set allow_zero_length_operator='<' %}\n    {% set allow_zero_length_operator_in_words='less_than' %}\n{% elif zero_length_range_allowed %}\n    {% set allow_zero_length_operator='<=' %}\n    {% set allow_zero_length_operator_in_words='less_than_or_equal_to' %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\n        \"`zero_length_range_allowed` argument for mutually_exclusive_ranges test must be one of [true, false] Got: '\" ~ zero_length_range_allowed ~\"'.'\"\n    ) }}\n{% endif %}\n\n{% set partition_clause=\"partition by \" ~ partition_by if partition_by else '' %}\n\nwith window_functions as (\n\n    select\n        {% if partition_by %}\n        {{ partition_by }} as partition_by_col,\n        {% endif %}\n        {{ lower_bound_column }} as lower_bound,\n        {{ upper_bound_column }} as upper_bound,\n\n        lead({{ lower_bound_column }}) over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }}\n        ) as next_lower_bound,\n\n        row_number() over (\n            {{ partition_clause }}\n            order by {{ lower_bound_column }} desc\n        ) = 1 as is_last_record\n\n    from {{ model }}\n\n),\n\ncalc as (\n    -- We want to return records where one of our assumptions fails, so we'll use\n    -- the `not` function with `and` statements so we can write our assumptions nore cleanly\n    select\n        *,\n\n        -- For each record: lower_bound should be < upper_bound.\n        -- Coalesce it to return an error on the null case (implicit assumption\n        -- these columns are not_null)\n        coalesce(\n            lower_bound {{ allow_zero_length_operator }} upper_bound,\n            false\n        ) as lower_bound_{{ allow_zero_length_operator_in_words }}_upper_bound,\n\n        -- For each record: upper_bound {{ allow_gaps_operator }} the next lower_bound.\n        -- Coalesce it to handle null cases for the last record.\n        coalesce(\n            upper_bound {{ allow_gaps_operator }} next_lower_bound,\n            is_last_record,\n            false\n        ) as upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n\n    from window_functions\n\n),\n\nvalidation_errors as (\n\n    select\n        *\n    from calc\n\n    where not(\n        -- THE FOLLOWING SHOULD BE TRUE --\n        lower_bound_{{ allow_zero_length_operator_in_words }}_upper_bound\n        and upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\n    )\n)\n\nselect * from validation_errors\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.472754}, "macro.dbt_utils.get_intervals_between": {"unique_id": "macro.dbt_utils.get_intervals_between", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/date_spine.sql", "original_file_path": "macros/sql/date_spine.sql", "name": "get_intervals_between", "macro_sql": "{% macro get_intervals_between(start_date, end_date, datepart) -%}\n    {{ return(adapter.dispatch('get_intervals_between', 'dbt_utils')(start_date, end_date, datepart)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_intervals_between"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.474035}, "macro.dbt_utils.default__get_intervals_between": {"unique_id": "macro.dbt_utils.default__get_intervals_between", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/date_spine.sql", "original_file_path": "macros/sql/date_spine.sql", "name": "default__get_intervals_between", "macro_sql": "{% macro default__get_intervals_between(start_date, end_date, datepart) -%}\n    {%- call statement('get_intervals_between', fetch_result=True) %}\n\n        select {{dbt_utils.datediff(start_date, end_date, datepart)}}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_intervals_between') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values[0]) }}\n    {%- else -%}\n        {{ return(1) }}\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_utils.datediff"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.475189}, "macro.dbt_utils.date_spine": {"unique_id": "macro.dbt_utils.date_spine", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/date_spine.sql", "original_file_path": "macros/sql/date_spine.sql", "name": "date_spine", "macro_sql": "{% macro date_spine(datepart, start_date, end_date) %}\n    {{ return(adapter.dispatch('date_spine', 'dbt_utils')(datepart, start_date, end_date)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__date_spine"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.475647}, "macro.dbt_utils.default__date_spine": {"unique_id": "macro.dbt_utils.default__date_spine", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/date_spine.sql", "original_file_path": "macros/sql/date_spine.sql", "name": "default__date_spine", "macro_sql": "{% macro default__date_spine(datepart, start_date, end_date) %}\n\n\n{# call as follows:\n\ndate_spine(\n    \"day\",\n    \"to_date('01/01/2016', 'mm/dd/yyyy')\",\n    \"dateadd(week, 1, current_date)\"\n) #}\n\n\nwith rawdata as (\n\n    {{dbt_utils.generate_series(\n        dbt_utils.get_intervals_between(start_date, end_date, datepart)\n    )}}\n\n),\n\nall_periods as (\n\n    select (\n        {{\n            dbt_utils.dateadd(\n                datepart,\n                \"row_number() over (order by 1) - 1\",\n                start_date\n            )\n        }}\n    ) as date_{{datepart}}\n    from rawdata\n\n),\n\nfiltered as (\n\n    select *\n    from all_periods\n    where date_{{datepart}} <= {{ end_date }}\n\n)\n\nselect * from filtered\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.generate_series", "macro.dbt_utils.get_intervals_between", "macro.dbt_utils.dateadd"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.476348}, "macro.dbt_utils.nullcheck_table": {"unique_id": "macro.dbt_utils.nullcheck_table", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/nullcheck_table.sql", "original_file_path": "macros/sql/nullcheck_table.sql", "name": "nullcheck_table", "macro_sql": "{% macro nullcheck_table(relation) %}\n    {{ return(adapter.dispatch('nullcheck_table', 'dbt_utils')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__nullcheck_table"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4770932}, "macro.dbt_utils.default__nullcheck_table": {"unique_id": "macro.dbt_utils.default__nullcheck_table", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/nullcheck_table.sql", "original_file_path": "macros/sql/nullcheck_table.sql", "name": "default__nullcheck_table", "macro_sql": "{% macro default__nullcheck_table(relation) %}\n\n  {%- do dbt_utils._is_relation(relation, 'nullcheck_table') -%}\n  {%- do dbt_utils._is_ephemeral(relation, 'nullcheck_table') -%}\n  {% set cols = adapter.get_columns_in_relation(relation) %}\n\n  select {{ dbt_utils.nullcheck(cols) }}\n  from {{relation}}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils._is_relation", "macro.dbt_utils._is_ephemeral", "macro.dbt_utils.nullcheck"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.477791}, "macro.dbt_utils.get_relations_by_pattern": {"unique_id": "macro.dbt_utils.get_relations_by_pattern", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_relations_by_pattern.sql", "original_file_path": "macros/sql/get_relations_by_pattern.sql", "name": "get_relations_by_pattern", "macro_sql": "{% macro get_relations_by_pattern(schema_pattern, table_pattern, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_relations_by_pattern', 'dbt_utils')(schema_pattern, table_pattern, exclude, database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_relations_by_pattern"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.479064}, "macro.dbt_utils.default__get_relations_by_pattern": {"unique_id": "macro.dbt_utils.default__get_relations_by_pattern", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_relations_by_pattern.sql", "original_file_path": "macros/sql/get_relations_by_pattern.sql", "name": "default__get_relations_by_pattern", "macro_sql": "{% macro default__get_relations_by_pattern(schema_pattern, table_pattern, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(\n                database=database,\n                schema=row.table_schema,\n                identifier=row.table_name,\n                type=row.table_type\n            ) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_utils.get_tables_by_pattern_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.480722}, "macro.dbt_utils.get_powers_of_two": {"unique_id": "macro.dbt_utils.get_powers_of_two", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/generate_series.sql", "original_file_path": "macros/sql/generate_series.sql", "name": "get_powers_of_two", "macro_sql": "{% macro get_powers_of_two(upper_bound) %}\n    {{ return(adapter.dispatch('get_powers_of_two', 'dbt_utils')(upper_bound)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_powers_of_two"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.48227}, "macro.dbt_utils.default__get_powers_of_two": {"unique_id": "macro.dbt_utils.default__get_powers_of_two", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/generate_series.sql", "original_file_path": "macros/sql/generate_series.sql", "name": "default__get_powers_of_two", "macro_sql": "{% macro default__get_powers_of_two(upper_bound) %}\n\n    {% if upper_bound <= 0 %}\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\n    {% endif %}\n\n    {% for _ in range(1, 100) %}\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\n    {% endfor %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.483087}, "macro.dbt_utils.generate_series": {"unique_id": "macro.dbt_utils.generate_series", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/generate_series.sql", "original_file_path": "macros/sql/generate_series.sql", "name": "generate_series", "macro_sql": "{% macro generate_series(upper_bound) %}\n    {{ return(adapter.dispatch('generate_series', 'dbt_utils')(upper_bound)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__generate_series"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4835851}, "macro.dbt_utils.default__generate_series": {"unique_id": "macro.dbt_utils.default__generate_series", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/generate_series.sql", "original_file_path": "macros/sql/generate_series.sql", "name": "default__generate_series", "macro_sql": "{% macro default__generate_series(upper_bound) %}\n\n    {% set n = dbt_utils.get_powers_of_two(upper_bound) %}\n\n    with p as (\n        select 0 as generated_number union all select 1\n    ), unioned as (\n\n    select\n\n    {% for i in range(n) %}\n    p{{i}}.generated_number * power(2, {{i}})\n    {% if not loop.last %} + {% endif %}\n    {% endfor %}\n    + 1\n    as generated_number\n\n    from\n\n    {% for i in range(n) %}\n    p as p{{i}}\n    {% if not loop.last %} cross join {% endif %}\n    {% endfor %}\n\n    )\n\n    select *\n    from unioned\n    where generated_number <= {{upper_bound}}\n    order by generated_number\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.get_powers_of_two"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.484607}, "macro.dbt_utils.get_relations_by_prefix": {"unique_id": "macro.dbt_utils.get_relations_by_prefix", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_relations_by_prefix.sql", "original_file_path": "macros/sql/get_relations_by_prefix.sql", "name": "get_relations_by_prefix", "macro_sql": "{% macro get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_relations_by_prefix', 'dbt_utils')(schema, prefix, exclude, database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_relations_by_prefix"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4858902}, "macro.dbt_utils.default__get_relations_by_prefix": {"unique_id": "macro.dbt_utils.default__get_relations_by_prefix", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_relations_by_prefix.sql", "original_file_path": "macros/sql/get_relations_by_prefix.sql", "name": "default__get_relations_by_prefix", "macro_sql": "{% macro default__get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\n\n    {%- call statement('get_tables', fetch_result=True) %}\n\n      {{ dbt_utils.get_tables_by_prefix_sql(schema, prefix, exclude, database) }}\n\n    {%- endcall -%}\n\n    {%- set table_list = load_result('get_tables') -%}\n\n    {%- if table_list and table_list['table'] -%}\n        {%- set tbl_relations = [] -%}\n        {%- for row in table_list['table'] -%}\n            {%- set tbl_relation = api.Relation.create(\n                database=database,\n                schema=row.table_schema,\n                identifier=row.table_name,\n                type=row.table_type\n            ) -%}\n            {%- do tbl_relations.append(tbl_relation) -%}\n        {%- endfor -%}\n\n        {{ return(tbl_relations) }}\n    {%- else -%}\n        {{ return([]) }}\n    {%- endif -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement", "macro.dbt_utils.get_tables_by_prefix_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.487544}, "macro.dbt_utils.get_tables_by_prefix_sql": {"unique_id": "macro.dbt_utils.get_tables_by_prefix_sql", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_tables_by_prefix_sql.sql", "original_file_path": "macros/sql/get_tables_by_prefix_sql.sql", "name": "get_tables_by_prefix_sql", "macro_sql": "{% macro get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_tables_by_prefix_sql', 'dbt_utils')(schema, prefix, exclude, database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_tables_by_prefix_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4884338}, "macro.dbt_utils.default__get_tables_by_prefix_sql": {"unique_id": "macro.dbt_utils.default__get_tables_by_prefix_sql", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_tables_by_prefix_sql.sql", "original_file_path": "macros/sql/get_tables_by_prefix_sql.sql", "name": "default__get_tables_by_prefix_sql", "macro_sql": "{% macro default__get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\n\n    {{ dbt_utils.get_tables_by_pattern_sql(\n        schema_pattern = schema,\n        table_pattern = prefix ~ '%',\n        exclude = exclude,\n        database = database\n    ) }}\n    \n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.get_tables_by_pattern_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.4889941}, "macro.dbt_utils.star": {"unique_id": "macro.dbt_utils.star", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/star.sql", "original_file_path": "macros/sql/star.sql", "name": "star", "macro_sql": "{% macro star(from, relation_alias=False, except=[], prefix='', suffix='') -%}\n    {{ return(adapter.dispatch('star', 'dbt_utils')(from, relation_alias, except, prefix, suffix)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__star"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.490999}, "macro.dbt_utils.default__star": {"unique_id": "macro.dbt_utils.default__star", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/star.sql", "original_file_path": "macros/sql/star.sql", "name": "default__star", "macro_sql": "{% macro default__star(from, relation_alias=False, except=[], prefix='', suffix='') -%}\n    {%- do dbt_utils._is_relation(from, 'star') -%}\n    {%- do dbt_utils._is_ephemeral(from, 'star') -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return('') }}\n    {% endif %}\n\n    {%- set include_cols = [] %}\n    {%- set cols = adapter.get_columns_in_relation(from) -%}\n    {%- set except = except | map(\"lower\") | list %}\n    {%- for col in cols -%}\n\n        {%- if col.column|lower not in except -%}\n            {% do include_cols.append(col.column) %}\n\n        {%- endif %}\n    {%- endfor %}\n\n    {%- for col in include_cols %}\n\n        {%- if relation_alias %}{{ relation_alias }}.{% else %}{%- endif -%}{{ adapter.quote(col)|trim }} {%- if prefix!='' or suffix!='' -%} as {{ adapter.quote(prefix ~ col ~ suffix)|trim }} {%- endif -%}\n        {%- if not loop.last %},{{ '\\n  ' }}{% endif %}\n\n    {%- endfor -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils._is_relation", "macro.dbt_utils._is_ephemeral"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.49336}, "macro.dbt_utils.unpivot": {"unique_id": "macro.dbt_utils.unpivot", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/unpivot.sql", "original_file_path": "macros/sql/unpivot.sql", "name": "unpivot", "macro_sql": "{% macro unpivot(relation=none, cast_to='varchar', exclude=none, remove=none, field_name='field_name', value_name='value', table=none) -%}\n    {{ return(adapter.dispatch('unpivot', 'dbt_utils')(relation, cast_to, exclude, remove, field_name, value_name, table)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__unpivot"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.496268}, "macro.dbt_utils.default__unpivot": {"unique_id": "macro.dbt_utils.default__unpivot", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/unpivot.sql", "original_file_path": "macros/sql/unpivot.sql", "name": "default__unpivot", "macro_sql": "{% macro default__unpivot(relation=none, cast_to='varchar', exclude=none, remove=none, field_name='field_name', value_name='value', table=none) -%}\n\n    {% if table %}\n        {%- set error_message = '\n            Warning: the `unpivot` macro no longer accepts a `table` parameter. \\\n            This parameter will be deprecated in a future release of dbt-utils. Use the `relation` parameter instead. \\\n            The {}.{} model triggered this warning. \\\n            '.format(model.package_name, model.name) -%}\n        {%- do exceptions.warn(error_message) -%}\n    {% endif %}\n\n    {% if relation and table %}\n        {{ exceptions.raise_compiler_error(\"Error: both the `relation` and `table` parameters were provided to `unpivot` macro. Choose one only (we recommend `relation`).\") }}\n    {% elif not relation and table %}\n        {% set relation=table %}\n    {% elif not relation and not table %}\n        {{ exceptions.raise_compiler_error(\"Error: argument `relation` is required for `unpivot` macro.\") }}\n    {% endif %}\n\n  {%- set exclude = exclude if exclude is not none else [] %}\n  {%- set remove = remove if remove is not none else [] %}\n\n  {%- set include_cols = [] %}\n\n  {%- set table_columns = {} %}\n\n  {%- do table_columns.update({relation: []}) %}\n\n  {%- do dbt_utils._is_relation(relation, 'unpivot') -%}\n  {%- do dbt_utils._is_ephemeral(relation, 'unpivot') -%}\n  {%- set cols = adapter.get_columns_in_relation(relation) %}\n\n  {%- for col in cols -%}\n    {%- if col.column.lower() not in remove|map('lower') and col.column.lower() not in exclude|map('lower') -%}\n      {% do include_cols.append(col) %}\n    {%- endif %}\n  {%- endfor %}\n\n\n  {%- for col in include_cols -%}\n    select\n      {%- for exclude_col in exclude %}\n        {{ exclude_col }},\n      {%- endfor %}\n\n      cast('{{ col.column }}' as {{ dbt_utils.type_string() }}) as {{ field_name }},\n      cast(  {% if col.data_type == 'boolean' %}\n           {{ dbt_utils.cast_bool_to_text(col.column) }}\n             {% else %}\n           {{ col.column }}\n             {% endif %}\n           as {{ cast_to }}) as {{ value_name }}\n\n    from {{ relation }}\n\n    {% if not loop.last -%}\n      union all\n    {% endif -%}\n  {%- endfor -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils._is_relation", "macro.dbt_utils._is_ephemeral", "macro.dbt_utils.type_string", "macro.dbt_utils.cast_bool_to_text"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5003362}, "macro.dbt_utils.union_relations": {"unique_id": "macro.dbt_utils.union_relations", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/union.sql", "original_file_path": "macros/sql/union.sql", "name": "union_relations", "macro_sql": "{%- macro union_relations(relations, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_relation') -%}\n    {{ return(adapter.dispatch('union_relations', 'dbt_utils')(relations, column_override, include, exclude, source_column_name)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__union_relations"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.504024}, "macro.dbt_utils.default__union_relations": {"unique_id": "macro.dbt_utils.default__union_relations", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/union.sql", "original_file_path": "macros/sql/union.sql", "name": "default__union_relations", "macro_sql": "\n\n{%- macro default__union_relations(relations, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_relation') -%}\n\n    {%- if exclude and include -%}\n        {{ exceptions.raise_compiler_error(\"Both an exclude and include list were provided to the `union` macro. Only one is allowed\") }}\n    {%- endif -%}\n\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. -#}\n    {%- if not execute %}\n        {{ return('') }}\n    {% endif -%}\n\n    {%- set column_override = column_override if column_override is not none else {} -%}\n\n    {%- set relation_columns = {} -%}\n    {%- set column_superset = {} -%}\n\n    {%- for relation in relations -%}\n\n        {%- do relation_columns.update({relation: []}) -%}\n\n        {%- do dbt_utils._is_relation(relation, 'union_relations') -%}\n        {%- do dbt_utils._is_ephemeral(relation, 'union_relations') -%}\n        {%- set cols = adapter.get_columns_in_relation(relation) -%}\n        {%- for col in cols -%}\n\n        {#- If an exclude list was provided and the column is in the list, do nothing -#}\n        {%- if exclude and col.column in exclude -%}\n\n        {#- If an include list was provided and the column is not in the list, do nothing -#}\n        {%- elif include and col.column not in include -%}\n\n        {#- Otherwise add the column to the column superset -#}\n        {%- else -%}\n\n            {#- update the list of columns in this relation -#}\n            {%- do relation_columns[relation].append(col.column) -%}\n\n            {%- if col.column in column_superset -%}\n\n                {%- set stored = column_superset[col.column] -%}\n                {%- if col.is_string() and stored.is_string() and col.string_size() > stored.string_size() -%}\n\n                    {%- do column_superset.update({col.column: col}) -%}\n\n                {%- endif %}\n\n            {%- else -%}\n\n                {%- do column_superset.update({col.column: col}) -%}\n\n            {%- endif -%}\n\n        {%- endif -%}\n\n        {%- endfor -%}\n    {%- endfor -%}\n\n    {%- set ordered_column_names = column_superset.keys() -%}\n\n    {% if (include | length > 0 or exclude | length > 0) and not column_superset.keys() %}\n        {%- set relations_string -%}\n            {%- for relation in relations -%}\n                {{ relation.name }}\n            {%- if not loop.last %}, {% endif -%}\n            {%- endfor -%}\n        {%- endset -%}\n\n        {%- set error_message -%}\n            There were no columns found to union for relations {{ relations_string }}\n        {%- endset -%}\n\n        {{ exceptions.raise_compiler_error(error_message) }}\n    {%- endif -%}\n\n    {%- for relation in relations %}\n\n        (\n            select\n\n                cast({{ dbt_utils.string_literal(relation) }} as {{ dbt_utils.type_string() }}) as {{ source_column_name }},\n                {% for col_name in ordered_column_names -%}\n\n                    {%- set col = column_superset[col_name] %}\n                    {%- set col_type = column_override.get(col.column, col.data_type) %}\n                    {%- set col_name = adapter.quote(col_name) if col_name in relation_columns[relation] else 'null' %}\n                    cast({{ col_name }} as {{ col_type }}) as {{ col.quoted }} {% if not loop.last %},{% endif -%}\n\n                {%- endfor %}\n\n            from {{ relation }}\n        )\n\n        {% if not loop.last -%}\n            union all\n        {% endif -%}\n\n    {%- endfor -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils._is_relation", "macro.dbt_utils._is_ephemeral", "macro.dbt_utils.string_literal", "macro.dbt_utils.type_string"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.509558}, "macro.dbt_utils.group_by": {"unique_id": "macro.dbt_utils.group_by", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/groupby.sql", "original_file_path": "macros/sql/groupby.sql", "name": "group_by", "macro_sql": "{%- macro group_by(n) -%}\n    {{ return(adapter.dispatch('group_by', 'dbt_utils')(n)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__group_by"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5102599}, "macro.dbt_utils.default__group_by": {"unique_id": "macro.dbt_utils.default__group_by", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/groupby.sql", "original_file_path": "macros/sql/groupby.sql", "name": "default__group_by", "macro_sql": "\n\n{%- macro default__group_by(n) -%}\n\n  group by {% for i in range(1, n + 1) -%}\n      {{ i }}{{ ',' if not loop.last }}   \n   {%- endfor -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.510753}, "macro.dbt_utils.surrogate_key": {"unique_id": "macro.dbt_utils.surrogate_key", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/surrogate_key.sql", "original_file_path": "macros/sql/surrogate_key.sql", "name": "surrogate_key", "macro_sql": "{%- macro surrogate_key(field_list) -%}\n    {# needed for safe_add to allow for non-keyword arguments see SO post #}\n    {# https://stackoverflow.com/questions/13944751/args-kwargs-in-jinja2-macros #}\n    {% set frustrating_jinja_feature = varargs %}\n    {{ return(adapter.dispatch('surrogate_key', 'dbt_utils')(field_list, *varargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__surrogate_key"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.51189}, "macro.dbt_utils.default__surrogate_key": {"unique_id": "macro.dbt_utils.default__surrogate_key", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/surrogate_key.sql", "original_file_path": "macros/sql/surrogate_key.sql", "name": "default__surrogate_key", "macro_sql": "\n\n{%- macro default__surrogate_key(field_list) -%}\n\n{%- if varargs|length >= 1 or field_list is string %}\n\n{%- set error_message = '\nWarning: the `surrogate_key` macro now takes a single list argument instead of \\\nmultiple string arguments. Support for multiple string arguments will be \\\ndeprecated in a future release of dbt-utils. The {}.{} model triggered this warning. \\\n'.format(model.package_name, model.name) -%}\n\n{%- do exceptions.warn(error_message) -%}\n\n{# first argument is not included in varargs, so add first element to field_list_xf #}\n{%- set field_list_xf = [field_list] -%}\n\n{%- for field in varargs %}\n{%- set _ = field_list_xf.append(field) -%}\n{%- endfor -%}\n\n{%- else -%}\n\n{# if using list, just set field_list_xf as field_list #}\n{%- set field_list_xf = field_list -%}\n\n{%- endif -%}\n\n\n{%- set fields = [] -%}\n\n{%- for field in field_list_xf -%}\n\n    {%- set _ = fields.append(\n        \"coalesce(cast(\" ~ field ~ \" as \" ~ dbt_utils.type_string() ~ \"), '')\"\n    ) -%}\n\n    {%- if not loop.last %}\n        {%- set _ = fields.append(\"'-'\") -%}\n    {%- endif -%}\n\n{%- endfor -%}\n\n{{dbt_utils.hash(dbt_utils.concat(fields))}}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_string", "macro.dbt_utils.hash", "macro.dbt_utils.concat"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.513862}, "macro.dbt_utils.safe_add": {"unique_id": "macro.dbt_utils.safe_add", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/safe_add.sql", "original_file_path": "macros/sql/safe_add.sql", "name": "safe_add", "macro_sql": "{%- macro safe_add() -%}\n    {# needed for safe_add to allow for non-keyword arguments see SO post #}\n    {# https://stackoverflow.com/questions/13944751/args-kwargs-in-jinja2-macros #}\n    {% set frustrating_jinja_feature = varargs %}\n    {{ return(adapter.dispatch('safe_add', 'dbt_utils')(*varargs)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__safe_add"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.514712}, "macro.dbt_utils.default__safe_add": {"unique_id": "macro.dbt_utils.default__safe_add", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/safe_add.sql", "original_file_path": "macros/sql/safe_add.sql", "name": "default__safe_add", "macro_sql": "\n\n{%- macro default__safe_add() -%}\n\n{% set fields = [] %}\n\n{%- for field in varargs -%}\n\n    {% do fields.append(\"coalesce(\" ~ field ~ \", 0)\") %}\n\n{%- endfor -%}\n\n{{ fields|join(' +\\n  ') }}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.515284}, "macro.dbt_utils.nullcheck": {"unique_id": "macro.dbt_utils.nullcheck", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/nullcheck.sql", "original_file_path": "macros/sql/nullcheck.sql", "name": "nullcheck", "macro_sql": "{% macro nullcheck(cols) %}\n    {{ return(adapter.dispatch('nullcheck', 'dbt_utils')(cols)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__nullcheck"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.516046}, "macro.dbt_utils.default__nullcheck": {"unique_id": "macro.dbt_utils.default__nullcheck", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/nullcheck.sql", "original_file_path": "macros/sql/nullcheck.sql", "name": "default__nullcheck", "macro_sql": "{% macro default__nullcheck(cols) %}\n{%- for col in cols %}\n\n    {% if col.is_string() -%}\n\n    nullif({{col.name}},'') as {{col.name}}\n\n    {%- else -%}\n\n    {{col.name}}\n\n    {%- endif -%}\n\n{%- if not loop.last -%} , {%- endif -%}\n\n{%- endfor -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.516712}, "macro.dbt_utils.get_tables_by_pattern_sql": {"unique_id": "macro.dbt_utils.get_tables_by_pattern_sql", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_tables_by_pattern_sql.sql", "original_file_path": "macros/sql/get_tables_by_pattern_sql.sql", "name": "get_tables_by_pattern_sql", "macro_sql": "{% macro get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\n    {{ return(adapter.dispatch('get_tables_by_pattern_sql', 'dbt_utils')\n        (schema_pattern, table_pattern, exclude, database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_tables_by_pattern_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.519381}, "macro.dbt_utils.default__get_tables_by_pattern_sql": {"unique_id": "macro.dbt_utils.default__get_tables_by_pattern_sql", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_tables_by_pattern_sql.sql", "original_file_path": "macros/sql/get_tables_by_pattern_sql.sql", "name": "default__get_tables_by_pattern_sql", "macro_sql": "{% macro default__get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\n\n        select distinct\n            table_schema as \"table_schema\",\n            table_name as \"table_name\",\n            {{ dbt_utils.get_table_types_sql() }}\n        from {{ database }}.information_schema.tables\n        where table_schema ilike '{{ schema_pattern }}'\n        and table_name ilike '{{ table_pattern }}'\n        and table_name not ilike '{{ exclude }}'\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.get_table_types_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.519926}, "macro.dbt_utils.bigquery__get_tables_by_pattern_sql": {"unique_id": "macro.dbt_utils.bigquery__get_tables_by_pattern_sql", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_tables_by_pattern_sql.sql", "original_file_path": "macros/sql/get_tables_by_pattern_sql.sql", "name": "bigquery__get_tables_by_pattern_sql", "macro_sql": "{% macro bigquery__get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\n\n    {% if '%' in schema_pattern %}\n        {% set schemata=dbt_utils._bigquery__get_matching_schemata(schema_pattern, database) %}\n    {% else %}\n        {% set schemata=[schema_pattern] %}\n    {% endif %}\n\n    {% set sql %}\n        {% for schema in schemata %}\n            select distinct\n                table_schema,\n                table_name,\n                case table_type\n                    when 'BASE TABLE' then 'table'\n                    else lower(table_type)\n                end as table_type\n\n            from {{ adapter.quote(database) }}.{{ schema }}.INFORMATION_SCHEMA.TABLES\n            where lower(table_name) like lower ('{{ table_pattern }}')\n                and lower(table_name) not like lower ('{{ exclude }}')\n\n            {% if not loop.last %} union all {% endif %}\n\n        {% endfor %}\n    {% endset %}\n\n    {{ return(sql) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils._bigquery__get_matching_schemata"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.521281}, "macro.dbt_utils._bigquery__get_matching_schemata": {"unique_id": "macro.dbt_utils._bigquery__get_matching_schemata", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_tables_by_pattern_sql.sql", "original_file_path": "macros/sql/get_tables_by_pattern_sql.sql", "name": "_bigquery__get_matching_schemata", "macro_sql": "{% macro _bigquery__get_matching_schemata(schema_pattern, database) %}\n    {% if execute %}\n\n        {% set sql %}\n        select schema_name from {{ adapter.quote(database) }}.INFORMATION_SCHEMA.SCHEMATA\n        where lower(schema_name) like lower('{{ schema_pattern }}')\n        {% endset %}\n\n        {% set results=run_query(sql) %}\n\n        {% set schemata=results.columns['schema_name'].values() %}\n\n        {{ return(schemata) }}\n\n    {% else %}\n\n        {{ return([]) }}\n\n    {% endif %}\n\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.run_query"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.522291}, "macro.dbt_utils.get_column_values": {"unique_id": "macro.dbt_utils.get_column_values", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_column_values.sql", "original_file_path": "macros/sql/get_column_values.sql", "name": "get_column_values", "macro_sql": "{% macro get_column_values(table, column, order_by='count(*) desc', max_records=none, default=none) -%}\n    {{ return(adapter.dispatch('get_column_values', 'dbt_utils')(table, column, order_by, max_records, default)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_column_values"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.524002}, "macro.dbt_utils.default__get_column_values": {"unique_id": "macro.dbt_utils.default__get_column_values", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_column_values.sql", "original_file_path": "macros/sql/get_column_values.sql", "name": "default__get_column_values", "macro_sql": "{% macro default__get_column_values(table, column, order_by='count(*) desc', max_records=none, default=none) -%}\n{% if default is none %}\n    {% set default = [] %}\n{% endif %}\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\n    {%- if not execute -%}\n        {{ return(default) }}\n    {% endif %}\n\n    {# Not all relations are tables. Renaming for internal clarity without breaking functionality for anyone using named arguments #}\n    {# TODO: Change the method signature in a future 0.x.0 release #}\n    {%- set target_relation = table -%}\n\n    {# adapter.load_relation is a convenience wrapper to avoid building a Relation when we already have one #}\n    {% set relation_exists = (load_relation(target_relation)) is not none %}\n\n    {%- call statement('get_column_values', fetch_result=true) %}\n\n        {%- if not relation_exists and default is none -%}\n\n          {{ exceptions.raise_compiler_error(\"In get_column_values(): relation \" ~ target_relation ~ \" does not exist and no default value was provided.\") }}\n\n        {%- elif not relation_exists and default is not none -%}\n\n          {{ log(\"Relation \" ~ target_relation ~ \" does not exist. Returning the default value: \" ~ default) }}\n\n          {{ return(default) }}\n\n        {%- else -%}\n\n\n            select\n                {{ column }} as value\n\n            from {{ target_relation }}\n            group by {{ column }}\n            order by {{ order_by }}\n\n            {% if max_records is not none %}\n            limit {{ max_records }}\n            {% endif %}\n\n        {% endif %}\n\n    {%- endcall -%}\n\n    {%- set value_list = load_result('get_column_values') -%}\n\n    {%- if value_list and value_list['data'] -%}\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\n        {{ return(values) }}\n    {%- else -%}\n        {{ return(default) }}\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.load_relation", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5268302}, "macro.dbt_utils.pivot": {"unique_id": "macro.dbt_utils.pivot", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/pivot.sql", "original_file_path": "macros/sql/pivot.sql", "name": "pivot", "macro_sql": "{% macro pivot(column,\n               values,\n               alias=True,\n               agg='sum',\n               cmp='=',\n               prefix='',\n               suffix='',\n               then_value=1,\n               else_value=0,\n               quote_identifiers=True,\n               distinct=False) %}\n    {{ return(adapter.dispatch('pivot', 'dbt_utils')(column, values, alias, agg, cmp, prefix, suffix, then_value, else_value, quote_identifiers, distinct)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__pivot"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.528733}, "macro.dbt_utils.default__pivot": {"unique_id": "macro.dbt_utils.default__pivot", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/pivot.sql", "original_file_path": "macros/sql/pivot.sql", "name": "default__pivot", "macro_sql": "{% macro default__pivot(column,\n               values,\n               alias=True,\n               agg='sum',\n               cmp='=',\n               prefix='',\n               suffix='',\n               then_value=1,\n               else_value=0,\n               quote_identifiers=True,\n               distinct=False) %}\n  {% for value in values %}\n    {{ agg }}(\n      {% if distinct %} distinct {% endif %}\n      case\n      when {{ column }} {{ cmp }} '{{ dbt_utils.escape_single_quotes(value) }}'\n        then {{ then_value }}\n      else {{ else_value }}\n      end\n    )\n    {% if alias %}\n      {% if quote_identifiers %}\n            as {{ adapter.quote(prefix ~ value ~ suffix) }}\n      {% else %}\n        as {{ dbt_utils.slugify(prefix ~ value ~ suffix) }}\n      {% endif %}\n    {% endif %}\n    {% if not loop.last %},{% endif %}\n  {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.escape_single_quotes", "macro.dbt_utils.slugify"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5303848}, "macro.dbt_utils.get_query_results_as_dict": {"unique_id": "macro.dbt_utils.get_query_results_as_dict", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_query_results_as_dict.sql", "original_file_path": "macros/sql/get_query_results_as_dict.sql", "name": "get_query_results_as_dict", "macro_sql": "{% macro get_query_results_as_dict(query) %}\n    {{ return(adapter.dispatch('get_query_results_as_dict', 'dbt_utils')(query)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_query_results_as_dict"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5312178}, "macro.dbt_utils.default__get_query_results_as_dict": {"unique_id": "macro.dbt_utils.default__get_query_results_as_dict", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_query_results_as_dict.sql", "original_file_path": "macros/sql/get_query_results_as_dict.sql", "name": "default__get_query_results_as_dict", "macro_sql": "{% macro default__get_query_results_as_dict(query) %}\n\n{# This macro returns a dictionary of the form {column_name: (tuple_of_results)} #}\n\n    {%- call statement('get_query_results', fetch_result=True,auto_begin=false) -%}\n\n        {{ query }}\n\n    {%- endcall -%}\n\n    {% set sql_results={} %}\n\n    {%- if execute -%}\n        {% set sql_results_table = load_result('get_query_results').table.columns %}\n        {% for column_name, column in sql_results_table.items() %}\n            {% do sql_results.update({column_name: column.values()}) %}\n        {% endfor %}\n    {%- endif -%}\n\n    {{ return(sql_results) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.532392}, "macro.dbt_utils.get_table_types_sql": {"unique_id": "macro.dbt_utils.get_table_types_sql", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_table_types_sql.sql", "original_file_path": "macros/sql/get_table_types_sql.sql", "name": "get_table_types_sql", "macro_sql": "{%- macro get_table_types_sql() -%}\n  {{ return(adapter.dispatch('get_table_types_sql', 'dbt_utils')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__get_table_types_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.533157}, "macro.dbt_utils.default__get_table_types_sql": {"unique_id": "macro.dbt_utils.default__get_table_types_sql", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_table_types_sql.sql", "original_file_path": "macros/sql/get_table_types_sql.sql", "name": "default__get_table_types_sql", "macro_sql": "{% macro default__get_table_types_sql() %}\n            case table_type\n                when 'BASE TABLE' then 'table'\n                when 'EXTERNAL TABLE' then 'external'\n                when 'MATERIALIZED VIEW' then 'materializedview'\n                else lower(table_type)\n            end as \"table_type\"\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.533335}, "macro.dbt_utils.postgres__get_table_types_sql": {"unique_id": "macro.dbt_utils.postgres__get_table_types_sql", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/get_table_types_sql.sql", "original_file_path": "macros/sql/get_table_types_sql.sql", "name": "postgres__get_table_types_sql", "macro_sql": "{% macro postgres__get_table_types_sql() %}\n            case table_type\n                when 'BASE TABLE' then 'table'\n                when 'FOREIGN' then 'external'\n                when 'MATERIALIZED VIEW' then 'materializedview'\n                else lower(table_type)\n            end as \"table_type\"\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5335062}, "macro.dbt_utils.degrees_to_radians": {"unique_id": "macro.dbt_utils.degrees_to_radians", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/haversine_distance.sql", "original_file_path": "macros/sql/haversine_distance.sql", "name": "degrees_to_radians", "macro_sql": "{% macro degrees_to_radians(degrees) -%}\n    acos(-1) * {{degrees}} / 180\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.535275}, "macro.dbt_utils.haversine_distance": {"unique_id": "macro.dbt_utils.haversine_distance", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/haversine_distance.sql", "original_file_path": "macros/sql/haversine_distance.sql", "name": "haversine_distance", "macro_sql": "{% macro haversine_distance(lat1, lon1, lat2, lon2, unit='mi') -%}\n    {{ return(adapter.dispatch('haversine_distance', 'dbt_utils')(lat1,lon1,lat2,lon2,unit)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.default__haversine_distance"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.535823}, "macro.dbt_utils.default__haversine_distance": {"unique_id": "macro.dbt_utils.default__haversine_distance", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/haversine_distance.sql", "original_file_path": "macros/sql/haversine_distance.sql", "name": "default__haversine_distance", "macro_sql": "{% macro default__haversine_distance(lat1, lon1, lat2, lon2, unit='mi') -%}\n{%- if unit == 'mi' %}\n    {% set conversion_rate = 1 %}\n{% elif unit == 'km' %}\n    {% set conversion_rate = 1.60934 %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\"unit input must be one of 'mi' or 'km'. Got \" ~ unit) }}\n{% endif %}\n\n    2 * 3961 * asin(sqrt(power((sin(radians(({{ lat2 }} - {{ lat1 }}) / 2))), 2) +\n    cos(radians({{lat1}})) * cos(radians({{lat2}})) *\n    power((sin(radians(({{ lon2 }} - {{ lon1 }}) / 2))), 2))) * {{ conversion_rate }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5370398}, "macro.dbt_utils.bigquery__haversine_distance": {"unique_id": "macro.dbt_utils.bigquery__haversine_distance", "package_name": "dbt_utils", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_utils", "path": "macros/sql/haversine_distance.sql", "original_file_path": "macros/sql/haversine_distance.sql", "name": "bigquery__haversine_distance", "macro_sql": "{% macro bigquery__haversine_distance(lat1, lon1, lat2, lon2, unit='mi') -%}\n{% set radians_lat1 = dbt_utils.degrees_to_radians(lat1) %}\n{% set radians_lat2 = dbt_utils.degrees_to_radians(lat2) %}\n{% set radians_lon1 = dbt_utils.degrees_to_radians(lon1) %}\n{% set radians_lon2 = dbt_utils.degrees_to_radians(lon2) %}\n{%- if unit == 'mi' %}\n    {% set conversion_rate = 1 %}\n{% elif unit == 'km' %}\n    {% set conversion_rate = 1.60934 %}\n{% else %}\n    {{ exceptions.raise_compiler_error(\"unit input must be one of 'mi' or 'km'. Got \" ~ unit) }}\n{% endif %}\n    2 * 3961 * asin(sqrt(power(sin(({{ radians_lat2 }} - {{ radians_lat1 }}) / 2), 2) +\n    cos({{ radians_lat1 }}) * cos({{ radians_lat2 }}) *\n    power(sin(({{ radians_lon2 }} - {{ radians_lon1 }}) / 2), 2))) * {{ conversion_rate }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.degrees_to_radians"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5386188}, "macro.dbt_date.get_date_dimension": {"unique_id": "macro.dbt_date.get_date_dimension", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/get_date_dimension.sql", "original_file_path": "macros/get_date_dimension.sql", "name": "get_date_dimension", "macro_sql": "{% macro get_date_dimension(start_date, end_date) %}\n    {{ adapter.dispatch('get_date_dimension', 'dbt_date') (start_date, end_date) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.default__get_date_dimension"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.55092}, "macro.dbt_date.default__get_date_dimension": {"unique_id": "macro.dbt_date.default__get_date_dimension", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/get_date_dimension.sql", "original_file_path": "macros/get_date_dimension.sql", "name": "default__get_date_dimension", "macro_sql": "{% macro default__get_date_dimension(start_date, end_date) %}\nwith base_dates as (\n    {{ dbt_date.get_base_dates(start_date, end_date) }}\n),\ndates_with_prior_year_dates as (\n\n    select\n        cast(d.date_day as date) as date_day,\n        cast({{ dbt_utils.dateadd('year', -1 , 'd.date_day') }} as date) as prior_year_date_day,\n        cast({{ dbt_utils.dateadd('day', -364 , 'd.date_day') }} as date) as prior_year_over_year_date_day\n    from\n    \tbase_dates d\n\n)\nselect\n    d.date_day,\n    {{ dbt_date.yesterday('d.date_day') }} as prior_date_day,\n    {{ dbt_date.tomorrow('d.date_day') }} as next_date_day,\n    d.prior_year_date_day as prior_year_date_day,\n    d.prior_year_over_year_date_day,\n    {{ dbt_date.day_of_week('d.date_day', isoweek=false) }} as day_of_week,\n    {{ dbt_date.day_of_week('d.date_day', isoweek=true) }} as day_of_week_iso,\n    {{ dbt_date.day_name('d.date_day', short=false) }} as day_of_week_name,\n    {{ dbt_date.day_name('d.date_day', short=true) }} as day_of_week_name_short,\n    {{ dbt_date.day_of_month('d.date_day') }} as day_of_month,\n    {{ dbt_date.day_of_year('d.date_day') }} as day_of_year,\n\n    {{ dbt_date.week_start('d.date_day') }} as week_start_date,\n    {{ dbt_date.week_end('d.date_day') }} as week_end_date,\n    {{ dbt_date.week_start('d.prior_year_over_year_date_day') }} as prior_year_week_start_date,\n    {{ dbt_date.week_end('d.prior_year_over_year_date_day') }} as prior_year_week_end_date,\n    {{ dbt_date.week_of_year('d.date_day') }} as week_of_year,\n\n    {{ dbt_date.iso_week_start('d.date_day') }} as iso_week_start_date,\n    {{ dbt_date.iso_week_end('d.date_day') }} as iso_week_end_date,\n    {{ dbt_date.iso_week_start('d.prior_year_over_year_date_day') }} as prior_year_iso_week_start_date,\n    {{ dbt_date.iso_week_end('d.prior_year_over_year_date_day') }} as prior_year_iso_week_end_date,\n    {{ dbt_date.iso_week_of_year('d.date_day') }} as iso_week_of_year,\n\n    {{ dbt_date.week_of_year('d.prior_year_over_year_date_day') }} as prior_year_week_of_year,\n    {{ dbt_date.iso_week_of_year('d.prior_year_over_year_date_day') }} as prior_year_iso_week_of_year,\n\n    cast({{ dbt_date.date_part('month', 'd.date_day') }} as {{ dbt_utils.type_int() }}) as month_of_year,\n    {{ dbt_date.month_name('d.date_day', short=false) }}  as month_name,\n    {{ dbt_date.month_name('d.date_day', short=true) }}  as month_name_short,\n\n    cast({{ dbt_utils.date_trunc('month', 'd.date_day') }} as date) as month_start_date,\n    cast({{ dbt_utils.last_day('d.date_day', 'month') }} as date) as month_end_date,\n\n    cast({{ dbt_utils.date_trunc('month', 'd.prior_year_date_day') }} as date) as prior_year_month_start_date,\n    cast({{ dbt_utils.last_day('d.prior_year_date_day', 'month') }} as date) as prior_year_month_end_date,\n\n    cast({{ dbt_date.date_part('quarter', 'd.date_day') }} as {{ dbt_utils.type_int() }}) as quarter_of_year,\n    cast({{ dbt_utils.date_trunc('quarter', 'd.date_day') }} as date) as quarter_start_date,\n    cast({{ dbt_utils.last_day('d.date_day', 'quarter') }} as date) as quarter_end_date,\n\n    cast({{ dbt_date.date_part('year', 'd.date_day') }} as {{ dbt_utils.type_int() }}) as year_number,\n    cast({{ dbt_utils.date_trunc('year', 'd.date_day') }} as date) as year_start_date,\n    cast({{ dbt_utils.last_day('d.date_day', 'year') }} as date) as year_end_date\nfrom\n    dates_with_prior_year_dates d\norder by 1\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.get_base_dates", "macro.dbt_utils.dateadd", "macro.dbt_date.yesterday", "macro.dbt_date.tomorrow", "macro.dbt_date.day_of_week", "macro.dbt_date.day_name", "macro.dbt_date.day_of_month", "macro.dbt_date.day_of_year", "macro.dbt_date.week_start", "macro.dbt_date.week_end", "macro.dbt_date.week_of_year", "macro.dbt_date.iso_week_start", "macro.dbt_date.iso_week_end", "macro.dbt_date.iso_week_of_year", "macro.dbt_date.date_part", "macro.dbt_utils.type_int", "macro.dbt_date.month_name", "macro.dbt_utils.date_trunc", "macro.dbt_utils.last_day"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.555584}, "macro.dbt_date.postgres__get_date_dimension": {"unique_id": "macro.dbt_date.postgres__get_date_dimension", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/get_date_dimension.sql", "original_file_path": "macros/get_date_dimension.sql", "name": "postgres__get_date_dimension", "macro_sql": "{% macro postgres__get_date_dimension(start_date, end_date) %}\nwith base_dates as (\n    {{ dbt_date.get_base_dates(start_date, end_date) }}\n),\ndates_with_prior_year_dates as (\n\n    select\n        cast(d.date_day as date) as date_day,\n        cast({{ dbt_utils.dateadd('year', -1 , 'd.date_day') }} as date) as prior_year_date_day,\n        cast({{ dbt_utils.dateadd('day', -364 , 'd.date_day') }} as date) as prior_year_over_year_date_day\n    from\n    \tbase_dates d\n\n)\nselect\n    d.date_day,\n    {{ dbt_date.yesterday('d.date_day') }} as prior_date_day,\n    {{ dbt_date.tomorrow('d.date_day') }} as next_date_day,\n    d.prior_year_date_day as prior_year_date_day,\n    d.prior_year_over_year_date_day,\n    {{ dbt_date.day_of_week('d.date_day', isoweek=true) }} as day_of_week,\n\n    {{ dbt_date.day_name('d.date_day', short=false) }} as day_of_week_name,\n    {{ dbt_date.day_name('d.date_day', short=true) }} as day_of_week_name_short,\n    {{ dbt_date.day_of_month('d.date_day') }} as day_of_month,\n    {{ dbt_date.day_of_year('d.date_day') }} as day_of_year,\n\n    {{ dbt_date.week_start('d.date_day') }} as week_start_date,\n    {{ dbt_date.week_end('d.date_day') }} as week_end_date,\n    {{ dbt_date.week_start('d.prior_year_over_year_date_day') }} as prior_year_week_start_date,\n    {{ dbt_date.week_end('d.prior_year_over_year_date_day') }} as prior_year_week_end_date,\n    {{ dbt_date.week_of_year('d.date_day') }} as week_of_year,\n\n    {{ dbt_date.iso_week_start('d.date_day') }} as iso_week_start_date,\n    {{ dbt_date.iso_week_end('d.date_day') }} as iso_week_end_date,\n    {{ dbt_date.iso_week_start('d.prior_year_over_year_date_day') }} as prior_year_iso_week_start_date,\n    {{ dbt_date.iso_week_end('d.prior_year_over_year_date_day') }} as prior_year_iso_week_end_date,\n    {{ dbt_date.iso_week_of_year('d.date_day') }} as iso_week_of_year,\n\n    {{ dbt_date.week_of_year('d.prior_year_over_year_date_day') }} as prior_year_week_of_year,\n    {{ dbt_date.iso_week_of_year('d.prior_year_over_year_date_day') }} as prior_year_iso_week_of_year,\n\n    cast({{ dbt_date.date_part('month', 'd.date_day') }} as {{ dbt_utils.type_int() }}) as month_of_year,\n    {{ dbt_date.month_name('d.date_day', short=false) }}  as month_name,\n    {{ dbt_date.month_name('d.date_day', short=true) }}  as month_name_short,\n\n    cast({{ dbt_utils.date_trunc('month', 'd.date_day') }} as date) as month_start_date,\n    cast({{ dbt_utils.last_day('d.date_day', 'month') }} as date) as month_end_date,\n\n    cast({{ dbt_utils.date_trunc('month', 'd.prior_year_date_day') }} as date) as prior_year_month_start_date,\n    cast({{ dbt_utils.last_day('d.prior_year_date_day', 'month') }} as date) as prior_year_month_end_date,\n\n    cast({{ dbt_date.date_part('quarter', 'd.date_day') }} as {{ dbt_utils.type_int() }}) as quarter_of_year,\n    cast({{ dbt_utils.date_trunc('quarter', 'd.date_day') }} as date) as quarter_start_date,\n    {# dbt_utils.last_day does not support quarter because postgresql does not support quarter interval. #}\n    cast({{dbt_utils.dateadd('day', '-1', dbt_utils.dateadd('month', '3', dbt_utils.date_trunc('quarter', 'd.date_day')))}} as date) as quarter_end_date,\n\n    cast({{ dbt_date.date_part('year', 'd.date_day') }} as {{ dbt_utils.type_int() }}) as year_number,\n    cast({{ dbt_utils.date_trunc('year', 'd.date_day') }} as date) as year_start_date,\n    cast({{ dbt_utils.last_day('d.date_day', 'year') }} as date) as year_end_date\nfrom\n    dates_with_prior_year_dates d\norder by 1\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.get_base_dates", "macro.dbt_utils.dateadd", "macro.dbt_date.yesterday", "macro.dbt_date.tomorrow", "macro.dbt_date.day_of_week", "macro.dbt_date.day_name", "macro.dbt_date.day_of_month", "macro.dbt_date.day_of_year", "macro.dbt_date.week_start", "macro.dbt_date.week_end", "macro.dbt_date.week_of_year", "macro.dbt_date.iso_week_start", "macro.dbt_date.iso_week_end", "macro.dbt_date.iso_week_of_year", "macro.dbt_date.date_part", "macro.dbt_utils.type_int", "macro.dbt_date.month_name", "macro.dbt_utils.date_trunc", "macro.dbt_utils.last_day"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5601301}, "macro.dbt_date.get_base_dates": {"unique_id": "macro.dbt_date.get_base_dates", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/get_base_dates.sql", "original_file_path": "macros/get_base_dates.sql", "name": "get_base_dates", "macro_sql": "{% macro get_base_dates(start_date=None, end_date=None, n_dateparts=None, datepart=\"day\") %}\n    {{ adapter.dispatch('get_base_dates', 'dbt_date') (start_date, end_date, n_dateparts, datepart) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.default__get_base_dates"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5618958}, "macro.dbt_date.default__get_base_dates": {"unique_id": "macro.dbt_date.default__get_base_dates", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/get_base_dates.sql", "original_file_path": "macros/get_base_dates.sql", "name": "default__get_base_dates", "macro_sql": "{% macro default__get_base_dates(start_date, end_date, n_dateparts, datepart) %}\n\n{%- if start_date and end_date -%}\n{%- set start_date=\"cast('\" ~ start_date ~ \"' as \" ~ dbt_utils.type_timestamp() ~ \")\" -%}\n{%- set end_date=\"cast('\" ~ end_date ~ \"' as \" ~ dbt_utils.type_timestamp() ~ \")\"  -%}\n\n{%- elif n_dateparts and datepart -%}\n\n{%- set start_date = dbt_utils.dateadd(datepart, -1 * n_dateparts, dbt_date.today()) -%}\n{%- set end_date = dbt_date.tomorrow() -%}\n{%- endif -%}\n\nwith date_spine as\n(\n\n    {{ dbt_utils.date_spine(\n        datepart=datepart,\n        start_date=start_date,\n        end_date=end_date,\n       )\n    }}\n\n)\nselect\n    cast(d.date_{{ datepart }} as {{ dbt_utils.type_timestamp() }}) as date_{{ datepart }}\nfrom\n    date_spine d\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp", "macro.dbt_utils.dateadd", "macro.dbt_date.today", "macro.dbt_date.tomorrow", "macro.dbt_utils.date_spine"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.563336}, "macro.dbt_date.bigquery__get_base_dates": {"unique_id": "macro.dbt_date.bigquery__get_base_dates", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/get_base_dates.sql", "original_file_path": "macros/get_base_dates.sql", "name": "bigquery__get_base_dates", "macro_sql": "{% macro bigquery__get_base_dates(start_date, end_date, n_dateparts, datepart) %}\n\n{%- if start_date and end_date -%}\n{%- set start_date=\"cast('\" ~ start_date ~ \"' as date )\" -%}\n{%- set end_date=\"cast('\" ~ end_date ~ \"' as date )\" -%}\n\n{%- elif n_dateparts and datepart -%}\n\n{%- set start_date = dbt_utils.dateadd(datepart, -1 * n_dateparts, dbt_date.today()) -%}\n{%- set end_date = dbt_date.tomorrow() -%}\n{%- endif -%}\n\nwith date_spine as\n(\n\n    {{ dbt_utils.date_spine(\n        datepart=datepart,\n        start_date=start_date,\n        end_date=end_date,\n       )\n    }}\n\n)\nselect\n    cast(d.date_{{ datepart }} as {{ dbt_utils.type_timestamp() }}) as date_{{ datepart }}\nfrom\n    date_spine d\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbt_date.today", "macro.dbt_date.tomorrow", "macro.dbt_utils.date_spine", "macro.dbt_utils.type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.564648}, "macro.dbt_date.get_fiscal_year_dates": {"unique_id": "macro.dbt_date.get_fiscal_year_dates", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/fiscal_date/get_fiscal_year_dates.sql", "original_file_path": "macros/fiscal_date/get_fiscal_year_dates.sql", "name": "get_fiscal_year_dates", "macro_sql": "{% macro get_fiscal_year_dates(dates, year_end_month=12, week_start_day=1, shift_year=1) %}\n{{ adapter.dispatch('get_fiscal_year_dates', 'dbt_date') (dates, year_end_month, week_start_day, shift_year) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.default__get_fiscal_year_dates"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.567209}, "macro.dbt_date.default__get_fiscal_year_dates": {"unique_id": "macro.dbt_date.default__get_fiscal_year_dates", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/fiscal_date/get_fiscal_year_dates.sql", "original_file_path": "macros/fiscal_date/get_fiscal_year_dates.sql", "name": "default__get_fiscal_year_dates", "macro_sql": "{% macro default__get_fiscal_year_dates(dates, year_end_month, week_start_day, shift_year) %}\n-- this gets all the dates within a fiscal year\n-- determined by the given year-end-month\n-- ending on the saturday closest to that month's end date\nwith date_dimension as (\n    select * from {{ dates }}\n),\nyear_month_end as (\n\n    select\n       d.year_number - {{ shift_year }} as fiscal_year_number,\n       d.month_end_date\n    from\n        date_dimension d\n    where\n        d.month_of_year = {{ year_end_month }}\n    group by 1,2\n\n),\nweeks as (\n\n    select\n        d.year_number,\n        d.month_of_year,\n        d.date_day as week_start_date,\n        cast({{ dbt_utils.dateadd('day', 6, 'd.date_day') }} as date) as week_end_date\n    from\n        date_dimension d\n    where\n        d.day_of_week = {{ week_start_day }}\n\n),\n-- get all the weeks that start in the month the year ends\nyear_week_ends as (\n\n    select\n        d.year_number - {{ shift_year }} as fiscal_year_number,\n        d.week_end_date\n    from\n        weeks d\n    where\n        d.month_of_year = {{ year_end_month }}\n    group by\n        1,2\n\n),\n-- then calculate which Saturday is closest to month end\nweeks_at_month_end as (\n\n    select\n        d.fiscal_year_number,\n        d.week_end_date,\n        m.month_end_date,\n        rank() over\n            (partition by d.fiscal_year_number\n                order by\n                abs({{ dbt_utils.datediff('d.week_end_date', 'm.month_end_date', 'day') }})\n\n            ) as closest_to_month_end\n    from\n        year_week_ends d\n        join\n        year_month_end m on d.fiscal_year_number = m.fiscal_year_number\n),\nfiscal_year_range as (\n\n    select\n        w.fiscal_year_number,\n        cast(\n            {{ dbt_utils.dateadd('day', 1,\n            'lag(w.week_end_date) over(order by w.week_end_date)') }}\n            as date) as fiscal_year_start_date,\n        w.week_end_date as fiscal_year_end_date\n    from\n        weeks_at_month_end w\n    where\n        w.closest_to_month_end = 1\n\n),\nfiscal_year_dates as (\n\n    select\n        d.date_day,\n        m.fiscal_year_number,\n        m.fiscal_year_start_date,\n        m.fiscal_year_end_date,\n        w.week_start_date,\n        w.week_end_date,\n        -- we reset the weeks of the year starting with the merch year start date\n        dense_rank()\n            over(\n                partition by m.fiscal_year_number\n                order by w.week_start_date\n                ) as fiscal_week_of_year\n    from\n        date_dimension d\n        join\n        fiscal_year_range m on d.date_day between m.fiscal_year_start_date and m.fiscal_year_end_date\n        join\n        weeks w on d.date_day between w.week_start_date and w.week_end_date\n\n)\nselect * from fiscal_year_dates order by 1\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbt_utils.datediff"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.568289}, "macro.dbt_date.get_fiscal_periods": {"unique_id": "macro.dbt_date.get_fiscal_periods", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/fiscal_date/get_fiscal_periods.sql", "original_file_path": "macros/fiscal_date/get_fiscal_periods.sql", "name": "get_fiscal_periods", "macro_sql": "{% macro get_fiscal_periods(dates, year_end_month, week_start_day, shift_year=1) %}\n{# \nThis macro requires you to pass in a ref to a date dimension, created via\ndbt_date.get_date_dimension()s\n#}\nwith fscl_year_dates_for_periods as (\n    {{ dbt_date.get_fiscal_year_dates(dates, year_end_month, week_start_day, shift_year) }}\n),\nfscl_year_w13 as (\n\n    select\n        f.*,\n        -- We count the weeks in a 13 week period\n        -- and separate the 4-5-4 week sequences\n        mod(cast(\n            (f.fiscal_week_of_year-1) as {{ dbt_utils.type_int() }}\n            ), 13) as w13_number,\n        -- Chop weeks into 13 week merch quarters\n        cast(\n            least(\n                floor((f.fiscal_week_of_year-1)/13.0)\n                , 3)\n            as {{ dbt_utils.type_int() }}) as quarter_number\n    from\n        fscl_year_dates_for_periods f\n\n),\nfscl_periods as (\n\n    select\n        f.date_day,\n        f.fiscal_year_number,\n        f.week_start_date,\n        f.week_end_date,\n        f.fiscal_week_of_year,\n        case \n            -- we move week 53 into the 3rd period of the quarter\n            when f.fiscal_week_of_year = 53 then 3\n            when f.w13_number between 0 and 3 then 1\n            when f.w13_number between 4 and 8 then 2\n            when f.w13_number between 9 and 12 then 3\n        end as period_of_quarter,\n        f.quarter_number\n    from\n        fscl_year_w13 f\n\n),\nfscl_periods_quarters as (\n\n    select\n        f.*,\n        cast((\n            (f.quarter_number * 3) + f.period_of_quarter\n         ) as {{ dbt_utils.type_int() }}) as fiscal_period_number\n    from\n        fscl_periods f\n\n)\nselect\n    date_day,\n    fiscal_year_number,\n    week_start_date,\n    week_end_date,\n    fiscal_week_of_year, \n    dense_rank() over(partition by fiscal_period_number order by fiscal_week_of_year) as fiscal_week_of_period,\n    fiscal_period_number,\n    quarter_number+1 as fiscal_quarter_number,\n    period_of_quarter as fiscal_period_of_quarter\nfrom \n    fscl_periods_quarters \norder by 1,2\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.get_fiscal_year_dates", "macro.dbt_utils.type_int"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.569833}, "macro.dbt_date.tomorrow": {"unique_id": "macro.dbt_date.tomorrow", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/tomorrow.sql", "original_file_path": "macros/calendar_date/tomorrow.sql", "name": "tomorrow", "macro_sql": "{%- macro tomorrow(date=None, tz=None) -%}\n{{ dbt_date.n_days_away(1, date, tz) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.n_days_away"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5704079}, "macro.dbt_date.next_week": {"unique_id": "macro.dbt_date.next_week", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/next_week.sql", "original_file_path": "macros/calendar_date/next_week.sql", "name": "next_week", "macro_sql": "{%- macro next_week(tz=None) -%}\n{{ dbt_date.n_weeks_away(1, tz) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.n_weeks_away"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.570911}, "macro.dbt_date.next_month_name": {"unique_id": "macro.dbt_date.next_month_name", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/next_month_name.sql", "original_file_path": "macros/calendar_date/next_month_name.sql", "name": "next_month_name", "macro_sql": "{%- macro next_month_name(short=True, tz=None) -%}\n{{ dbt_date.month_name(dbt_date.next_month(1, tz), short=short) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.month_name", "macro.dbt_date.next_month"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5715451}, "macro.dbt_date.next_month": {"unique_id": "macro.dbt_date.next_month", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/next_month.sql", "original_file_path": "macros/calendar_date/next_month.sql", "name": "next_month", "macro_sql": "{%- macro next_month(tz=None) -%}\n{{ dbt_date.n_months_away(1, tz) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.n_months_away"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.572047}, "macro.dbt_date.day_name": {"unique_id": "macro.dbt_date.day_name", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_name.sql", "original_file_path": "macros/calendar_date/day_name.sql", "name": "day_name", "macro_sql": "{%- macro day_name(date, short=True) -%}\n    {{ adapter.dispatch('day_name', 'dbt_date') (date, short) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.default__day_name"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.573211}, "macro.dbt_date.default__day_name": {"unique_id": "macro.dbt_date.default__day_name", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_name.sql", "original_file_path": "macros/calendar_date/day_name.sql", "name": "default__day_name", "macro_sql": "\n\n{%- macro default__day_name(date, short) -%}\n{%- set f = 'Dy' if short else 'Day' -%}\n    to_char({{ date }}, '{{ f }}')\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.573616}, "macro.dbt_date.snowflake__day_name": {"unique_id": "macro.dbt_date.snowflake__day_name", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_name.sql", "original_file_path": "macros/calendar_date/day_name.sql", "name": "snowflake__day_name", "macro_sql": "\n\n{%- macro snowflake__day_name(date, short) -%}\n    {%- if short -%}\n    dayname({{ date }})\n    {%- else -%}\n    -- long version not implemented on Snowflake so we're doing it manually :/\n    case dayname({{ date }})\n        when 'Mon' then 'Monday'\n        when 'Tue' then 'Tuesday'\n        when 'Wed' then 'Wednesday'\n        when 'Thu' then 'Thursday'\n        when 'Fri' then 'Friday'\n        when 'Sat' then 'Saturday'\n        when 'Sun' then 'Sunday'\n    end\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.574021}, "macro.dbt_date.bigquery__day_name": {"unique_id": "macro.dbt_date.bigquery__day_name", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_name.sql", "original_file_path": "macros/calendar_date/day_name.sql", "name": "bigquery__day_name", "macro_sql": "\n\n{%- macro bigquery__day_name(date, short) -%}\n{%- set f = '%a' if short else '%A' -%}\n    format_date('{{ f }}', cast({{ date }} as date))\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5744178}, "macro.dbt_date.postgres__day_name": {"unique_id": "macro.dbt_date.postgres__day_name", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_name.sql", "original_file_path": "macros/calendar_date/day_name.sql", "name": "postgres__day_name", "macro_sql": "\n\n{%- macro postgres__day_name(date, short) -%}\n{# FM = Fill mode, which suppresses padding blanks #}\n{%- set f = 'FMDy' if short else 'FMDay' -%}\n    to_char({{ date }}, '{{ f }}')\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.574822}, "macro.dbt_date.to_unixtimestamp": {"unique_id": "macro.dbt_date.to_unixtimestamp", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/to_unixtimestamp.sql", "original_file_path": "macros/calendar_date/to_unixtimestamp.sql", "name": "to_unixtimestamp", "macro_sql": "{%- macro to_unixtimestamp(timestamp) -%}\n    {{ adapter.dispatch('to_unixtimestamp', 'dbt_date') (timestamp) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.default__to_unixtimestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.575525}, "macro.dbt_date.default__to_unixtimestamp": {"unique_id": "macro.dbt_date.default__to_unixtimestamp", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/to_unixtimestamp.sql", "original_file_path": "macros/calendar_date/to_unixtimestamp.sql", "name": "default__to_unixtimestamp", "macro_sql": "\n\n{%- macro default__to_unixtimestamp(timestamp) -%}\n    {{ dbt_date.date_part('epoch', timestamp) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.575809}, "macro.dbt_date.snowflake__to_unixtimestamp": {"unique_id": "macro.dbt_date.snowflake__to_unixtimestamp", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/to_unixtimestamp.sql", "original_file_path": "macros/calendar_date/to_unixtimestamp.sql", "name": "snowflake__to_unixtimestamp", "macro_sql": "\n\n{%- macro snowflake__to_unixtimestamp(timestamp) -%}\n    {{ dbt_date.date_part('epoch_seconds', timestamp) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5760891}, "macro.dbt_date.bigquery__to_unixtimestamp": {"unique_id": "macro.dbt_date.bigquery__to_unixtimestamp", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/to_unixtimestamp.sql", "original_file_path": "macros/calendar_date/to_unixtimestamp.sql", "name": "bigquery__to_unixtimestamp", "macro_sql": "\n\n{%- macro bigquery__to_unixtimestamp(timestamp) -%}\n    unix_seconds({{ timestamp }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.576299}, "macro.dbt_date.n_days_away": {"unique_id": "macro.dbt_date.n_days_away", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/n_days_away.sql", "original_file_path": "macros/calendar_date/n_days_away.sql", "name": "n_days_away", "macro_sql": "{%- macro n_days_away(n, date=None, tz=None) -%}\n{{ dbt_date.n_days_ago(-1 * n, date, tz) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.n_days_ago"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.577023}, "macro.dbt_date.week_start": {"unique_id": "macro.dbt_date.week_start", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/week_start.sql", "original_file_path": "macros/calendar_date/week_start.sql", "name": "week_start", "macro_sql": "{%- macro week_start(date=None, tz=None) -%}\n{%-set dt = date if date else dbt_date.today(tz) -%}\n{{ adapter.dispatch('week_start', 'dbt_date') (dt) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.today", "macro.dbt_date.default__week_start"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.578023}, "macro.dbt_date.default__week_start": {"unique_id": "macro.dbt_date.default__week_start", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/week_start.sql", "original_file_path": "macros/calendar_date/week_start.sql", "name": "default__week_start", "macro_sql": "{%- macro default__week_start(date) -%}\ncast({{ dbt_utils.date_trunc('week', date) }} as date)\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.date_trunc"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.578324}, "macro.dbt_date.snowflake__week_start": {"unique_id": "macro.dbt_date.snowflake__week_start", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/week_start.sql", "original_file_path": "macros/calendar_date/week_start.sql", "name": "snowflake__week_start", "macro_sql": "\n\n{%- macro snowflake__week_start(date) -%}\n    {#\n        Get the day of week offset: e.g. if the date is a Sunday,\n        dbt_date.day_of_week returns 1, so we subtract 1 to get a 0 offset\n    #}\n    {% set off_set = dbt_date.day_of_week(date, isoweek=False) ~ \" - 1\" %}\n    cast({{ dbt_utils.dateadd(\"day\", \"-1 * (\" ~ off_set ~ \")\", date) }} as date)\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.day_of_week", "macro.dbt_utils.dateadd"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5788958}, "macro.dbt_date.postgres__week_start": {"unique_id": "macro.dbt_date.postgres__week_start", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/week_start.sql", "original_file_path": "macros/calendar_date/week_start.sql", "name": "postgres__week_start", "macro_sql": "\n\n{%- macro postgres__week_start(date) -%}\n-- Sunday as week start date\ncast({{ dbt_utils.dateadd('day', -1, dbt_utils.date_trunc('week', dbt_utils.dateadd('day', 1, date))) }} as date)\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbt_utils.date_trunc"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.579411}, "macro.dbt_date.iso_week_start": {"unique_id": "macro.dbt_date.iso_week_start", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_start.sql", "original_file_path": "macros/calendar_date/iso_week_start.sql", "name": "iso_week_start", "macro_sql": "{%- macro iso_week_start(date=None, tz=None) -%}\n{%-set dt = date if date else dbt_date.today(tz) -%}\n{{ adapter.dispatch('iso_week_start', 'dbt_date') (dt) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.today", "macro.dbt_date.default__iso_week_start"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5804312}, "macro.dbt_date._iso_week_start": {"unique_id": "macro.dbt_date._iso_week_start", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_start.sql", "original_file_path": "macros/calendar_date/iso_week_start.sql", "name": "_iso_week_start", "macro_sql": "{%- macro _iso_week_start(date, week_type) -%}\ncast({{ dbt_utils.date_trunc(week_type, date) }} as date)\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.date_trunc"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.580749}, "macro.dbt_date.default__iso_week_start": {"unique_id": "macro.dbt_date.default__iso_week_start", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_start.sql", "original_file_path": "macros/calendar_date/iso_week_start.sql", "name": "default__iso_week_start", "macro_sql": "\n\n{%- macro default__iso_week_start(date) -%}\n{{ dbt_date._iso_week_start(date, 'isoweek') }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date._iso_week_start"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.581035}, "macro.dbt_date.snowflake__iso_week_start": {"unique_id": "macro.dbt_date.snowflake__iso_week_start", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_start.sql", "original_file_path": "macros/calendar_date/iso_week_start.sql", "name": "snowflake__iso_week_start", "macro_sql": "\n\n{%- macro snowflake__iso_week_start(date) -%}\n{{ dbt_date._iso_week_start(date, 'week') }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date._iso_week_start"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5813582}, "macro.dbt_date.postgres__iso_week_start": {"unique_id": "macro.dbt_date.postgres__iso_week_start", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_start.sql", "original_file_path": "macros/calendar_date/iso_week_start.sql", "name": "postgres__iso_week_start", "macro_sql": "\n\n{%- macro postgres__iso_week_start(date) -%}\n{{ dbt_date._iso_week_start(date, 'week') }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date._iso_week_start"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5816388}, "macro.dbt_date.n_days_ago": {"unique_id": "macro.dbt_date.n_days_ago", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/n_days_ago.sql", "original_file_path": "macros/calendar_date/n_days_ago.sql", "name": "n_days_ago", "macro_sql": "{%- macro n_days_ago(n, date=None, tz=None) -%}\n{%-set dt = date if date else dbt_date.today(tz) -%}\n{%- set n = n|int -%}\ncast({{ dbt_utils.dateadd('day', -1 * n, dt) }} as date)\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.today", "macro.dbt_utils.dateadd"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.58257}, "macro.dbt_date.last_week": {"unique_id": "macro.dbt_date.last_week", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/last_week.sql", "original_file_path": "macros/calendar_date/last_week.sql", "name": "last_week", "macro_sql": "{%- macro last_week(tz=None) -%}\n{{ dbt_date.n_weeks_ago(1, tz) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.n_weeks_ago"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.58308}, "macro.dbt_date.now": {"unique_id": "macro.dbt_date.now", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/now.sql", "original_file_path": "macros/calendar_date/now.sql", "name": "now", "macro_sql": "{%- macro now(tz=None) -%}\n{{ dbt_date.convert_timezone(dbt_utils.current_timestamp(), tz) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.convert_timezone", "macro.dbt_utils.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.58362}, "macro.dbt_date.periods_since": {"unique_id": "macro.dbt_date.periods_since", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/periods_since.sql", "original_file_path": "macros/calendar_date/periods_since.sql", "name": "periods_since", "macro_sql": "{%- macro periods_since(date_col, period_name='day', tz=None) -%}\n{{ dbt_utils.datediff(date_col, dbt_date.now(tz), period_name) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.datediff", "macro.dbt_date.now"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.584272}, "macro.dbt_date.today": {"unique_id": "macro.dbt_date.today", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/today.sql", "original_file_path": "macros/calendar_date/today.sql", "name": "today", "macro_sql": "{%- macro today(tz=None) -%}\ncast({{ dbt_date.now(tz) }} as date)\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.now"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.584764}, "macro.dbt_date.last_month": {"unique_id": "macro.dbt_date.last_month", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/last_month.sql", "original_file_path": "macros/calendar_date/last_month.sql", "name": "last_month", "macro_sql": "{%- macro last_month(tz=None) -%}\n{{ dbt_date.n_months_ago(1, tz) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.n_months_ago"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.585269}, "macro.dbt_date.day_of_year": {"unique_id": "macro.dbt_date.day_of_year", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_of_year.sql", "original_file_path": "macros/calendar_date/day_of_year.sql", "name": "day_of_year", "macro_sql": "{%- macro day_of_year(date) -%}\n{{ adapter.dispatch('day_of_year', 'dbt_date') (date) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.default__day_of_year"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.585983}, "macro.dbt_date.default__day_of_year": {"unique_id": "macro.dbt_date.default__day_of_year", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_of_year.sql", "original_file_path": "macros/calendar_date/day_of_year.sql", "name": "default__day_of_year", "macro_sql": "\n\n{%- macro default__day_of_year(date) -%}\n    {{ dbt_date.date_part('dayofyear', date) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.586266}, "macro.dbt_date.postgres__day_of_year": {"unique_id": "macro.dbt_date.postgres__day_of_year", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_of_year.sql", "original_file_path": "macros/calendar_date/day_of_year.sql", "name": "postgres__day_of_year", "macro_sql": "\n\n{%- macro postgres__day_of_year(date) -%}\n    {{ dbt_date.date_part('doy', date) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.586544}, "macro.dbt_date.redshift__day_of_year": {"unique_id": "macro.dbt_date.redshift__day_of_year", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_of_year.sql", "original_file_path": "macros/calendar_date/day_of_year.sql", "name": "redshift__day_of_year", "macro_sql": "\n\n{%- macro redshift__day_of_year(date) -%}\n    cast({{ dbt_date.date_part('dayofyear', date) }} as {{ dbt_utils.type_bigint() }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part", "macro.dbt_utils.type_bigint"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.586907}, "macro.dbt_date.from_unixtimestamp": {"unique_id": "macro.dbt_date.from_unixtimestamp", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/from_unixtimestamp.sql", "original_file_path": "macros/calendar_date/from_unixtimestamp.sql", "name": "from_unixtimestamp", "macro_sql": "{%- macro from_unixtimestamp(epochs, format=\"seconds\") -%}\n    {{ adapter.dispatch('from_unixtimestamp', 'dbt_date') (epochs, format) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.default__from_unixtimestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.58904}, "macro.dbt_date.default__from_unixtimestamp": {"unique_id": "macro.dbt_date.default__from_unixtimestamp", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/from_unixtimestamp.sql", "original_file_path": "macros/calendar_date/from_unixtimestamp.sql", "name": "default__from_unixtimestamp", "macro_sql": "\n\n{%- macro default__from_unixtimestamp(epochs, format=\"seconds\") -%}\n    {%- if format != \"seconds\" -%}\n    {{ exceptions.raise_compiler_error(\n        \"value \" ~ format ~ \" for `format` for from_unixtimestamp is not supported.\"\n        )\n    }}\n    {% endif -%}\n    to_timestamp({{ epochs }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.589555}, "macro.dbt_date.postgres__from_unixtimestamp": {"unique_id": "macro.dbt_date.postgres__from_unixtimestamp", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/from_unixtimestamp.sql", "original_file_path": "macros/calendar_date/from_unixtimestamp.sql", "name": "postgres__from_unixtimestamp", "macro_sql": "\n\n{%- macro postgres__from_unixtimestamp(epochs, format=\"seconds\") -%}\n    {%- if format != \"seconds\" -%}\n    {{ exceptions.raise_compiler_error(\n        \"value \" ~ format ~ \" for `format` for from_unixtimestamp is not supported.\"\n        )\n    }}\n    {% endif -%}\n    cast(to_timestamp({{ epochs }}) at time zone 'UTC' as timestamp)\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5900779}, "macro.dbt_date.snowflake__from_unixtimestamp": {"unique_id": "macro.dbt_date.snowflake__from_unixtimestamp", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/from_unixtimestamp.sql", "original_file_path": "macros/calendar_date/from_unixtimestamp.sql", "name": "snowflake__from_unixtimestamp", "macro_sql": "\n\n{%- macro snowflake__from_unixtimestamp(epochs, format) -%}\n    {%- if format == \"seconds\" -%}\n    {%- set scale = 0 -%}\n    {%- elif format == \"milliseconds\" -%}\n    {%- set scale = 3 -%}\n    {%- elif format == \"microseconds\" -%}\n    {%- set scale = 6 -%}\n    {%- else -%}\n    {{ exceptions.raise_compiler_error(\n        \"value \" ~ format ~ \" for `format` for from_unixtimestamp is not supported.\"\n        )\n    }}\n    {% endif -%}\n    to_timestamp_ntz({{ epochs }}, {{ scale }})\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.590994}, "macro.dbt_date.bigquery__from_unixtimestamp": {"unique_id": "macro.dbt_date.bigquery__from_unixtimestamp", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/from_unixtimestamp.sql", "original_file_path": "macros/calendar_date/from_unixtimestamp.sql", "name": "bigquery__from_unixtimestamp", "macro_sql": "\n\n{%- macro bigquery__from_unixtimestamp(epochs, format) -%}\n    {%- if format == \"seconds\" -%}\n        timestamp_seconds({{ epochs }})\n    {%- elif format == \"milliseconds\" -%}\n        timestamp_millis({{ epochs }})\n    {%- elif format == \"microseconds\" -%}\n        timestamp_micros({{ epochs }})\n    {%- else -%}\n    {{ exceptions.raise_compiler_error(\n        \"value \" ~ format ~ \" for `format` for from_unixtimestamp is not supported.\"\n        )\n    }}\n    {% endif -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.591769}, "macro.dbt_date.n_months_ago": {"unique_id": "macro.dbt_date.n_months_ago", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/n_months_ago.sql", "original_file_path": "macros/calendar_date/n_months_ago.sql", "name": "n_months_ago", "macro_sql": "{%- macro n_months_ago(n, tz=None) -%}\n{%- set n = n|int -%}\n{{ dbt_utils.date_trunc('month', \n    dbt_utils.dateadd('month', -1 * n, \n        dbt_date.today(tz)\n        )\n    ) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.date_trunc", "macro.dbt_utils.dateadd", "macro.dbt_date.today"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.592615}, "macro.dbt_date.date_part": {"unique_id": "macro.dbt_date.date_part", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/date_part.sql", "original_file_path": "macros/calendar_date/date_part.sql", "name": "date_part", "macro_sql": "{% macro date_part(datepart, date) -%}\n    {{ adapter.dispatch('date_part', 'dbt_date') (datepart, date) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.default__date_part"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.593309}, "macro.dbt_date.default__date_part": {"unique_id": "macro.dbt_date.default__date_part", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/date_part.sql", "original_file_path": "macros/calendar_date/date_part.sql", "name": "default__date_part", "macro_sql": "{% macro default__date_part(datepart, date) -%}\n    date_part('{{ datepart }}', {{  date }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.593579}, "macro.dbt_date.bigquery__date_part": {"unique_id": "macro.dbt_date.bigquery__date_part", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/date_part.sql", "original_file_path": "macros/calendar_date/date_part.sql", "name": "bigquery__date_part", "macro_sql": "{% macro bigquery__date_part(datepart, date) -%}\n    extract({{ datepart }} from {{ date }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.593846}, "macro.dbt_date.n_weeks_away": {"unique_id": "macro.dbt_date.n_weeks_away", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/n_weeks_away.sql", "original_file_path": "macros/calendar_date/n_weeks_away.sql", "name": "n_weeks_away", "macro_sql": "{%- macro n_weeks_away(n, tz=None) -%}\n{%- set n = n|int -%}\n{{ dbt_utils.date_trunc('week', \n    dbt_utils.dateadd('week', n, \n        dbt_date.today(tz)\n        )\n    ) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.date_trunc", "macro.dbt_utils.dateadd", "macro.dbt_date.today"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.594653}, "macro.dbt_date.day_of_month": {"unique_id": "macro.dbt_date.day_of_month", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_of_month.sql", "original_file_path": "macros/calendar_date/day_of_month.sql", "name": "day_of_month", "macro_sql": "{%- macro day_of_month(date) -%}\n{{ dbt_date.date_part('day', date) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5952058}, "macro.dbt_date.redshift__day_of_month": {"unique_id": "macro.dbt_date.redshift__day_of_month", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_of_month.sql", "original_file_path": "macros/calendar_date/day_of_month.sql", "name": "redshift__day_of_month", "macro_sql": "\n\n{%- macro redshift__day_of_month(date) -%}\ncast({{ dbt_date.date_part('day', date) }} as {{ dbt_utils.type_bigint() }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part", "macro.dbt_utils.type_bigint"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.595616}, "macro.dbt_date.yesterday": {"unique_id": "macro.dbt_date.yesterday", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/yesterday.sql", "original_file_path": "macros/calendar_date/yesterday.sql", "name": "yesterday", "macro_sql": "{%- macro yesterday(date=None, tz=None) -%}\n{{ dbt_date.n_days_ago(1, date, tz) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.n_days_ago"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5961862}, "macro.dbt_date.day_of_week": {"unique_id": "macro.dbt_date.day_of_week", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_of_week.sql", "original_file_path": "macros/calendar_date/day_of_week.sql", "name": "day_of_week", "macro_sql": "{%- macro day_of_week(date, isoweek=true) -%}\n{{ adapter.dispatch('day_of_week', 'dbt_date') (date, isoweek) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.default__day_of_week"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.599}, "macro.dbt_date.default__day_of_week": {"unique_id": "macro.dbt_date.default__day_of_week", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_of_week.sql", "original_file_path": "macros/calendar_date/day_of_week.sql", "name": "default__day_of_week", "macro_sql": "\n\n{%- macro default__day_of_week(date, isoweek) -%}\n\n    {%- set dow = dbt_date.date_part('dayofweek', date) -%}\n\n    {%- if isoweek -%}\n    case\n        -- Shift start of week from Sunday (0) to Monday (1)\n        when {{ dow }} = 0 then 7\n        else {{ dow }}\n    end\n    {%- else -%}\n    {{ dow }} + 1\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.5995789}, "macro.dbt_date.snowflake__day_of_week": {"unique_id": "macro.dbt_date.snowflake__day_of_week", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_of_week.sql", "original_file_path": "macros/calendar_date/day_of_week.sql", "name": "snowflake__day_of_week", "macro_sql": "\n\n{%- macro snowflake__day_of_week(date, isoweek) -%}\n\n    {%- if isoweek -%}\n        {%- set dow_part = 'dayofweekiso' -%}\n        {{ dbt_date.date_part(dow_part, date) }}\n    {%- else -%}\n        {%- set dow_part = 'dayofweek' -%}\n        case\n            when {{ dbt_date.date_part(dow_part, date) }} = 7 then 1\n            else {{ dbt_date.date_part(dow_part, date) }} + 1\n        end\n    {%- endif -%}\n\n\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.600372}, "macro.dbt_date.bigquery__day_of_week": {"unique_id": "macro.dbt_date.bigquery__day_of_week", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_of_week.sql", "original_file_path": "macros/calendar_date/day_of_week.sql", "name": "bigquery__day_of_week", "macro_sql": "\n\n{%- macro bigquery__day_of_week(date, isoweek) -%}\n\n    {%- set dow = dbt_date.date_part('dayofweek', date) -%}\n\n    {%- if isoweek -%}\n    case\n        -- Shift start of week from Sunday (1) to Monday (2)\n        when {{ dow }} = 1 then 7\n        else {{ dow }} - 1\n    end\n    {%- else -%}\n    {{ dow }}\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.600941}, "macro.dbt_date.postgres__day_of_week": {"unique_id": "macro.dbt_date.postgres__day_of_week", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_of_week.sql", "original_file_path": "macros/calendar_date/day_of_week.sql", "name": "postgres__day_of_week", "macro_sql": "\n\n\n{%- macro postgres__day_of_week(date, isoweek) -%}\n\n    {%- if isoweek -%}\n        {%- set dow_part = 'isodow' -%}\n        -- Monday(1) to Sunday (7)\n        cast({{ dbt_date.date_part(dow_part, date) }} as {{ dbt_utils.type_int() }})\n    {%- else -%}\n        {%- set dow_part = 'dow' -%}\n        -- Sunday(1) to Saturday (7)\n        cast({{ dbt_date.date_part(dow_part, date) }} + 1 as {{ dbt_utils.type_int() }})\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part", "macro.dbt_utils.type_int"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.601773}, "macro.dbt_date.redshift__day_of_week": {"unique_id": "macro.dbt_date.redshift__day_of_week", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/day_of_week.sql", "original_file_path": "macros/calendar_date/day_of_week.sql", "name": "redshift__day_of_week", "macro_sql": "\n\n\n{%- macro redshift__day_of_week(date, isoweek) -%}\n\n    {%- set dow = dbt_date.date_part('dayofweek', date) -%}\n\n    {%- if isoweek -%}\n    case\n        -- Shift start of week from Sunday (0) to Monday (1)\n        when {{ dow }} = 0 then 7\n        else cast({{ dow }} as {{ dbt_utils.type_bigint() }})\n    end\n    {%- else -%}\n    cast({{ dow }} + 1 as {{ dbt_utils.type_bigint() }})\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part", "macro.dbt_utils.type_bigint"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.602732}, "macro.dbt_date.iso_week_end": {"unique_id": "macro.dbt_date.iso_week_end", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_end.sql", "original_file_path": "macros/calendar_date/iso_week_end.sql", "name": "iso_week_end", "macro_sql": "{%- macro iso_week_end(date=None, tz=None) -%}\n{%-set dt = date if date else dbt_date.today(tz) -%}\n{{ adapter.dispatch('iso_week_end', 'dbt_date') (dt) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.today", "macro.dbt_date.default__iso_week_end"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.6037068}, "macro.dbt_date._iso_week_end": {"unique_id": "macro.dbt_date._iso_week_end", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_end.sql", "original_file_path": "macros/calendar_date/iso_week_end.sql", "name": "_iso_week_end", "macro_sql": "{%- macro _iso_week_end(date, week_type) -%}\n{%- set dt = dbt_date.iso_week_start(date) -%}\n{{ dbt_date.n_days_away(6, dt) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.iso_week_start", "macro.dbt_date.n_days_away"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.604131}, "macro.dbt_date.default__iso_week_end": {"unique_id": "macro.dbt_date.default__iso_week_end", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_end.sql", "original_file_path": "macros/calendar_date/iso_week_end.sql", "name": "default__iso_week_end", "macro_sql": "\n\n{%- macro default__iso_week_end(date) -%}\n{{ dbt_date._iso_week_end(date, 'isoweek') }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date._iso_week_end"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.604414}, "macro.dbt_date.snowflake__iso_week_end": {"unique_id": "macro.dbt_date.snowflake__iso_week_end", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_end.sql", "original_file_path": "macros/calendar_date/iso_week_end.sql", "name": "snowflake__iso_week_end", "macro_sql": "\n\n{%- macro snowflake__iso_week_end(date) -%}\n{{ dbt_date._iso_week_end(date, 'weekiso') }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date._iso_week_end"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.6046941}, "macro.dbt_date.n_weeks_ago": {"unique_id": "macro.dbt_date.n_weeks_ago", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/n_weeks_ago.sql", "original_file_path": "macros/calendar_date/n_weeks_ago.sql", "name": "n_weeks_ago", "macro_sql": "{%- macro n_weeks_ago(n, tz=None) -%}\n{%- set n = n|int -%}\n{{ dbt_utils.date_trunc('week', \n    dbt_utils.dateadd('week', -1 * n, \n        dbt_date.today(tz)\n        )\n    ) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.date_trunc", "macro.dbt_utils.dateadd", "macro.dbt_date.today"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.605577}, "macro.dbt_date.month_name": {"unique_id": "macro.dbt_date.month_name", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/month_name.sql", "original_file_path": "macros/calendar_date/month_name.sql", "name": "month_name", "macro_sql": "{%- macro month_name(date, short=True) -%}\n    {{ adapter.dispatch('month_name', 'dbt_date') (date, short) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.default__month_name"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.606546}, "macro.dbt_date.default__month_name": {"unique_id": "macro.dbt_date.default__month_name", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/month_name.sql", "original_file_path": "macros/calendar_date/month_name.sql", "name": "default__month_name", "macro_sql": "\n\n{%- macro default__month_name(date, short) -%}\n{%- set f = 'MON' if short else 'MONTH' -%}\n    to_char({{ date }}, '{{ f }}')\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.606955}, "macro.dbt_date.bigquery__month_name": {"unique_id": "macro.dbt_date.bigquery__month_name", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/month_name.sql", "original_file_path": "macros/calendar_date/month_name.sql", "name": "bigquery__month_name", "macro_sql": "\n\n{%- macro bigquery__month_name(date, short) -%}\n{%- set f = '%b' if short else '%B' -%}\n    format_date('{{ f }}', cast({{ date }} as date))\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.607357}, "macro.dbt_date.snowflake__month_name": {"unique_id": "macro.dbt_date.snowflake__month_name", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/month_name.sql", "original_file_path": "macros/calendar_date/month_name.sql", "name": "snowflake__month_name", "macro_sql": "\n\n{%- macro snowflake__month_name(date, short) -%}\n{%- set f = 'MON' if short else 'MMMM' -%}\n    to_char({{ date }}, '{{ f }}')\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.607758}, "macro.dbt_date.postgres__month_name": {"unique_id": "macro.dbt_date.postgres__month_name", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/month_name.sql", "original_file_path": "macros/calendar_date/month_name.sql", "name": "postgres__month_name", "macro_sql": "\n\n{%- macro postgres__month_name(date, short) -%}\n{# FM = Fill mode, which suppresses padding blanks #}\n{%- set f = 'FMMon' if short else 'FMMonth' -%}\n    to_char({{ date }}, '{{ f }}')\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.608168}, "macro.dbt_date.last_month_name": {"unique_id": "macro.dbt_date.last_month_name", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/last_month_name.sql", "original_file_path": "macros/calendar_date/last_month_name.sql", "name": "last_month_name", "macro_sql": "{%- macro last_month_name(short=True, tz=None) -%}\n{{ dbt_date.month_name(dbt_date.last_month(1, tz), short=short) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.month_name", "macro.dbt_date.last_month"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.608809}, "macro.dbt_date.week_of_year": {"unique_id": "macro.dbt_date.week_of_year", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/week_of_year.sql", "original_file_path": "macros/calendar_date/week_of_year.sql", "name": "week_of_year", "macro_sql": "{%- macro week_of_year(date=None, tz=None) -%}\n{%-set dt = date if date else dbt_date.today(tz) -%}\n{{ adapter.dispatch('week_of_year', 'dbt_date') (dt) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.today", "macro.dbt_date.default__week_of_year"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.609727}, "macro.dbt_date.default__week_of_year": {"unique_id": "macro.dbt_date.default__week_of_year", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/week_of_year.sql", "original_file_path": "macros/calendar_date/week_of_year.sql", "name": "default__week_of_year", "macro_sql": "{%- macro default__week_of_year(date) -%}\ncast({{ dbt_date.date_part('week', date) }} as {{ dbt_utils.type_int() }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part", "macro.dbt_utils.type_int"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.6100988}, "macro.dbt_date.postgres__week_of_year": {"unique_id": "macro.dbt_date.postgres__week_of_year", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/week_of_year.sql", "original_file_path": "macros/calendar_date/week_of_year.sql", "name": "postgres__week_of_year", "macro_sql": "\n\n{%- macro postgres__week_of_year(date) -%}\n{# postgresql 'week' returns isoweek. Use to_char instead.\n   WW = the first week starts on the first day of the year #}\ncast(to_char({{ date }}, 'WW') as {{ dbt_utils.type_int() }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_int"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.610402}, "macro.dbt_date.convert_timezone": {"unique_id": "macro.dbt_date.convert_timezone", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/convert_timezone.sql", "original_file_path": "macros/calendar_date/convert_timezone.sql", "name": "convert_timezone", "macro_sql": "{%- macro convert_timezone(column, target_tz=None, source_tz=None) -%}\n{%- set source_tz = \"UTC\" if not source_tz else source_tz -%}\n{%- set target_tz = var(\"dbt_date:time_zone\") if not target_tz else target_tz -%}\n{{ adapter.dispatch('convert_timezone', 'dbt_date') (column, target_tz, source_tz) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.spark__convert_timezone"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.612481}, "macro.dbt_date.default__convert_timezone": {"unique_id": "macro.dbt_date.default__convert_timezone", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/convert_timezone.sql", "original_file_path": "macros/calendar_date/convert_timezone.sql", "name": "default__convert_timezone", "macro_sql": "{% macro default__convert_timezone(column, target_tz, source_tz) -%}\n{%- if not source_tz -%}\ncast(convert_timezone('{{ target_tz }}', {{ column }}) as {{ dbt_utils.type_timestamp() }})\n{%- else -%}\ncast(convert_timezone('{{ source_tz }}', '{{ target_tz }}', {{ column }}) as {{ dbt_utils.type_timestamp() }})\n{%- endif -%}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.613149}, "macro.dbt_date.bigquery__convert_timezone": {"unique_id": "macro.dbt_date.bigquery__convert_timezone", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/convert_timezone.sql", "original_file_path": "macros/calendar_date/convert_timezone.sql", "name": "bigquery__convert_timezone", "macro_sql": "{%- macro bigquery__convert_timezone(column, target_tz, source_tz=None) -%}\ntimestamp(datetime({{ column }}, '{{ target_tz}}'))\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.613461}, "macro.dbt_date.spark__convert_timezone": {"unique_id": "macro.dbt_date.spark__convert_timezone", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/convert_timezone.sql", "original_file_path": "macros/calendar_date/convert_timezone.sql", "name": "spark__convert_timezone", "macro_sql": "{%- macro spark__convert_timezone(column, target_tz, source_tz) -%}\nfrom_utc_timestamp(\n        to_utc_timestamp({{ column }}, '{{ source_tz }}'),\n        '{{ target_tz }}'\n        )\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.61379}, "macro.dbt_date.postgres__convert_timezone": {"unique_id": "macro.dbt_date.postgres__convert_timezone", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/convert_timezone.sql", "original_file_path": "macros/calendar_date/convert_timezone.sql", "name": "postgres__convert_timezone", "macro_sql": "{% macro postgres__convert_timezone(column, target_tz, source_tz) -%}\n{%- if source_tz -%}\ncast({{ column }} at time zone '{{ source_tz }}' at time zone '{{ target_tz }}' as {{ dbt_utils.type_timestamp() }})\n{%- else -%}\ncast({{ column }} at time zone '{{ target_tz }}' as {{ dbt_utils.type_timestamp() }})\n{%- endif -%}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.614536}, "macro.dbt_date.n_months_away": {"unique_id": "macro.dbt_date.n_months_away", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/n_months_away.sql", "original_file_path": "macros/calendar_date/n_months_away.sql", "name": "n_months_away", "macro_sql": "{%- macro n_months_away(n, tz=None) -%}\n{%- set n = n|int -%}\n{{ dbt_utils.date_trunc('month', \n    dbt_utils.dateadd('month', n, \n        dbt_date.today(tz)\n        )\n    ) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.date_trunc", "macro.dbt_utils.dateadd", "macro.dbt_date.today"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.615345}, "macro.dbt_date.iso_week_of_year": {"unique_id": "macro.dbt_date.iso_week_of_year", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_of_year.sql", "original_file_path": "macros/calendar_date/iso_week_of_year.sql", "name": "iso_week_of_year", "macro_sql": "{%- macro iso_week_of_year(date=None, tz=None) -%}\n{%-set dt = date if date else dbt_date.today(tz) -%}\n{{ adapter.dispatch('iso_week_of_year', 'dbt_date') (dt) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.today", "macro.dbt_date.default__iso_week_of_year"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.6164339}, "macro.dbt_date._iso_week_of_year": {"unique_id": "macro.dbt_date._iso_week_of_year", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_of_year.sql", "original_file_path": "macros/calendar_date/iso_week_of_year.sql", "name": "_iso_week_of_year", "macro_sql": "{%- macro _iso_week_of_year(date, week_type) -%}\ncast({{ dbt_date.date_part(week_type, date) }} as {{ dbt_utils.type_int() }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part", "macro.dbt_utils.type_int"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.6168199}, "macro.dbt_date.default__iso_week_of_year": {"unique_id": "macro.dbt_date.default__iso_week_of_year", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_of_year.sql", "original_file_path": "macros/calendar_date/iso_week_of_year.sql", "name": "default__iso_week_of_year", "macro_sql": "\n\n{%- macro default__iso_week_of_year(date) -%}\n{{ dbt_date._iso_week_of_year(date, 'isoweek') }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date._iso_week_of_year"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.617103}, "macro.dbt_date.snowflake__iso_week_of_year": {"unique_id": "macro.dbt_date.snowflake__iso_week_of_year", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_of_year.sql", "original_file_path": "macros/calendar_date/iso_week_of_year.sql", "name": "snowflake__iso_week_of_year", "macro_sql": "\n\n{%- macro snowflake__iso_week_of_year(date) -%}\n{{ dbt_date._iso_week_of_year(date, 'weekiso') }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date._iso_week_of_year"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.617384}, "macro.dbt_date.postgres__iso_week_of_year": {"unique_id": "macro.dbt_date.postgres__iso_week_of_year", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/iso_week_of_year.sql", "original_file_path": "macros/calendar_date/iso_week_of_year.sql", "name": "postgres__iso_week_of_year", "macro_sql": "\n\n{%- macro postgres__iso_week_of_year(date) -%}\n-- postgresql week is isoweek, the first week of a year containing January 4 of that year.\n{{ dbt_date._iso_week_of_year(date, 'week') }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date._iso_week_of_year"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.617684}, "macro.dbt_date.week_end": {"unique_id": "macro.dbt_date.week_end", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/week_end.sql", "original_file_path": "macros/calendar_date/week_end.sql", "name": "week_end", "macro_sql": "{%- macro week_end(date=None, tz=None) -%}\n{%-set dt = date if date else dbt_date.today(tz) -%}\n{{ adapter.dispatch('week_end', 'dbt_date') (dt) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.today", "macro.dbt_date.default__week_end"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.618665}, "macro.dbt_date.default__week_end": {"unique_id": "macro.dbt_date.default__week_end", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/week_end.sql", "original_file_path": "macros/calendar_date/week_end.sql", "name": "default__week_end", "macro_sql": "{%- macro default__week_end(date) -%}\n{{ dbt_utils.last_day(date, 'week') }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.last_day"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.618953}, "macro.dbt_date.snowflake__week_end": {"unique_id": "macro.dbt_date.snowflake__week_end", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/week_end.sql", "original_file_path": "macros/calendar_date/week_end.sql", "name": "snowflake__week_end", "macro_sql": "\n\n{%- macro snowflake__week_end(date) -%}\n{%- set dt = dbt_date.week_start(date) -%}\n{{ dbt_date.n_days_away(6, dt) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.week_start", "macro.dbt_date.n_days_away"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.619358}, "macro.dbt_date.postgres__week_end": {"unique_id": "macro.dbt_date.postgres__week_end", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/week_end.sql", "original_file_path": "macros/calendar_date/week_end.sql", "name": "postgres__week_end", "macro_sql": "\n\n{%- macro postgres__week_end(date) -%}\n{%- set dt = dbt_date.week_start(date) -%}\n{{ dbt_date.n_days_away(6, dt) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.week_start", "macro.dbt_date.n_days_away"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.619759}, "macro.dbt_date.next_month_number": {"unique_id": "macro.dbt_date.next_month_number", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/next_month_number.sql", "original_file_path": "macros/calendar_date/next_month_number.sql", "name": "next_month_number", "macro_sql": "{%- macro next_month_number(tz=None) -%}\n{{ dbt_date.date_part('month', dbt_date.next_month(1, tz)) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part", "macro.dbt_date.next_month"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.620356}, "macro.dbt_date.last_month_number": {"unique_id": "macro.dbt_date.last_month_number", "package_name": "dbt_date", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbt_date", "path": "macros/calendar_date/last_month_number.sql", "original_file_path": "macros/calendar_date/last_month_number.sql", "name": "last_month_number", "macro_sql": "{%- macro last_month_number(tz=None) -%}\n{{ dbt_date.date_part('month', dbt_date.last_month(1, tz)) }}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_date.date_part", "macro.dbt_date.last_month"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.62095}, "macro.dbtvault.spark__sat": {"unique_id": "macro.dbtvault.spark__sat", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/databricks/sat.sql", "original_file_path": "macros/tables/databricks/sat.sql", "name": "spark__sat", "macro_sql": "{%- macro spark__sat(src_pk, src_hashdiff, src_payload, src_eff, src_ldts, src_source, source_model, out_of_sequence) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_hashdiff=src_hashdiff, src_payload=src_payload,\n                                       src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_payload, src_eff, src_ldts, src_source]) -%}\n{%- set rank_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_ldts]) -%}\n{%- set pk_cols = dbtvault.expand_column_list(columns=[src_pk]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols +  dbtvault.escape_column_names([config.get('rank_column')]) -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\nWITH source_data AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ dbtvault.prefix(source_cols_with_rank, 'a', alias_target='source') }}\n    {%- else %}\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='source') }}\n    {%- endif %}\n    FROM {{ ref(source_model) }} AS a\n    WHERE {{ dbtvault.prefix([src_pk], 'a') }} IS NOT NULL\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n    AND __PERIOD_FILTER__\n    {% elif model.config.materialized == 'vault_insert_by_rank' %}\n    AND __RANK_FILTER__\n    {% endif %}\n),\n\n{% if dbtvault.is_any_incremental() %}\nlatest_records_pre AS (\n    SELECT {{ dbtvault.prefix(rank_cols, 'current_records', alias_target='target') }},\n           RANK() OVER (\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'current_records') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'current_records') }} DESC\n           ) AS rank\n    FROM {{ this }} AS current_records\n    JOIN (\n        SELECT DISTINCT {{ dbtvault.prefix([src_pk], 'source_data') }}\n        FROM source_data\n    ) AS source_records\n    ON {{ dbtvault.prefix([src_pk], 'current_records') }} = {{ dbtvault.prefix([src_pk], 'source_records') }}\n),\nlatest_records AS (\n\n    SELECT *\n    FROM latest_records_pre\n    WHERE rank = 1\n),\n{%- endif %}\n\nrecords_to_insert AS (\n    SELECT DISTINCT {{ dbtvault.alias_all(source_cols, 'stage') }}\n    FROM source_data AS stage\n    {%- if dbtvault.is_any_incremental() %}\n    LEFT JOIN latest_records\n    ON {{ dbtvault.prefix([src_pk], 'latest_records', alias_target='target') }} = {{ dbtvault.prefix([src_pk], 'stage') }}\n    WHERE {{ dbtvault.prefix([src_hashdiff], 'latest_records', alias_target='target') }} != {{ dbtvault.prefix([src_hashdiff], 'stage') }}\n        OR {{ dbtvault.prefix([src_hashdiff], 'latest_records', alias_target='target') }} IS NULL\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.expand_column_list", "macro.dbtvault.escape_column_names", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.is_any_incremental", "macro.dbtvault.alias_all"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.628006}, "macro.dbtvault.spark__hub": {"unique_id": "macro.dbtvault.spark__hub", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/databricks/hub.sql", "original_file_path": "macros/tables/databricks/hub.sql", "name": "spark__hub", "macro_sql": "{%- macro spark__hub(src_pk, src_nk, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_nk=src_nk,\n                                       src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_nk = dbtvault.escape_column_names(src_nk) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_nk, src_ldts, src_source]) -%}\n{%- set src_pk_cols =dbtvault.expand_column_list(columns=[src_pk]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + [config.get('rank_column')] -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{{ 'WITH ' -}}\n\n{%- if not (source_model is iterable and source_model is not string) -%}\n    {%- set source_model = [source_model] -%}\n{%- endif -%}\n\n{%- set ns = namespace(last_cte= \"\") -%}\n\n{%- for src in source_model -%}\n\n{%- set source_number = loop.index | string -%}\n\nrow_rank_{{ source_number }} AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ source_cols_with_rank | join(', ') }}\n    {%- else %}\n    SELECT {{ source_cols | join(', ') }}\n    {%- endif %}\n    FROM\n    (\n        {%- if model.config.materialized == 'vault_insert_by_rank' %}\n        SELECT {{ dbtvault.prefix(source_cols_with_rank, 'rr') }},\n        {%- else %}\n        SELECT {{ dbtvault.prefix(source_cols, 'rr') }},\n        {%- endif %}\n               ROW_NUMBER() OVER(\n                   PARTITION BY {{ dbtvault.prefix([src_pk], 'rr') }}\n                   ORDER BY {{ dbtvault.prefix([src_ldts], 'rr') }}\n               ) AS row_number\n        FROM {{ ref(src) }} AS rr\n        WHERE {{ dbtvault.multikey(src_pk, prefix='rr', condition='IS NOT NULL') }}\n    ) h\n    WHERE h.row_number = 1\n    {%- set ns.last_cte = \"row_rank_{}\".format(source_number) %}\n),{{ \"\\n\" if not loop.last }}\n{% endfor -%}\n{% if source_model | length > 1 %}\nstage_union AS (\n    {%- for src in source_model %}\n    SELECT * FROM row_rank_{{ loop.index | string }}\n    {%- if not loop.last %}\n    UNION ALL\n    {%- endif %}\n    {%- endfor %}\n    {%- set ns.last_cte = \"stage_union\" %}\n),\n{%- endif -%}\n{%- if model.config.materialized == 'vault_insert_by_period' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __PERIOD_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- elif model.config.materialized == 'vault_insert_by_rank' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __RANK_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- endif -%}\n{%- if source_model | length > 1 %}\n\nrow_rank_union AS (\n    SELECT *\n    FROM\n    (\n        SELECT ru.*,\n               ROW_NUMBER() OVER(\n                   PARTITION BY {{ dbtvault.prefix([src_pk], 'ru') }}\n                   ORDER BY {{ dbtvault.prefix([src_ldts], 'ru') }}, {{ dbtvault.prefix([src_source], 'ru') }} ASC\n               ) AS row_rank_number\n        FROM {{ ns.last_cte }} AS ru\n        WHERE {{ dbtvault.multikey(src_pk, prefix='ru', condition='IS NOT NULL') }}\n    ) h\n    WHERE h.row_rank_number = 1\n    {%- set ns.last_cte = \"row_rank_union\" %}\n),\n{% endif %}\nrecords_to_insert AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='target') }}\n    FROM {{ ns.last_cte }} AS a\n    {%- if dbtvault.is_any_incremental() %}\n    LEFT JOIN {{ this }} AS d\n    ON {{ dbtvault.multikey(src_pk, prefix=['a','d'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='d', condition='IS NULL') }}\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.639665}, "macro.dbtvault.bigquery__xts": {"unique_id": "macro.dbtvault.bigquery__xts", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/bigquery/xts.sql", "original_file_path": "macros/tables/bigquery/xts.sql", "name": "bigquery__xts", "macro_sql": "{%- macro bigquery__xts(src_pk, src_satellite, src_ldts, src_source, source_model) -%}\n\n{{ dbtvault.default__xts(src_pk=src_pk,\n                         src_satellite=src_satellite,\n                         src_ldts=src_ldts,\n                         src_source=src_source,\n                         source_model=source_model) }}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__xts"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.651406}, "macro.dbtvault.bigquery__ma_sat": {"unique_id": "macro.dbtvault.bigquery__ma_sat", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/bigquery/ma_sat.sql", "original_file_path": "macros/tables/bigquery/ma_sat.sql", "name": "bigquery__ma_sat", "macro_sql": "{%- macro bigquery__ma_sat(src_pk, src_cdk, src_hashdiff, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_cdk=src_cdk, src_hashdiff=src_hashdiff,\n                                       src_payload=src_payload, src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_cdk = dbtvault.escape_column_names(src_cdk) -%}\n{%- set src_hashdiff = dbtvault.escape_column_names(src_hashdiff) -%}\n{%- set src_payload = dbtvault.escape_column_names(src_payload) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_cdk, src_payload, src_eff, src_ldts, src_source]) -%}\n{%- set rank_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_ldts]) -%}\n{%- set cdk_cols = dbtvault.expand_column_list(columns=[src_cdk]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' -%}\n    {%- set source_cols_with_rank = source_cols + [config.get('rank_column')] -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{# Select unique source records -#}\nWITH source_data AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT DISTINCT {{ dbtvault.prefix(source_cols_with_rank, 's', alias_target='source') }}\n    {%- else %}\n    SELECT DISTINCT {{ dbtvault.prefix(source_cols, 's', alias_target='source') }}\n    {%- endif %}\n    FROM {{ ref(source_model) }} AS s\n    WHERE {{ dbtvault.multikey([src_pk], prefix='s', condition='IS NOT NULL') }}\n    {%- for child_key in src_cdk %}\n        AND {{ dbtvault.multikey(child_key, prefix='s', condition='IS NOT NULL') }}\n    {%- endfor %}\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n        AND __PERIOD_FILTER__\n    {%- elif model.config.materialized == 'vault_insert_by_rank' %}\n        AND __RANK_FILTER__\n    {%- endif %}\n),\n\n{# if any_incremental -#}\n{% if dbtvault.is_any_incremental() %}\n\nsource_data_with_count AS (\n    SELECT a.*\n        ,b.source_count\n    FROM source_data a\n    INNER JOIN\n    (\n        SELECT {{ dbtvault.prefix([src_pk], 't') }}\n            ,COUNT(*) AS source_count\n        FROM (SELECT DISTINCT {{ dbtvault.prefix([src_pk], 's') }}, {{ dbtvault.prefix([src_hashdiff], 's', alias_target='source') }}, {{ dbtvault.prefix(cdk_cols, 's') }} FROM source_data AS s) AS t\n        GROUP BY {{ dbtvault.prefix([src_pk], 't') }}\n    ) AS b\n    ON {{ dbtvault.multikey([src_pk], prefix=['a','b'], condition='=') }}\n),\n\n{# Select latest records from satellite, restricted to PKs in source data -#}\nlatest_records AS (\n    SELECT {{ dbtvault.prefix([src_pk], 'mas', alias_target='target') }}\n        ,{{ dbtvault.prefix([src_hashdiff], 'mas', alias_target='target') }}\n        ,{{ dbtvault.prefix([src_cdk], 'mas', alias_target='target') }}\n        ,{{ dbtvault.prefix([src_ldts], 'mas', alias_target='target') }}\n        ,mas.latest_rank\n        ,DENSE_RANK() OVER (PARTITION BY {{ dbtvault.prefix([src_pk], 'mas') }}\n            ORDER BY {{ dbtvault.prefix([src_hashdiff], 'mas', alias_target='target') }}, {{ dbtvault.prefix([src_cdk], 'mas') }} ASC) AS check_rank\n    FROM\n    (\n    SELECT {{ dbtvault.prefix([src_pk], 'inner_mas', alias_target='target') }}\n        ,{{ dbtvault.prefix([src_hashdiff], 'inner_mas', alias_target='target') }}\n        ,{{ dbtvault.prefix([src_cdk], 'inner_mas', alias_target='target') }}\n        ,{{ dbtvault.prefix([src_ldts], 'inner_mas', alias_target='target') }}\n        ,RANK() OVER (PARTITION BY {{ dbtvault.prefix([src_pk], 'inner_mas') }}\n            ORDER BY {{ dbtvault.prefix([src_ldts], 'inner_mas') }} DESC) AS latest_rank\n    FROM {{ this }} AS inner_mas\n    INNER JOIN (SELECT DISTINCT {{ dbtvault.prefix([src_pk], 's') }} FROM source_data as s ) AS spk\n        ON {{ dbtvault.multikey([src_pk], prefix=['inner_mas', 'spk'], condition='=') }}\n    ) AS mas\n    WHERE latest_rank = 1\n),\n\n{# Select summary details for each group of latest records -#}\nlatest_group_details AS (\n    SELECT {{ dbtvault.prefix([src_pk], 'lr') }}\n        ,{{ dbtvault.prefix([src_ldts], 'lr') }}\n        ,MAX(lr.check_rank) AS latest_count\n    FROM latest_records AS lr\n    GROUP BY {{ dbtvault.prefix([src_pk], 'lr') }}, {{ dbtvault.prefix([src_ldts], 'lr') }}\n),\n\n{# endif any_incremental -#}\n{%- endif %}\n\n{# Select groups of source records where at least one member does not appear in a group of latest records -#}\nrecords_to_insert AS (\n{% if not dbtvault.is_any_incremental() %}\n    SELECT {{ dbtvault.alias_all(source_cols, 'source_data') }}\n    FROM source_data\n{%- endif %}\n\n{# if any_incremental -#}\n{% if dbtvault.is_any_incremental() %}\n    SELECT {{ dbtvault.alias_all(source_cols, 'source_data_with_count') }}\n    FROM source_data_with_count\n    WHERE EXISTS\n    (\n        SELECT 1\n        FROM source_data_with_count AS stage\n        WHERE NOT EXISTS\n        (\n            SELECT 1\n            FROM\n            (\n                SELECT {{ dbtvault.prefix([src_pk], 'lr', alias_target='target') }}\n                ,{{ dbtvault.prefix([src_hashdiff], 'lr', alias_target='target') }}\n                ,{{ dbtvault.prefix([src_cdk], 'lr', alias_target='target') }}\n                ,{{ dbtvault.prefix([src_ldts], 'lr', alias_target='target') }}\n                ,lg.latest_count\n                FROM latest_records AS lr\n                INNER JOIN latest_group_details AS lg\n                    ON {{ dbtvault.multikey([src_pk], prefix=['lr', 'lg'], condition='=') }}\n                    AND {{ dbtvault.prefix([src_ldts], 'lr') }} = {{ dbtvault.prefix([src_ldts], 'lg') }}\n            ) AS active_records\n            WHERE {{ dbtvault.multikey([src_pk], prefix=['stage', 'active_records'], condition='=') }}\n                AND {{ dbtvault.prefix([src_hashdiff], 'stage') }} = {{ dbtvault.prefix([src_hashdiff], 'active_records', alias_target='target') }}\n{# In order to maintain the parallel with the standard satellite, we don''t allow for groups of records to be updated if the ldts is the only difference #}\n{#        AND {{ dbtvault.prefix([src_ldts], 'stage') }} = {{ dbtvault.prefix([src_ldts], 'active_records') }} #}\n                AND {{ dbtvault.multikey(src_cdk, prefix=['stage', 'active_records'], condition='=') }}\n                AND stage.source_count = active_records.latest_count\n        )\n        AND {{ dbtvault.multikey([src_pk], prefix=['source_data_with_count', 'stage'], condition='=') }}\n    )\n{# endif any_incremental -#}\n{%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental", "macro.dbtvault.alias_all"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.666229}, "macro.dbtvault.bigquery__t_link": {"unique_id": "macro.dbtvault.bigquery__t_link", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/bigquery/t_link.sql", "original_file_path": "macros/tables/bigquery/t_link.sql", "name": "bigquery__t_link", "macro_sql": "{%- macro bigquery__t_link(src_pk, src_fk, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n{{ dbtvault.default__t_link(src_pk=src_pk, src_fk=src_fk, src_payload=src_payload,\n                            src_eff=src_eff, src_ldts=src_ldts, src_source=src_source,\n                            source_model=source_model) }}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__t_link"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.667111}, "macro.dbtvault.bigquery__sat": {"unique_id": "macro.dbtvault.bigquery__sat", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/bigquery/sat.sql", "original_file_path": "macros/tables/bigquery/sat.sql", "name": "bigquery__sat", "macro_sql": "{%- macro bigquery__sat(src_pk, src_hashdiff, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_hashdiff=src_hashdiff, src_payload=src_payload,\n                                       src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_hashdiff = dbtvault.escape_column_names(src_hashdiff) -%}\n{%- set src_payload = dbtvault.escape_column_names(src_payload) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_payload, src_eff, src_ldts, src_source]) -%}\n{%- set rank_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_ldts]) -%}\n{%- set pk_cols = dbtvault.expand_column_list(columns=[src_pk]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + dbtvault.escape_column_names([config.get('rank_column')]) -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\nWITH source_data AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ dbtvault.prefix(source_cols_with_rank, 'a', alias_target='source') }}\n    {%- else %}\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='source') }}\n    {%- endif %}\n    FROM {{ ref(source_model) }} AS a\n    WHERE {{ dbtvault.multikey(src_pk, prefix='a', condition='IS NOT NULL') }}\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n    AND __PERIOD_FILTER__\n    {% elif model.config.materialized == 'vault_insert_by_rank' %}\n    AND __RANK_FILTER__\n    {% endif %}\n),\n\n{% if dbtvault.is_any_incremental() %}\n\nlatest_records AS (\n    SELECT {{ dbtvault.prefix(rank_cols, 'a', alias_target='target') }}\n    FROM\n    (\n        SELECT {{ dbtvault.prefix(rank_cols, 'current_records', alias_target='target') }},\n            RANK() OVER (\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'current_records') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'current_records') }} DESC\n            ) AS rank\n        FROM {{ this }} AS current_records\n            JOIN (\n                SELECT DISTINCT {{ dbtvault.prefix([src_pk], 'source_data') }}\n                FROM source_data\n            ) AS source_records\n                ON {{ dbtvault.multikey(src_pk, prefix=['current_records','source_records'], condition='=') }}\n    ) AS a\n    WHERE a.rank = 1\n),\n\n{%- endif %}\n\nrecords_to_insert AS (\n    SELECT DISTINCT {{ dbtvault.alias_all(source_cols, 'stage') }}\n    FROM source_data AS stage\n    {%- if dbtvault.is_any_incremental() %}\n    LEFT JOIN latest_records\n    ON {{ dbtvault.multikey(src_pk, prefix=['latest_records','stage'], condition='=') }}\n    WHERE {{ dbtvault.prefix([src_hashdiff], 'latest_records', alias_target='target') }} != {{ dbtvault.prefix([src_hashdiff], 'stage') }}\n        OR {{ dbtvault.prefix([src_hashdiff], 'latest_records', alias_target='target') }} IS NULL\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental", "macro.dbtvault.alias_all"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.6752489}, "macro.dbtvault.bigquery__hub": {"unique_id": "macro.dbtvault.bigquery__hub", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/bigquery/hub.sql", "original_file_path": "macros/tables/bigquery/hub.sql", "name": "bigquery__hub", "macro_sql": "{%- macro bigquery__hub(src_pk, src_nk, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_nk=src_nk,\n                                       src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_nk = dbtvault.escape_column_names(src_nk) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_nk, src_ldts, src_source]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + dbtvault.escape_column_names([config.get('rank_column')]) -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{{ 'WITH ' -}}\n\n{%- if not (source_model is iterable and source_model is not string) -%}\n    {%- set source_model = [source_model] -%}\n{%- endif -%}\n\n{%- set ns = namespace(last_cte= \"\") -%}\n\n{%- for src in source_model -%}\n\n{%- set source_number = loop.index | string -%}\n\n    row_rank_{{ source_number }} AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ dbtvault.prefix(source_cols_with_rank, 'rr') }},\n    {%- else %}\n    SELECT {{ dbtvault.prefix(source_cols, 'rr') }},\n    {%- endif %}\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'rr') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'rr') }}\n           ) AS row_number\n    FROM {{ ref(src) }} AS rr\n    WHERE {{ dbtvault.multikey(src_pk, prefix='rr', condition='IS NOT NULL') }}\n    QUALIFY row_number = 1\n    {%- set ns.last_cte = \"row_rank_{}\".format(source_number) %}\n),\n\n{% endfor -%}\n{% if source_model | length > 1 %}\nstage_union AS (\n    {%- for src in source_model %}\n    SELECT * FROM row_rank_{{ loop.index | string }}\n    {%- if not loop.last %}\n    UNION ALL\n    {%- endif %}\n    {%- endfor %}\n    {%- set ns.last_cte = \"stage_union\" %}\n),\n{%- endif -%}\n{%- if model.config.materialized == 'vault_insert_by_period' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __PERIOD_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- elif model.config.materialized == 'vault_insert_by_rank' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __RANK_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- endif -%}\n{%- if source_model | length > 1 %}\n\n    row_rank_union AS (\n    SELECT ru.*,\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'ru') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'ru') }}, {{ dbtvault.prefix([src_source], 'ru') }} ASC\n           ) AS row_rank_number\n    FROM {{ ns.last_cte }} AS ru\n    WHERE {{ dbtvault.multikey(src_pk, prefix='ru', condition='IS NOT NULL') }}\n    QUALIFY row_rank_number = 1\n    {%- set ns.last_cte = \"row_rank_union\" %}\n),\n\n{% endif %}\nrecords_to_insert AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='target') }}\n    FROM {{ ns.last_cte }} AS a\n    {%- if dbtvault.is_any_incremental() %}\n    LEFT JOIN {{ this }} AS d\n    ON {{ dbtvault.multikey(src_pk, prefix=['a','d'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='d', condition='IS NULL') }}\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.6854012}, "macro.dbtvault.bigquery__eff_sat": {"unique_id": "macro.dbtvault.bigquery__eff_sat", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/bigquery/eff_sat.sql", "original_file_path": "macros/tables/bigquery/eff_sat.sql", "name": "bigquery__eff_sat", "macro_sql": "{%- macro bigquery__eff_sat(src_pk, src_dfk, src_sfk, src_start_date, src_end_date, src_eff, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_dfk=src_dfk, src_sfk=src_sfk,\n                                       src_start_date=src_start_date, src_end_date=src_end_date,\n                                       src_eff=src_eff, src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_dfk = dbtvault.escape_column_names(src_dfk) -%}\n{%- set src_sfk = dbtvault.escape_column_names(src_sfk) -%}\n{%- set src_start_date = dbtvault.escape_column_names(src_start_date) -%}\n{%- set src_end_date = dbtvault.escape_column_names(src_end_date) -%}\n{%- set src_eff = dbtvault.escape_column_names(src_eff) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_dfk, src_sfk, src_start_date, src_end_date, src_eff, src_ldts, src_source]) -%}\n{%- set fk_cols = dbtvault.expand_column_list(columns=[src_dfk, src_sfk]) -%}\n{%- set dfk_cols = dbtvault.expand_column_list(columns=[src_dfk]) -%}\n{%- set is_auto_end_dating = config.get('is_auto_end_dating', default=false) %}\n\n{%- set max_datetime = var('max_datetime', '9999-12-31 23:59:59.999999') %}\n\n{{- dbtvault.prepend_generated_by() }}\n\nWITH source_data AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='source') }}\n    FROM {{ ref(source_model) }} AS a\n    WHERE {{ dbtvault.multikey(src_dfk, prefix='a', condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(src_sfk, prefix='a', condition='IS NOT NULL') }}\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n    AND __PERIOD_FILTER__\n    {%- elif model.config.materialized == 'vault_insert_by_rank' %}\n    AND __RANK_FILTER__\n    {%- endif %}\n),\n\n{%- if dbtvault.is_any_incremental() %}\n\n{# Selecting the most recent records for each link hashkey -#}\nlatest_records_unranked AS (\n    SELECT {{ dbtvault.alias_all(source_cols, 'b') }},\n           ROW_NUMBER() OVER (\n                PARTITION BY {{ dbtvault.prefix([src_pk], 'b') }}\n                ORDER BY b.{{ src_ldts }} DESC\n           ) AS row_num\n    FROM {{ this }} AS b\n),\n\nlatest_records AS (\n    SELECT *\n    FROM latest_records_unranked\n    WHERE row_num = 1\n),\n\n{# Selecting the open records of the most recent records for each link hashkey -#}\nlatest_open AS (\n    SELECT {{ dbtvault.alias_all(source_cols, 'c') }}\n    FROM latest_records AS c\n    WHERE DATE(c.{{ src_end_date }}) = CAST(PARSE_DATETIME('%F %H:%M:%E6S', '{{ max_datetime }}') AS DATE)\n),\n\n{# Selecting the closed records of the most recent records for each link hashkey -#}\nlatest_closed AS (\n    SELECT {{ dbtvault.alias_all(source_cols, 'd') }}\n    FROM latest_records AS d\n    WHERE DATE(d.{{ src_end_date }}) != CAST(PARSE_DATETIME('%F %H:%M:%E6S', '{{ max_datetime }}') AS DATE)\n),\n\n{# Identifying the completely new link relationships to be opened in eff sat -#}\nnew_open_records AS (\n    SELECT DISTINCT\n        {{ dbtvault.alias_all(source_cols, 'f') }}\n    FROM source_data AS f\n    LEFT JOIN latest_records AS lr\n    ON {{ dbtvault.multikey(src_pk, prefix=['f','lr'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='lr', condition='IS NULL') }}\n),\n\n{# Identifying the currently closed link relationships to be reopened in eff sat -#}\nnew_reopened_records AS (\n    SELECT DISTINCT\n        {{ dbtvault.prefix([src_pk], 'lc') }},\n        {{ dbtvault.alias_all(fk_cols, 'lc') }},\n        lc.{{ src_start_date }} AS {{ src_start_date }},\n        g.{{ src_end_date }} AS {{ src_end_date }},\n        g.{{ src_eff }} AS {{ src_eff }},\n        g.{{ src_ldts }},\n        g.{{ src_source }}\n    FROM source_data AS g\n    INNER JOIN latest_closed AS lc\n    ON {{ dbtvault.multikey(src_pk, prefix=['g','lc'], condition='=') }}\n    WHERE CAST((g.{{ src_end_date }}) AS DATE) = CAST(PARSE_DATETIME('%F %H:%M:%E6S', '{{ max_datetime }}') AS DATE)\n),\n\n{%- if is_auto_end_dating %}\n\n{# Creating the closing records -#}\n{# Identifying the currently open relationships that need to be closed due to change in SFK(s) -#}\nnew_closed_records AS (\n    SELECT DISTINCT\n        {{ dbtvault.prefix([src_pk], 'lo') }},\n        {{ dbtvault.alias_all(fk_cols, 'lo') }},\n        lo.{{ src_start_date }} AS {{ src_start_date }},\n        h.{{ src_eff }} AS {{ src_end_date }},\n        h.{{ src_eff }} AS {{ src_eff }},\n        h.{{ src_ldts }},\n        lo.{{ src_source }}\n    FROM source_data AS h\n    INNER JOIN latest_open AS lo\n    ON {{ dbtvault.multikey(src_dfk, prefix=['lo', 'h'], condition='=') }}\n    WHERE ({{ dbtvault.multikey(src_sfk, prefix=['lo', 'h'], condition='<>', operator='OR') }})\n),\n\n{#- else if is_auto_end_dating -#}\n{% else %}\n\nnew_closed_records AS (\n    SELECT DISTINCT\n        lo.{{ src_pk }},\n        {{ dbtvault.alias_all(fk_cols, 'lo') }},\n        lo.{{ src_start_date }} AS {{ src_start_date }},\n        h.{{ src_eff }} AS {{ src_end_date }},\n        h.{{ src_eff }} AS {{ src_eff }},\n        h.{{ src_ldts }},\n        lo.{{ src_source }}\n    FROM source_data AS h\n    LEFT JOIN Latest_open AS lo\n    ON lo.{{ src_pk }} = h.{{ src_pk }}\n    LEFT JOIN latest_closed AS lc\n    ON lc.{{ src_pk }} = h.{{ src_pk }}\n    WHERE CAST((h.{{ src_end_date }}) AS DATE) != CAST(PARSE_DATETIME('%F %H:%M:%E6S', '{{ max_datetime }}') AS DATE)\n    AND lo.{{ src_pk }} IS NOT NULL\n    AND lc.{{ src_pk }} IS NULL\n),\n\n{#- end if is_auto_end_dating -#}\n{%- endif %}\n\nrecords_to_insert AS (\n    SELECT * FROM new_open_records\n    UNION DISTINCT\n    SELECT * FROM new_reopened_records\n    UNION DISTINCT\n    SELECT * FROM new_closed_records\n)\n\n{#- else if not dbtvault.is_any_incremental() -#}\n{%- else %}\n\nrecords_to_insert AS (\n    SELECT {{ dbtvault.alias_all(source_cols, 'i') }}\n    FROM source_data AS i\n)\n\n{#- end if not dbtvault.is_any_incremental() -#}\n{%- endif %}\n\nSELECT *\nFROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental", "macro.dbtvault.alias_all"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.696992}, "macro.dbtvault.bigquery__link": {"unique_id": "macro.dbtvault.bigquery__link", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/bigquery/link.sql", "original_file_path": "macros/tables/bigquery/link.sql", "name": "bigquery__link", "macro_sql": "{%- macro bigquery__link(src_pk, src_fk, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_fk=src_fk,\n                                       src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_fk, src_ldts, src_source]) -%}\n{%- set fk_cols = dbtvault.expand_column_list([src_fk]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + [config.get('rank_column')] -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{{ 'WITH ' -}}\n\n{%- if not (source_model is iterable and source_model is not string) -%}\n    {%- set source_model = [source_model] -%}\n{%- endif -%}\n\n{%- set ns = namespace(last_cte= \"\") -%}\n\n{%- for src in source_model -%}\n\n{%- set source_number = loop.index | string -%}\n\nrow_rank_{{ source_number }} AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ dbtvault.prefix(source_cols_with_rank, 'rr') }},\n    {%- else %}\n    SELECT {{ dbtvault.prefix(source_cols, 'rr') }},\n    {%- endif %}\n        ROW_NUMBER() OVER(\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'rr') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'rr') }}\n        ) AS row_number\n    FROM {{ ref (src) }} AS rr\n    {%- if source_model | length == 1 %}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='rr', condition ='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(fk_cols, prefix='rr', condition ='IS NOT NULL') }}\n    QUALIFY row_number = 1\n    {%- endif %}\n    {%- set ns.last_cte = \"row_rank_{}\".format(source_number) %}\n    ),\n\n{% endfor -%}\n\n{% if source_model | length > 1 %}\nstage_union AS (\n    {%- for src in source_model %}\n    SELECT * FROM row_rank_{{ loop.index | string }}\n    {%- if not loop.last %}\n    UNION ALL\n    {%- endif %}\n    {%- endfor %}\n    {%- set ns.last_cte = \"stage_union\" %}\n),\n{%- endif -%}\n{%- if model.config.materialized == 'vault_insert_by_period' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __PERIOD_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- elif model.config.materialized == 'vault_insert_by_rank' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __RANK_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{% endif %}\n{%- if source_model | length > 1 %}\n\nrow_rank_union AS (\n    SELECT ru.*,\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'ru') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'ru') }}, {{ dbtvault.prefix([src_source], 'ru') }} ASC\n           ) AS row_rank_number\n    FROM {{ ns.last_cte }} AS ru\n    WHERE {{ dbtvault.multikey(src_pk, prefix='ru', condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(fk_cols, prefix='ru', condition='IS NOT NULL') }}\n    QUALIFY row_rank_number = 1\n    {%- set ns.last_cte = \"row_rank_union\" %}\n),\n{% endif %}\nrecords_to_insert AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='target') }}\n    FROM {{ ns.last_cte }} AS a\n    {%- if dbtvault.is_any_incremental() %}\n    LEFT JOIN {{ this }} AS d\n    ON {{ dbtvault.multikey(src_pk, prefix=['a','d'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='d', condition='IS NULL') }}\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.7076569}, "macro.dbtvault.xts": {"unique_id": "macro.dbtvault.xts", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/xts.sql", "original_file_path": "macros/tables/snowflake/xts.sql", "name": "xts", "macro_sql": "{%- macro xts(src_pk, src_satellite, src_ldts, src_source, source_model) -%}\n    {{- adapter.dispatch('xts', 'dbtvault')(src_pk=src_pk,\n                                            src_satellite=src_satellite,\n                                            src_ldts=src_ldts,\n                                            src_source=src_source,\n                                            source_model=source_model) -}}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__xts"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.711057}, "macro.dbtvault.default__xts": {"unique_id": "macro.dbtvault.default__xts", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/xts.sql", "original_file_path": "macros/tables/snowflake/xts.sql", "name": "default__xts", "macro_sql": "{%- macro default__xts(src_pk, src_satellite, src_ldts, src_source, source_model) -%}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{%- if not (source_model is iterable and source_model is not string) -%}\n    {%- set source_model = [source_model] -%}\n{%- endif %}\n\n{{ 'WITH ' }}\n{%- for src in source_model %}\n    {%- for satellite in src_satellite.items() -%}\n        {%- set satellite_name = (satellite[1]['sat_name'].values() | list) [0] -%}\n        {%- set hashdiff = (satellite[1]['hashdiff'].values() | list) [0] %}\n\n        satellite_{{ satellite_name }}_from_{{ src }} AS (\n            SELECT {{ dbtvault.prefix([src_pk], 's') }}, s.{{ dbtvault.escape_column_names(hashdiff) }} AS HASHDIFF, s.{{ dbtvault.escape_column_names(satellite_name) }} AS SATELLITE_NAME, s.{{ src_ldts }}, s.{{ src_source }}\n            FROM {{ ref(src) }} AS s\n            WHERE {{ dbtvault.multikey(src_pk, prefix='s', condition='IS NOT NULL') }}\n        ),\n    {%- endfor %}\n{%- endfor %}\n\nunion_satellites AS (\n    {%- for src in source_model %}\n        {%- for satellite in src_satellite.items() %}\n    SELECT * FROM satellite_{{ (satellite[1]['sat_name'].values() | list) [0] }}_from_{{ src }}\n            {%- if not loop.last %}\n    UNION ALL\n            {%- endif %}\n        {%- endfor %}\n        {%- if not loop.last %}\n    UNION ALL\n        {%- endif %}\n    {%- endfor %}\n),\n\nrecords_to_insert AS (\n    SELECT DISTINCT union_satellites.* FROM union_satellites\n    {%- if dbtvault.is_vault_insert_by_period() or is_incremental() %}\n    LEFT JOIN {{ this }} AS d\n    ON (union_satellites.{{ 'HASHDIFF' }} = d.{{ 'HASHDIFF' }}\n        AND union_satellites.{{ src_ldts }} = d.{{ src_ldts }}\n        AND union_satellites.{{ 'SATELLITE_NAME' }} = d.{{ 'SATELLITE_NAME' }}\n    )\n    WHERE {{ dbtvault.prefix(['HASHDIFF'], 'd') }} IS NULL\n    AND {{ dbtvault.prefix([ src_ldts ], 'd') }} IS NULL\n    AND {{ dbtvault.prefix([ 'SATELLITE_NAME' ], 'd') }} IS NULL\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.escape_column_names", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_vault_insert_by_period", "macro.dbt.is_incremental"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.714968}, "macro.dbtvault.pit": {"unique_id": "macro.dbtvault.pit", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/pit.sql", "original_file_path": "macros/tables/snowflake/pit.sql", "name": "pit", "macro_sql": "{%- macro pit(src_pk, as_of_dates_table, satellites, stage_tables, src_ldts, source_model ) -%}\n\n{# TODO Should the length of the ghost_pk zero hash be determined by the hashing option being used, i.e. MD5 = 16, SHA = 32 ? #}\n\n    {{- adapter.dispatch('pit', 'dbtvault')(source_model=source_model, src_pk=src_pk,\n                                            as_of_dates_table=as_of_dates_table,\n                                            satellites=satellites,\n                                            stage_tables=stage_tables,\n                                            src_ldts=src_ldts) -}}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__pit"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.724122}, "macro.dbtvault.default__pit": {"unique_id": "macro.dbtvault.default__pit", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/pit.sql", "original_file_path": "macros/tables/snowflake/pit.sql", "name": "default__pit", "macro_sql": "{%- macro default__pit(src_pk, as_of_dates_table, satellites, stage_tables, src_ldts, source_model) -%}\n\n{{- dbtvault.check_required_parameters(source_model=source_model, src_pk=src_pk,\n                                       satellites=satellites,\n                                       stage_tables=stage_tables,\n                                       src_ldts=src_ldts) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{%- if (as_of_dates_table is none) and execute -%}\n    {%- set error_message -%}\n    \"PIT error: Missing as_of_dates table configuration. A as_of_dates_table must be provided.\"\n    {%- endset -%}\n    {{- exceptions.raise_compiler_error(error_message) -}}\n{%- endif -%}\n\n{#- Acquiring the source relation for the AS_OF table -#}\n{%- if as_of_dates_table is mapping and as_of_dates_table is not none -%}\n    {%- set source_name = as_of_dates_table | first -%}\n    {%- set source_table_name = as_of_dates_table[source_name] -%}\n    {%- set as_of_table_relation = source(source_name, source_table_name) -%}\n{%- elif as_of_dates_table is not mapping and as_of_dates_table is not none -%}\n    {%- set as_of_table_relation = ref(as_of_dates_table) -%}\n{%- endif -%}\n\n{#- Setting ghost values to replace NULLS -#}\n{%- set ghost_pk = '0000000000000000' -%}\n{%- set ghost_date = '1900-01-01 00:00:00.000' %}\n\n{# Stating the dependancies on the stage tables outside of the If STATEMENT #}\n{% for stg in stage_tables -%}\n    {{ \"-- depends_on: \" ~ ref(stg) }}\n{% endfor %}\n\n{#- Setting the new AS_OF dates CTE name -#}\n{%- if dbtvault.is_any_incremental() -%}\n{%- set new_as_of_dates_cte = 'new_rows_as_of' -%}\n{%- else -%}\n{%- set new_as_of_dates_cte = 'as_of_dates' -%}\n{%- endif %}\n\nWITH as_of_dates AS (\n    SELECT * FROM {{ as_of_table_relation }}\n),\n\n{%- if dbtvault.is_any_incremental() %}\n\nlast_safe_load_datetime AS (\n    SELECT MIN(LOAD_DATETIME) AS LAST_SAFE_LOAD_DATETIME FROM (\n    {%- for stg in stage_tables -%}\n        {%- set stage_ldts = stage_tables[stg] %}\n        SELECT MIN({{ stage_ldts }}) AS LOAD_DATETIME FROM {{ (ref(stg)) }}\n        {{ \"UNION ALL\" if not loop.last }}\n    {%- endfor %}\n    ) a\n),\n\nas_of_grain_old_entries AS (\n    SELECT DISTINCT AS_OF_DATE FROM {{ this }}\n),\n\nas_of_grain_lost_entries AS (\n    SELECT a.AS_OF_DATE\n    FROM as_of_grain_old_entries AS a\n    LEFT OUTER JOIN as_of_dates AS b\n    ON a.AS_OF_DATE = b.AS_OF_DATE\n    WHERE b.AS_OF_DATE IS NULL\n),\n\nas_of_grain_new_entries AS (\n    SELECT a.AS_OF_DATE\n    FROM as_of_dates AS a\n    LEFT OUTER JOIN as_of_grain_old_entries AS b\n    ON a.AS_OF_DATE = b.AS_OF_DATE\n    WHERE b.AS_OF_DATE IS NULL\n),\n\nmin_date AS (\n    SELECT min(AS_OF_DATE) AS MIN_DATE\n    FROM as_of_dates\n),\n\nbackfill_as_of AS (\n    SELECT AS_OF_DATE\n    FROM as_of_dates AS a\n    WHERE a.AS_OF_DATE < (SELECT LAST_SAFE_LOAD_DATETIME FROM last_safe_load_datetime)\n),\n\nnew_rows_pks AS (\n    SELECT {{ dbtvault.prefix([src_pk], 'a') }}\n    FROM {{ ref(source_model) }} AS a\n    WHERE a.{{ src_ldts }} >= (SELECT LAST_SAFE_LOAD_DATETIME FROM last_safe_load_datetime)\n),\n\nnew_rows_as_of AS (\n    SELECT AS_OF_DATE\n    FROM as_of_dates AS a\n    WHERE a.AS_OF_DATE >= (SELECT LAST_SAFE_LOAD_DATETIME FROM last_safe_load_datetime)\n    UNION\n    SELECT AS_OF_DATE\n    FROM as_of_grain_new_entries\n),\n\noverlap AS (\n    SELECT a.*\n    FROM {{ this }} AS a\n    INNER JOIN {{ ref(source_model) }} as b\n    ON {{ dbtvault.multikey(src_pk, prefix=['a','b'], condition='=') }}\n    WHERE a.AS_OF_DATE >= (SELECT MIN_DATE FROM min_date)\n    AND a.AS_OF_DATE < (SELECT LAST_SAFE_LOAD_DATETIME FROM last_safe_load_datetime)\n    AND a.AS_OF_DATE NOT IN (SELECT AS_OF_DATE FROM as_of_grain_lost_entries)\n),\n\n{#- Back-fill any newly arrived hubs, set all historical pit dates to ghost records -#}\n\nbackfill_rows_as_of_dates AS (\n    SELECT\n        {{ dbtvault.prefix([src_pk], 'a') }},\n        b.AS_OF_DATE\n    FROM new_rows_pks AS a\n    INNER JOIN backfill_as_of AS b\n        ON (1=1 )\n),\n\nbackfill AS (\n    SELECT\n        {{ dbtvault.prefix([src_pk], 'a') }},\n        a.AS_OF_DATE,\n    {%- for sat_name in satellites -%}\n        {%- set sat_pk_name = (satellites[sat_name]['pk'].keys() | list )[0] | upper -%}\n        {%- set sat_ldts_name = (satellites[sat_name]['ldts'].keys() | list )[0] | upper -%}\n        {%- set sat_name = sat_name | upper %}\n        {%- if target.type == \"sqlserver\" -%}\n        CONVERT(BINARY(16), '{{ ghost_pk }}', 2) AS {{ dbtvault.escape_column_names( sat_name ~ '_' ~ sat_pk_name ) }},\n        {%- else -%}\n        CAST('{{ ghost_pk }}' AS BINARY(16)) AS {{ dbtvault.escape_column_names( sat_name ~ '_' ~ sat_pk_name ) }},\n        {%- endif -%}\n        CAST('{{ ghost_date }}' AS {{ dbtvault.type_timestamp() }}) AS {{ dbtvault.escape_column_names( sat_name ~ '_' ~ sat_ldts_name ) }}\n        {{- ',' if not loop.last -}}\n    {%- endfor %}\n    FROM backfill_rows_as_of_dates AS a\n\n    {% for sat_name in satellites -%}\n        {%- set sat_pk_name = (satellites[sat_name]['pk'].keys() | list )[0] -%}\n        {%- set sat_ldts_name = (satellites[sat_name]['ldts'].keys() | list )[0] -%}\n        {%- set sat_pk = dbtvault.escape_column_names(satellites[sat_name]['pk'][sat_pk_name]) -%}\n        {%- set sat_ldts = dbtvault.escape_column_names(satellites[sat_name]['ldts'][sat_ldts_name]) -%}\n        LEFT JOIN {{ ref(sat_name) }} AS {{ dbtvault.escape_column_names( sat_name | lower ~ '_src' ) }}\n        {{ \"ON\" | indent(4) }} a.{{ src_pk }} = {{ dbtvault.escape_column_names( sat_name | lower ~ '_src' ) }}.{{ sat_pk }}\n        {{ \"AND\" | indent(4) }} {{ dbtvault.escape_column_names( sat_name | lower ~ '_src' ) }}.{{ sat_ldts }} <= a.AS_OF_DATE\n    {% endfor -%}\n\n    GROUP BY\n        {{ dbtvault.prefix([src_pk], 'a') }}, a.AS_OF_DATE\n),\n{%- endif %}\n\nnew_rows_as_of_dates AS (\n    SELECT\n        {{ dbtvault.prefix([src_pk], 'a') }},\n        b.AS_OF_DATE\n    FROM {{ ref(source_model) }} AS a\n    INNER JOIN {{ new_as_of_dates_cte }} AS b\n    ON (1=1)\n),\n\nnew_rows AS (\n    SELECT\n        {{ dbtvault.prefix([src_pk], 'a') }},\n        a.AS_OF_DATE,\n    {%- for sat_name in satellites -%}\n        {%- set sat_pk_name = (satellites[sat_name]['pk'].keys() | list )[0] -%}\n        {%- set sat_ldts_name = (satellites[sat_name]['ldts'].keys() | list )[0] -%}\n        {%- set sat_pk = dbtvault.escape_column_names(satellites[sat_name]['pk'][sat_pk_name]) -%}\n        {%- set sat_ldts = dbtvault.escape_column_names(satellites[sat_name]['ldts'][sat_ldts_name]) %}\n        {%- if target.type == \"sqlserver\" -%}\n        COALESCE(MAX({{ dbtvault.escape_column_names( sat_name | lower ~ '_src' ) }}.{{ sat_pk }}), CONVERT(BINARY(16), '{{ ghost_pk }}', 2)) AS {{ dbtvault.escape_column_names( sat_name | upper ~ '_' ~ sat_pk_name | upper ) }},\n        {%- else -%}\n        COALESCE(MAX({{ dbtvault.escape_column_names( sat_name | lower ~ '_src' ) }}.{{ sat_pk }}), CAST('{{ ghost_pk }}' AS BINARY(16))) AS {{ dbtvault.escape_column_names( sat_name | upper ~ '_' ~ sat_pk_name | upper ) }},\n        {%- endif -%}\n        COALESCE(MAX({{ dbtvault.escape_column_names( sat_name | lower ~ '_src' ) }}.{{ sat_ldts }}), CAST('{{ ghost_date }}' AS {{ dbtvault.type_timestamp() }})) AS {{ dbtvault.escape_column_names( sat_name | upper ~ '_' ~ sat_ldts_name | upper ) }}\n        {{- \",\" if not loop.last }}\n    {%- endfor %}\n    FROM new_rows_as_of_dates AS a\n\n    {% for sat_name in satellites -%}\n        {%- set sat_pk_name = (satellites[sat_name]['pk'].keys() | list )[0] -%}\n        {%- set sat_ldts_name = (satellites[sat_name]['ldts'].keys() | list )[0] -%}\n        {%- set sat_pk = dbtvault.escape_column_names(satellites[sat_name]['pk'][sat_pk_name]) -%}\n        {%- set sat_ldts = dbtvault.escape_column_names(satellites[sat_name]['ldts'][sat_ldts_name]) -%}\n        LEFT JOIN {{ ref(sat_name) }} AS {{ dbtvault.escape_column_names( sat_name | lower ~ '_src' ) }}\n        {{ \"ON\" | indent(4) }} a.{{ src_pk }} = {{ dbtvault.escape_column_names( sat_name | lower ~ '_src' ) }}.{{ sat_pk }}\n        {{ \"AND\" | indent(4) }} {{ dbtvault.escape_column_names( sat_name | lower ~ '_src' ) }}.{{ sat_ldts }} <= a.AS_OF_DATE\n    {% endfor -%}\n\n    GROUP BY\n        {{ dbtvault.prefix([src_pk], 'a') }}, a.AS_OF_DATE\n),\n\npit AS (\n    SELECT * FROM new_rows\n{%- if dbtvault.is_any_incremental() %}\n    UNION ALL\n    SELECT * FROM overlap\n    UNION ALL\n    SELECT * FROM backfill\n\n{%- endif %}\n)\n\nSELECT DISTINCT * FROM pit\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.is_any_incremental", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.737209}, "macro.dbtvault.ma_sat": {"unique_id": "macro.dbtvault.ma_sat", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/ma_sat.sql", "original_file_path": "macros/tables/snowflake/ma_sat.sql", "name": "ma_sat", "macro_sql": "{%- macro ma_sat(src_pk, src_cdk, src_hashdiff, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n    {{- adapter.dispatch('ma_sat', 'dbtvault')(src_pk=src_pk, src_cdk=src_cdk, src_hashdiff=src_hashdiff,\n                                               src_payload=src_payload, src_eff=src_eff, src_ldts=src_ldts,\n                                               src_source=src_source, source_model=source_model) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__ma_sat"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.740829}, "macro.dbtvault.default__ma_sat": {"unique_id": "macro.dbtvault.default__ma_sat", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/ma_sat.sql", "original_file_path": "macros/tables/snowflake/ma_sat.sql", "name": "default__ma_sat", "macro_sql": "\n\n{%- macro default__ma_sat(src_pk, src_cdk, src_hashdiff, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_cdk=src_cdk, src_hashdiff=src_hashdiff,\n                                       src_payload=src_payload, src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_cdk = dbtvault.escape_column_names(src_cdk) -%}\n{%- set src_hashdiff = dbtvault.escape_column_names(src_hashdiff) -%}\n{%- set src_payload = dbtvault.escape_column_names(src_payload) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_cdk, src_payload, src_eff, src_ldts, src_source]) -%}\n{%- set rank_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_ldts]) -%}\n{%- set cdk_cols = dbtvault.expand_column_list(columns=[src_cdk]) -%}\n{%- set cols_for_latest = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_cdk, src_ldts]) %}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' -%}\n    {%- set source_cols_with_rank = source_cols + [config.get('rank_column')] -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{# Select unique source records #}\nWITH source_data AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT DISTINCT {{ dbtvault.prefix(source_cols_with_rank, 's', alias_target='source') }}\n    {%- else %}\n    SELECT DISTINCT {{ dbtvault.prefix(source_cols, 's', alias_target='source') }}\n    {%- endif %}\n    {% if dbtvault.is_any_incremental() %}\n        ,COUNT(DISTINCT {{ dbtvault.prefix([src_hashdiff], 's', alias_target='source') }}, {{ dbtvault.prefix(cdk_cols, 's', alias_target='source') }})\n            OVER (PARTITION BY {{ dbtvault.prefix([src_pk], 's') }}) AS source_count\n    {% endif %}\n    FROM {{ ref(source_model) }} AS s\n    WHERE {{ dbtvault.multikey([src_pk], prefix='s', condition='IS NOT NULL') }}\n    {%- for child_key in cdk_cols %}\n        AND {{ dbtvault.multikey(child_key, prefix='s', condition='IS NOT NULL') }}\n    {%- endfor %}\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n        AND __PERIOD_FILTER__\n    {%- elif model.config.materialized == 'vault_insert_by_rank' %}\n        AND __RANK_FILTER__\n    {%- endif %}\n),\n\n{# if any_incremental -#}\n{% if dbtvault.is_any_incremental() %}\n\n{# Select latest records from satellite, restricted to PKs in source data -#}\nlatest_records AS (\n    SELECT {{ dbtvault.prefix(cols_for_latest, 'mas', alias_target='target') }}\n        ,mas.latest_rank\n        ,DENSE_RANK() OVER (PARTITION BY {{ dbtvault.prefix([src_pk], 'mas') }}\n            ORDER BY {{ dbtvault.prefix([src_hashdiff], 'mas', alias_target='target') }}, {{ dbtvault.prefix(cdk_cols, 'mas') }} ASC) AS check_rank\n    FROM\n    (\n    SELECT {{ dbtvault.prefix(cols_for_latest, 'inner_mas', alias_target='target') }}\n        ,RANK() OVER (PARTITION BY {{ dbtvault.prefix([src_pk], 'inner_mas') }}\n            ORDER BY {{ dbtvault.prefix([src_ldts], 'inner_mas') }} DESC) AS latest_rank\n    FROM {{ this }} AS inner_mas\n    INNER JOIN (SELECT DISTINCT {{ dbtvault.prefix([src_pk], 's') }} FROM source_data as s ) AS spk\n        ON {{ dbtvault.multikey([src_pk], prefix=['inner_mas', 'spk'], condition='=') }}\n    QUALIFY latest_rank = 1\n    ) AS mas\n),\n\n{# Select summary details for each group of latest records -#}\nlatest_group_details AS (\n    SELECT {{ dbtvault.prefix([src_pk], 'lr') }}\n        ,{{ dbtvault.prefix([src_ldts], 'lr') }}\n        ,MAX(lr.check_rank) AS latest_count\n    FROM latest_records AS lr\n    GROUP BY {{ dbtvault.prefix([src_pk], 'lr') }}, {{ dbtvault.prefix([src_ldts], 'lr') }}\n),\n\n{# endif any_incremental -#}\n{%- endif %}\n\n{# Select groups of source records where at least one member does not appear in a group of latest records -#}\nrecords_to_insert AS (\n    SELECT {{ dbtvault.alias_all(source_cols, 'source_data') }}\n    FROM source_data\n\n{# if any_incremental -#}\n{% if dbtvault.is_any_incremental() %}\n    WHERE EXISTS\n    (\n        SELECT 1\n        FROM source_data AS stage\n        WHERE NOT EXISTS\n        (\n            SELECT 1\n            FROM\n            (\n                SELECT {{ dbtvault.prefix(cols_for_latest, 'lr', alias_target='target') }}\n                ,lg.latest_count\n                FROM latest_records AS lr\n                INNER JOIN latest_group_details AS lg\n                    ON {{ dbtvault.multikey([src_pk], prefix=['lr', 'lg'], condition='=') }}\n                    AND {{ dbtvault.prefix([src_ldts], 'lr') }} = {{ dbtvault.prefix([src_ldts], 'lg') }}\n            ) AS active_records\n            WHERE {{ dbtvault.multikey([src_pk], prefix=['stage', 'active_records'], condition='=') }}\n                AND {{ dbtvault.prefix([src_hashdiff], 'stage') }} = {{ dbtvault.prefix([src_hashdiff], 'active_records', alias_target='target') }}\n                AND {{ dbtvault.multikey(cdk_cols, prefix=['stage', 'active_records'], condition='=') }}\n                AND stage.source_count = active_records.latest_count\n        )\n        AND {{ dbtvault.multikey([src_pk], prefix=['source_data', 'stage'], condition='=') }}\n    )\n{# endif any_incremental -#}\n{%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.is_any_incremental", "macro.dbtvault.multikey", "macro.dbtvault.alias_all"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.749516}, "macro.dbtvault.t_link": {"unique_id": "macro.dbtvault.t_link", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/t_link.sql", "original_file_path": "macros/tables/snowflake/t_link.sql", "name": "t_link", "macro_sql": "{%- macro t_link(src_pk, src_fk, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n    {{- adapter.dispatch('t_link', 'dbtvault')(src_pk=src_pk, src_fk=src_fk, src_payload=src_payload,\n                                               src_eff=src_eff, src_ldts=src_ldts, src_source=src_source,\n                                               source_model=source_model) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__t_link"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.751913}, "macro.dbtvault.default__t_link": {"unique_id": "macro.dbtvault.default__t_link", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/t_link.sql", "original_file_path": "macros/tables/snowflake/t_link.sql", "name": "default__t_link", "macro_sql": "\n\n{%- macro default__t_link(src_pk, src_fk, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_fk=src_fk, src_eff=src_eff,\n                                       src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_fk = dbtvault.escape_column_names(src_fk) -%}\n{%- set src_payload = dbtvault.escape_column_names(src_payload) -%}\n{%- set src_eff = dbtvault.escape_column_names(src_eff) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_fk, src_payload, src_eff, src_ldts, src_source]) -%}\n{%- set fk_cols = dbtvault.expand_column_list([src_fk]) -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\nWITH stage AS (\n    SELECT {{ source_cols | join(', ') }}\n    FROM {{ ref(source_model) }}\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n    WHERE __PERIOD_FILTER__\n    AND {{ dbtvault.multikey(src_pk, condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(fk_cols, condition='IS NOT NULL') }}\n    {%- elif model.config.materialized == 'vault_insert_by_rank' %}\n    WHERE __RANK_FILTER__\n    AND {{ dbtvault.multikey(src_pk, condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(fk_cols, condition='IS NOT NULL') }}\n    {%- else %}\n    WHERE {{ dbtvault.multikey(src_pk, condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(fk_cols, condition='IS NOT NULL') }}\n    {%- endif %}\n),\nrecords_to_insert AS (\n    SELECT DISTINCT {{ dbtvault.prefix(source_cols, 'stg') }}\n    FROM stage AS stg\n    {% if dbtvault.is_any_incremental() -%}\n    LEFT JOIN {{ this }} AS tgt\n    ON {{ dbtvault.multikey(src_pk, prefix=['stg','tgt'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='tgt', condition='IS NULL') }}\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.multikey", "macro.dbtvault.prefix", "macro.dbtvault.is_any_incremental"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.7557042}, "macro.dbtvault.sat": {"unique_id": "macro.dbtvault.sat", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/sat.sql", "original_file_path": "macros/tables/snowflake/sat.sql", "name": "sat", "macro_sql": "{%- macro sat(src_pk, src_hashdiff, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n    {{- adapter.dispatch('sat', 'dbtvault')(src_pk=src_pk, src_hashdiff=src_hashdiff,\n                                            src_payload=src_payload, src_eff=src_eff, src_ldts=src_ldts,\n                                            src_source=src_source, source_model=source_model) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.spark__sat"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.7597408}, "macro.dbtvault.default__sat": {"unique_id": "macro.dbtvault.default__sat", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/sat.sql", "original_file_path": "macros/tables/snowflake/sat.sql", "name": "default__sat", "macro_sql": "\n\n{%- macro default__sat(src_pk, src_hashdiff, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_hashdiff=src_hashdiff, src_payload=src_payload,\n                                       src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_hashdiff = dbtvault.escape_column_names(src_hashdiff) -%}\n{%- set src_payload = dbtvault.escape_column_names(src_payload) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_payload, src_eff, src_ldts, src_source]) -%}\n{%- set rank_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_ldts]) -%}\n{%- set pk_cols = dbtvault.expand_column_list(columns=[src_pk]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + dbtvault.escape_column_names([config.get('rank_column')]) -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\nWITH source_data AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ dbtvault.prefix(source_cols_with_rank, 'a', alias_target='source') }}\n    {%- else %}\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='source') }}\n    {%- endif %}\n    FROM {{ ref(source_model) }} AS a\n    WHERE {{ dbtvault.multikey(src_pk, prefix='a', condition='IS NOT NULL') }}\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n    AND __PERIOD_FILTER__\n    {% elif model.config.materialized == 'vault_insert_by_rank' %}\n    AND __RANK_FILTER__\n    {% endif %}\n),\n\n{%- if dbtvault.is_any_incremental() %}\n\nlatest_records AS (\n    SELECT {{ dbtvault.prefix(rank_cols, 'a', alias_target='target') }}\n    FROM (\n        SELECT {{ dbtvault.prefix(rank_cols, 'current_records', alias_target='target') }},\n            RANK() OVER (\n                PARTITION BY {{ dbtvault.prefix([src_pk], 'current_records') }}\n                ORDER BY {{ dbtvault.prefix([src_ldts], 'current_records') }} DESC\n            ) AS rank\n        FROM {{ this }} AS current_records\n            JOIN (\n                SELECT DISTINCT {{ dbtvault.prefix([src_pk], 'source_data') }}\n                FROM source_data\n            ) AS source_records\n                ON {{ dbtvault.multikey(src_pk, prefix=['current_records','source_records'], condition='=') }}\n    ) AS a\n    WHERE a.rank = 1\n),\n\n{%- endif %}\n\nrecords_to_insert AS (\n    SELECT DISTINCT {{ dbtvault.alias_all(source_cols, 'stage') }}\n    FROM source_data AS stage\n    {%- if dbtvault.is_any_incremental() %}\n        LEFT JOIN latest_records\n            ON {{ dbtvault.multikey(src_pk, prefix=['latest_records','stage'], condition='=') }}\n            WHERE {{ dbtvault.prefix([src_hashdiff], 'latest_records', alias_target='target') }} != {{ dbtvault.prefix([src_hashdiff], 'stage') }}\n                OR {{ dbtvault.prefix([src_hashdiff], 'latest_records', alias_target='target') }} IS NULL\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental", "macro.dbtvault.alias_all"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.76507}, "macro.dbtvault.hub": {"unique_id": "macro.dbtvault.hub", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/hub.sql", "original_file_path": "macros/tables/snowflake/hub.sql", "name": "hub", "macro_sql": "{%- macro hub(src_pk, src_nk, src_ldts, src_source, source_model) -%}\n\n    {{- adapter.dispatch('hub', 'dbtvault')(src_pk=src_pk, src_nk=src_nk,\n                                            src_ldts=src_ldts, src_source=src_source,\n                                            source_model=source_model) -}}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.spark__hub"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.770123}, "macro.dbtvault.default__hub": {"unique_id": "macro.dbtvault.default__hub", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/hub.sql", "original_file_path": "macros/tables/snowflake/hub.sql", "name": "default__hub", "macro_sql": "{%- macro default__hub(src_pk, src_nk, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_nk=src_nk,\n                                       src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_nk = dbtvault.escape_column_names(src_nk) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_nk, src_ldts, src_source]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + dbtvault.escape_column_names([config.get('rank_column')]) -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{{ 'WITH ' -}}\n\n{%- if not (source_model is iterable and source_model is not string) -%}\n    {%- set source_model = [source_model] -%}\n{%- endif -%}\n\n{%- set ns = namespace(last_cte= \"\") -%}\n\n{%- for src in source_model -%}\n\n{%- set source_number = loop.index | string -%}\n\nrow_rank_{{ source_number }} AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ dbtvault.prefix(source_cols_with_rank, 'rr') }},\n    {%- else %}\n    SELECT {{ dbtvault.prefix(source_cols, 'rr') }},\n    {%- endif %}\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'rr') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'rr') }}\n           ) AS row_number\n    FROM {{ ref(src) }} AS rr\n    WHERE {{ dbtvault.multikey(src_pk, prefix='rr', condition='IS NOT NULL') }}\n    QUALIFY row_number = 1\n    {%- set ns.last_cte = \"row_rank_{}\".format(source_number) %}\n),{{ \"\\n\" if not loop.last }}\n{% endfor -%}\n{% if source_model | length > 1 %}\nstage_union AS (\n    {%- for src in source_model %}\n    SELECT * FROM row_rank_{{ loop.index | string }}\n    {%- if not loop.last %}\n    UNION ALL\n    {%- endif %}\n    {%- endfor %}\n    {%- set ns.last_cte = \"stage_union\" %}\n),\n{%- endif -%}\n{%- if model.config.materialized == 'vault_insert_by_period' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __PERIOD_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- elif model.config.materialized == 'vault_insert_by_rank' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __RANK_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- endif -%}\n{%- if source_model | length > 1 %}\n\nrow_rank_union AS (\n    SELECT ru.*,\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'ru') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'ru') }}, {{ dbtvault.prefix([src_source], 'ru') }} ASC\n           ) AS row_rank_number\n    FROM {{ ns.last_cte }} AS ru\n    WHERE {{ dbtvault.multikey(src_pk, prefix='ru', condition='IS NOT NULL') }}\n    QUALIFY row_rank_number = 1\n    {%- set ns.last_cte = \"row_rank_union\" %}\n),\n{% endif %}\nrecords_to_insert AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='target') }}\n    FROM {{ ns.last_cte }} AS a\n    {%- if dbtvault.is_any_incremental() %}\n    LEFT JOIN {{ this }} AS d\n    ON {{ dbtvault.multikey(src_pk, prefix=['a','d'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='d', condition='IS NULL') }}\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.776308}, "macro.dbtvault.eff_sat": {"unique_id": "macro.dbtvault.eff_sat", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/eff_sat.sql", "original_file_path": "macros/tables/snowflake/eff_sat.sql", "name": "eff_sat", "macro_sql": "{%- macro eff_sat(src_pk, src_dfk, src_sfk, src_start_date, src_end_date, src_eff, src_ldts, src_source, source_model) -%}\n\n    {{- adapter.dispatch('eff_sat', 'dbtvault')(src_pk=src_pk, src_dfk=src_dfk, src_sfk=src_sfk,\n                                                src_start_date=src_start_date, src_end_date=src_end_date,\n                                                src_eff=src_eff, src_ldts=src_ldts, src_source=src_source,\n                                                source_model=source_model) -}}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__eff_sat"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.781908}, "macro.dbtvault.default__eff_sat": {"unique_id": "macro.dbtvault.default__eff_sat", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/eff_sat.sql", "original_file_path": "macros/tables/snowflake/eff_sat.sql", "name": "default__eff_sat", "macro_sql": "{%- macro default__eff_sat(src_pk, src_dfk, src_sfk, src_start_date, src_end_date, src_eff, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_dfk=src_dfk, src_sfk=src_sfk,\n                                       src_start_date=src_start_date, src_end_date=src_end_date,\n                                       src_eff=src_eff, src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_dfk = dbtvault.escape_column_names(src_dfk) -%}\n{%- set src_sfk = dbtvault.escape_column_names(src_sfk) -%}\n{%- set src_start_date = dbtvault.escape_column_names(src_start_date) -%}\n{%- set src_end_date = dbtvault.escape_column_names(src_end_date) -%}\n{%- set src_eff = dbtvault.escape_column_names(src_eff) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_dfk, src_sfk, src_start_date, src_end_date, src_eff, src_ldts, src_source]) -%}\n{%- set fk_cols = dbtvault.expand_column_list(columns=[src_dfk, src_sfk]) -%}\n{%- set dfk_cols = dbtvault.expand_column_list(columns=[src_dfk]) -%}\n{%- set is_auto_end_dating = config.get('is_auto_end_dating', default=false) %}\n\n{{- dbtvault.prepend_generated_by() }}\n\n{%- set max_datetime = var('max_datetime', '9999-12-31 23:59:59.999999') %}\n\nWITH source_data AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='source') }}\n    FROM {{ ref(source_model) }} AS a\n    WHERE {{ dbtvault.multikey(src_dfk, prefix='a', condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(src_sfk, prefix='a', condition='IS NOT NULL') }}\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n    AND __PERIOD_FILTER__\n    {%- elif model.config.materialized == 'vault_insert_by_rank' %}\n    AND __RANK_FILTER__\n    {%- endif %}\n),\n\n{%- if dbtvault.is_any_incremental() %}\n\n{# Selecting the most recent records for each link hashkey -#}\nlatest_records AS (\n    SELECT {{ dbtvault.alias_all(source_cols, 'b') }},\n           ROW_NUMBER() OVER (\n                PARTITION BY {{ dbtvault.prefix([src_pk], 'b') }}\n                ORDER BY b.{{ src_ldts }} DESC\n           ) AS row_num\n    FROM {{ this }} AS b\n    QUALIFY row_num = 1\n),\n\n{# Selecting the open records of the most recent records for each link hashkey -#}\nlatest_open AS (\n    SELECT {{ dbtvault.alias_all(source_cols, 'c') }}\n    FROM latest_records AS c\n    WHERE TO_DATE(c.{{ src_end_date }}) = TO_DATE('{{ max_datetime }}')\n),\n\n{# Selecting the closed records of the most recent records for each link hashkey -#}\nlatest_closed AS (\n    SELECT {{ dbtvault.alias_all(source_cols, 'd') }}\n    FROM latest_records AS d\n    WHERE TO_DATE(d.{{ src_end_date }}) != TO_DATE('{{ max_datetime }}')\n),\n\n{# Identifying the completely new link relationships to be opened in eff sat -#}\nnew_open_records AS (\n    SELECT DISTINCT\n        {{ dbtvault.alias_all(source_cols, 'f') }}\n    FROM source_data AS f\n    LEFT JOIN latest_records AS lr\n    ON {{ dbtvault.multikey(src_pk, prefix=['f','lr'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='lr', condition='IS NULL') }}\n),\n\n{# Identifying the currently closed link relationships to be reopened in eff sat -#}\nnew_reopened_records AS (\n    SELECT DISTINCT\n        {{ dbtvault.prefix([src_pk], 'lc') }},\n        {{ dbtvault.alias_all(fk_cols, 'lc') }},\n        lc.{{ src_start_date }} AS {{ src_start_date }},\n        g.{{ src_end_date }} AS {{ src_end_date }},\n        g.{{ src_eff }} AS {{ src_eff }},\n        g.{{ src_ldts }},\n        g.{{ src_source }}\n    FROM source_data AS g\n    INNER JOIN latest_closed AS lc\n    ON {{ dbtvault.multikey(src_pk, prefix=['g','lc'], condition='=') }}\n    WHERE TO_DATE(g.{{ src_end_date }}) = TO_DATE('{{ max_datetime }}')\n),\n\n{%- if is_auto_end_dating %}\n\n{# Creating the closing records -#}\n{# Identifying the currently open relationships that need to be closed due to change in SFK(s) -#}\nnew_closed_records AS (\n    SELECT DISTINCT\n        {{ dbtvault.prefix([src_pk], 'lo') }},\n        {{ dbtvault.alias_all(fk_cols, 'lo') }},\n        lo.{{ src_start_date }} AS {{ src_start_date }},\n        h.{{ src_eff }} AS {{ src_end_date }},\n        h.{{ src_eff }} AS {{ src_eff }},\n        h.{{ src_ldts }},\n        lo.{{ src_source }}\n    FROM source_data AS h\n    INNER JOIN latest_open AS lo\n    ON {{ dbtvault.multikey(src_dfk, prefix=['lo', 'h'], condition='=') }}\n    WHERE ({{ dbtvault.multikey(src_sfk, prefix=['lo', 'h'], condition='<>', operator='OR') }})\n),\n\n{#- else if is_auto_end_dating -#}\n{% else %}\n\nnew_closed_records AS (\n    SELECT DISTINCT\n        lo.{{ src_pk }},\n        {{ dbtvault.alias_all(fk_cols, 'lo') }},\n        lo.{{ src_start_date }} AS {{ src_start_date }},\n        h.{{ src_eff }} AS {{ src_end_date }},\n        h.{{ src_eff }} AS {{ src_eff }},\n        h.{{ src_ldts }},\n        lo.{{ src_source }}\n    FROM source_data AS h\n    LEFT JOIN Latest_open AS lo\n    ON {{ dbtvault.multikey(src_pk, prefix=['lo', 'h'], condition='=') }}\n    LEFT JOIN latest_closed AS lc\n    ON {{ dbtvault.multikey(src_pk, prefix=['lc', 'h'], condition='=') }}\n    WHERE TO_DATE(h.{{ src_end_date }}) != TO_DATE('{{ max_datetime }}')\n    AND {{ dbtvault.multikey(src_pk, prefix='lo', condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(src_pk, prefix='lc', condition='IS NULL') }}\n),\n\n{#- end if is_auto_end_dating -#}\n{%- endif %}\n\nrecords_to_insert AS (\n    SELECT * FROM new_open_records\n    UNION\n    SELECT * FROM new_reopened_records\n    UNION\n    SELECT * FROM new_closed_records\n)\n\n{#- else if not dbtvault.is_any_incremental() -#}\n{%- else %}\n\nrecords_to_insert AS (\n    SELECT {{ dbtvault.alias_all(source_cols, 'i') }}\n    FROM source_data AS i\n)\n\n{#- end if not dbtvault.is_any_incremental() -#}\n{%- endif %}\n\nSELECT * FROM records_to_insert\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental", "macro.dbtvault.alias_all"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.7932742}, "macro.dbtvault.bridge": {"unique_id": "macro.dbtvault.bridge", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/bridge.sql", "original_file_path": "macros/tables/snowflake/bridge.sql", "name": "bridge", "macro_sql": "{%- macro bridge(src_pk, as_of_dates_table, bridge_walk, stage_tables_ldts, src_ldts, source_model) -%}\n\n    {{- adapter.dispatch('bridge', 'dbtvault')(source_model=source_model, src_pk=src_pk,\n                                               bridge_walk=bridge_walk,\n                                               as_of_dates_table=as_of_dates_table,\n                                               stage_tables_ldts=stage_tables_ldts,\n                                               src_ldts=src_ldts) -}}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__bridge"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.830314}, "macro.dbtvault.default__bridge": {"unique_id": "macro.dbtvault.default__bridge", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/bridge.sql", "original_file_path": "macros/tables/snowflake/bridge.sql", "name": "default__bridge", "macro_sql": "{%- macro default__bridge(src_pk, as_of_dates_table, bridge_walk, stage_tables_ldts, src_ldts, source_model) -%}\n\n{{- dbtvault.check_required_parameters(source_model=source_model, src_pk=src_pk,\n                                       bridge_walk=bridge_walk,\n                                       stage_tables_ldts=stage_tables_ldts,\n                                       src_ldts=src_ldts) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{%- if (as_of_dates_table is none) and execute -%}\n    {%- set error_message -%}\n    \"Bridge error: Missing as_of_dates table configuration. A as_of_dates_table must be provided.\"\n    {%- endset -%}\n    {{- exceptions.raise_compiler_error(error_message) -}}\n{%- endif -%}\n\n{#- Acquiring the source relation for the AS_OF table -#}\n{%- if as_of_dates_table is mapping and as_of_dates_table is not none -%}\n    {%- set source_name = as_of_dates_table | first -%}\n    {%- set source_table_name = as_of_dates_table[source_name] -%}\n    {%- set source_relation = source(source_name, source_table_name) -%}\n{%- elif as_of_dates_table is not mapping and as_of_dates_table is not none -%}\n    {%- set source_relation = ref(as_of_dates_table) -%}\n{%- endif -%}\n\n{%- set max_datetime = var('max_datetime', '9999-12-31 23:59:59.999999') -%}\n\n{#- Stating the dependencies on the stage tables outside of the If STATEMENT -#}\n{% for stg in stage_tables_ldts -%}\n    {{- \"-- depends_on: \" ~ ref(stg) -}}\n{%- endfor %}\n\n{#- Setting the new AS_OF dates CTE name -#}\n{%- if dbtvault.is_any_incremental() -%}\n    {%- set new_as_of_dates_cte = 'NEW_ROWS_AS_OF'  -%}\n{%- else -%}\n    {%- set new_as_of_dates_cte = 'AS_OF' -%}\n{%- endif %}\n\nWITH as_of AS (\n     SELECT a.AS_OF_DATE\n     FROM {{ source_relation }} AS a\n     WHERE a.AS_OF_DATE <= CURRENT_DATE()\n),\n\n{%- if dbtvault.is_any_incremental() %}\n\nlast_safe_load_datetime AS (\n    SELECT MIN(LOAD_DATETIME) AS LAST_SAFE_LOAD_DATETIME\n    FROM (\n    {%- filter indent(width=8) -%}\n    {%- for stg in stage_tables_ldts -%}\n        {%- set stage_ldts =(stage_tables_ldts[stg])  -%}\n        {{ \"SELECT MIN(\" ~ stage_ldts ~ \") AS LOAD_DATETIME FROM \" ~ ref(stg) }}\n        {{ \"UNION ALL\" if not loop.last }}\n    {% endfor -%}\n    {%- endfilter -%}\n    ) AS l\n),\n\nas_of_grain_old_entries AS (\n    SELECT DISTINCT AS_OF_DATE\n    FROM {{ this }}\n),\n\nas_of_grain_lost_entries AS (\n    SELECT a.AS_OF_DATE\n    FROM as_of_grain_old_entries AS a\n    LEFT OUTER JOIN as_of AS b\n        ON a.AS_OF_DATE = b.AS_OF_DATE\n    WHERE b.AS_OF_DATE IS NULL\n),\n\nas_of_grain_new_entries AS (\n    SELECT a.AS_OF_DATE\n    FROM as_of AS a\n    LEFT OUTER JOIN as_of_grain_old_entries AS b\n        ON a.AS_OF_DATE = b.AS_OF_DATE\n    WHERE b.AS_OF_DATE IS NULL\n),\n\nmin_date AS (\n    SELECT min(AS_OF_DATE) AS MIN_DATE\n    FROM as_of\n),\n\nnew_rows_pks AS (\n    SELECT {{ dbtvault.prefix([src_pk], 'h') }}\n    FROM {{ ref(source_model) }} AS h\n    WHERE h.{{ src_ldts }} >= (SELECT LAST_SAFE_LOAD_DATETIME FROM last_safe_load_datetime)\n),\n\nnew_rows_as_of AS (\n    SELECT AS_OF_DATE\n    FROM as_of\n    WHERE as_of.AS_OF_DATE >= (SELECT LAST_SAFE_LOAD_DATETIME FROM last_safe_load_datetime)\n    UNION\n    SELECT as_of_date\n    FROM as_of_grain_new_entries\n),\n\noverlap_pks AS (\n    SELECT {{ dbtvault.prefix([src_pk], 'p') }}\n    FROM {{ this }} AS p\n    INNER JOIN {{ ref(source_model) }} as h\n        ON {{ dbtvault.multikey(src_pk, prefix=['p','h'], condition='=') }}\n    WHERE p.AS_OF_DATE >= (SELECT MIN_DATE FROM min_date)\n        AND p.AS_OF_DATE < (SELECT LAST_SAFE_LOAD_DATETIME FROM last_safe_load_datetime)\n        AND p.AS_OF_DATE NOT IN (SELECT AS_OF_DATE FROM as_of_grain_lost_entries)\n),\n\noverlap_as_of AS (\n    SELECT AS_OF_DATE\n    FROM as_of AS p\n    WHERE p.AS_OF_DATE >= (SELECT MIN_DATE FROM min_date)\n        AND p.AS_OF_DATE < (SELECT LAST_SAFE_LOAD_DATETIME FROM last_safe_load_datetime)\n        AND p.AS_OF_DATE NOT IN (SELECT AS_OF_DATE FROM as_of_grain_lost_entries)\n),\n\noverlap AS (\n    SELECT\n        {{ dbtvault.prefix([src_pk], 'a') }},\n        b.AS_OF_DATE\n        {%- for bridge_step in bridge_walk.keys() -%}\n            {%- set link_table = dbtvault.escape_column_names(bridge_walk[bridge_step]['link_table']) -%}\n            {%- set link_pk = dbtvault.escape_column_names(bridge_walk[bridge_step]['link_pk']) -%}\n            {%- set bridge_link_pk = dbtvault.escape_column_names(bridge_walk[bridge_step]['bridge_link_pk']) -%}\n            {%- set eff_sat_table = dbtvault.escape_column_names(bridge_walk[bridge_step]['eff_sat_table']) -%}\n            {%- set bridge_end_date = dbtvault.escape_column_names(bridge_walk[bridge_step]['bridge_end_date']) -%}\n            {%- set bridge_load_date = dbtvault.escape_column_names(bridge_walk[bridge_step]['bridge_load_date']) -%}\n            {%- set eff_sat_end_date = dbtvault.escape_column_names(bridge_walk[bridge_step]['eff_sat_end_date']) -%}\n            {%- set eff_sat_load_date = dbtvault.escape_column_names(bridge_walk[bridge_step]['eff_sat_load_date']) -%}\n            {%- filter indent(width=8) %}\n            {{ ',' ~ link_table ~ '.' ~ link_pk ~ ' AS ' ~ bridge_link_pk }}\n            {{ ',' ~ eff_sat_table ~ '.' ~ eff_sat_end_date ~ ' AS ' ~ bridge_end_date }}\n            {{ ',' ~ eff_sat_table ~ '.' ~ eff_sat_load_date ~' AS ' ~ bridge_load_date }}\n            {%- endfilter -%}\n        {% endfor %}\n    FROM overlap_pks AS a\n    INNER JOIN overlap_as_of AS b\n        ON (1=1)\n    {%- set loop_vars = namespace(lastlink = '', last_link_fk = '') -%}\n    {%- for bridge_step in bridge_walk.keys() -%}\n        {%- set current_link = bridge_walk[bridge_step]['link_table'] -%}\n        {%- set current_eff_sat = bridge_walk[bridge_step]['eff_sat_table'] -%}\n        {%- set link_pk = dbtvault.escape_column_names(bridge_walk[bridge_step]['link_pk']) -%}\n        {%- set link_fk1 = dbtvault.escape_column_names(bridge_walk[bridge_step]['link_fk1']) -%}\n        {%- set link_fk2 = dbtvault.escape_column_names(bridge_walk[bridge_step]['link_fk2']) -%}\n        {%- set eff_sat_pk = dbtvault.escape_column_names(bridge_walk[bridge_step]['eff_sat_pk']) -%}\n        {%- set eff_sat_load_date = dbtvault.escape_column_names(bridge_walk[bridge_step]['eff_sat_load_date']) -%}\n        {%- if loop.first %}\n    LEFT JOIN {{ ref(current_link) }} AS {{ dbtvault.escape_column_names(current_link) }}\n        ON a.{{ src_pk }} = {{ dbtvault.escape_column_names(current_link) }}.{{ link_fk1 }}\n        {%- else %}\n    LEFT JOIN {{ ref(current_link) }} AS {{ dbtvault.escape_column_names(current_link) }}\n        ON {{ loop_vars.last_link }}.{{ loop_vars.last_link_fk2 }} = {{ dbtvault.escape_column_names(current_link) }}.{{ link_fk1 }}\n        {%- endif %}\n    INNER JOIN {{ ref(current_eff_sat) }} AS {{ dbtvault.escape_column_names(current_eff_sat) }}\n        ON {{ dbtvault.escape_column_names(current_eff_sat) }}.{{ eff_sat_pk }} = {{ dbtvault.escape_column_names(current_link) }}.{{ link_pk }}\n        AND {{ dbtvault.escape_column_names(current_eff_sat) }}.{{ eff_sat_load_date }} <= b.AS_OF_DATE\n        {%- set loop_vars.last_link = current_link -%}\n        {%- set loop_vars.last_link_fk2 = link_fk2 -%}\n    {% endfor %}\n),\n{%- endif %}\n\nnew_rows AS (\n    SELECT\n        {{ dbtvault.prefix([src_pk], 'a') }},\n        b.AS_OF_DATE\n        {%- for bridge_step in bridge_walk.keys() -%}\n            {%- set link_table = dbtvault.escape_column_names(bridge_walk[bridge_step]['link_table']) -%}\n            {%- set link_pk = dbtvault.escape_column_names(bridge_walk[bridge_step]['link_pk']) -%}\n            {%- set bridge_link_pk = dbtvault.escape_column_names(bridge_walk[bridge_step]['bridge_link_pk']) -%}\n            {%- set eff_sat_table = dbtvault.escape_column_names(bridge_walk[bridge_step]['eff_sat_table']) -%}\n            {%- set bridge_end_date = dbtvault.escape_column_names(bridge_walk[bridge_step]['bridge_end_date']) -%}\n            {%- set bridge_load_date = dbtvault.escape_column_names(bridge_walk[bridge_step]['bridge_load_date']) -%}\n            {%- set eff_sat_end_date = dbtvault.escape_column_names(bridge_walk[bridge_step]['eff_sat_end_date']) -%}\n            {%- set eff_sat_load_date = dbtvault.escape_column_names(bridge_walk[bridge_step]['eff_sat_load_date']) -%}\n            {%- filter indent(width=8) -%}\n            {{ ',' ~ link_table ~'.'~ link_pk ~' AS '~ bridge_link_pk }}\n            {{ ',' ~ eff_sat_table ~ '.' ~ eff_sat_end_date ~ ' AS ' ~ bridge_end_date }}\n            {{ ',' ~ eff_sat_table ~ '.' ~ eff_sat_load_date ~ ' AS ' ~ bridge_load_date }}\n            {%- endfilter -%}\n        {% endfor %}\n    FROM {{ ref(source_model) }} AS a\n    INNER JOIN {{ new_as_of_dates_cte }} AS b\n        ON (1=1)\n    {%- set loop_vars = namespace(lastlink = '', last_link_fk = '') %}\n    {%- for bridge_step in bridge_walk.keys() -%}\n        {%- set current_link = bridge_walk[bridge_step]['link_table'] -%}\n        {%- set current_eff_sat = bridge_walk[bridge_step]['eff_sat_table'] -%}\n        {%- set link_pk = dbtvault.escape_column_names(bridge_walk[bridge_step]['link_pk']) -%}\n        {%- set link_fk1 = dbtvault.escape_column_names(bridge_walk[bridge_step]['link_fk1']) -%}\n        {%- set link_fk2 = dbtvault.escape_column_names(bridge_walk[bridge_step]['link_fk2']) -%}\n        {%- set eff_sat_pk = dbtvault.escape_column_names(bridge_walk[bridge_step]['eff_sat_pk']) -%}\n        {%- set eff_sat_load_date = dbtvault.escape_column_names(bridge_walk[bridge_step]['eff_sat_load_date']) -%}\n        {%- if loop.first  %}\n    LEFT JOIN {{ ref(current_link) }} AS {{ dbtvault.escape_column_names(current_link) }}\n        ON a.{{ src_pk }} = {{ dbtvault.escape_column_names(current_link) }}.{{ link_fk1 }}\n        {%- else %}\n    LEFT JOIN {{ ref(current_link) }} AS {{ dbtvault.escape_column_names(current_link) }}\n        ON {{ loop_vars.last_link }}.{{ loop_vars.last_link_fk2 }} = {{ dbtvault.escape_column_names(current_link) }}.{{ link_fk1 }}\n        {%- endif %}\n    INNER JOIN {{ ref(current_eff_sat) }} AS {{ dbtvault.escape_column_names(current_eff_sat) }}\n        ON {{ dbtvault.escape_column_names(current_eff_sat) }}.{{ eff_sat_pk }} = {{ dbtvault.escape_column_names(current_link) }}.{{ link_pk }}\n        AND {{ dbtvault.escape_column_names(current_eff_sat) }}.{{ eff_sat_load_date }} <= b.AS_OF_DATE\n        {%- set loop_vars.last_link = dbtvault.escape_column_names(current_link) -%}\n        {%- set loop_vars.last_link_fk2 = link_fk2 -%}\n    {% endfor %}\n),\n\n{# Full data from bridge walk(s) -#}\nall_rows AS (\n    SELECT * FROM new_rows\n    {%- if dbtvault.is_any_incremental() %}\n    UNION ALL\n    SELECT * FROM overlap\n    {%- endif %}\n),\n\n{# Select most recent set of relationship key(s) for each as of date -#}\ncandidate_rows AS (\n    SELECT *,\n        ROW_NUMBER() OVER (\n            PARTITION BY AS_OF_DATE,\n                {%- for bridge_step in bridge_walk.keys() -%}\n                {% set bridge_link_pk = dbtvault.escape_column_names(bridge_walk[bridge_step]['bridge_link_pk']) -%}\n                    {%- if loop.first %}\n                {{ bridge_link_pk }}\n                    {%- else %}\n                {{ ','~ bridge_link_pk }}\n                    {%- endif -%}\n                {%- endfor %}\n            ORDER BY\n                {%- for bridge_step in bridge_walk.keys() -%}\n                {% set bridge_load_date = dbtvault.escape_column_names(bridge_walk[bridge_step]['bridge_load_date']) %}\n                    {%- if loop.first %}\n                {{ bridge_load_date ~' DESC' }}\n                    {%- else %}\n                {{ ','~ bridge_load_date ~' DESC' }}\n                    {%- endif -%}\n                {%- endfor %}\n            ) AS row_num\n    FROM all_rows\n    QUALIFY row_num = 1\n),\n\nbridge AS (\n    SELECT\n        {{ dbtvault.prefix([src_pk], 'c') }},\n        c.AS_OF_DATE\n        {%- for bridge_step in bridge_walk.keys() -%}\n        {% set bridge_link_pk = dbtvault.escape_column_names(bridge_walk[bridge_step]['bridge_link_pk']) -%}\n        {{ ',c.' ~ bridge_link_pk }}\n        {%- endfor %}\n    FROM candidate_rows AS c\n        {%- for bridge_step in bridge_walk.keys() -%}\n            {%- set bridge_end_date = dbtvault.escape_column_names(bridge_walk[bridge_step]['bridge_end_date']) -%}\n            {%- if loop.first %}\n    WHERE TO_DATE({{ 'c.' ~ bridge_end_date }}) = TO_DATE('{{ max_datetime }}')\n            {%- else %}\n        AND TO_DATE({{ 'c.' ~ bridge_end_date }}) = TO_DATE('{{ max_datetime }}')\n            {%- endif -%}\n        {%- endfor %}\n)\n\nSELECT * FROM bridge\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.is_any_incremental", "macro.dbtvault.prefix", "macro.dbtvault.multikey"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.850071}, "macro.dbtvault.biquery__xts": {"unique_id": "macro.dbtvault.biquery__xts", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/sqlserver/xts.sql", "original_file_path": "macros/tables/sqlserver/xts.sql", "name": "biquery__xts", "macro_sql": "{%- macro biquery__xts(src_pk, src_satellite, src_ldts, src_source, source_model) -%}\n\n{{ dbtvault.default__xts(src_pk=src_pk,\n                         src_satellite=src_satellite,\n                         src_ldts=src_ldts,\n                         src_source=src_source,\n                         source_model=source_model) }}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__xts"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.851043}, "macro.dbtvault.sqlserver__ma_sat": {"unique_id": "macro.dbtvault.sqlserver__ma_sat", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/sqlserver/ma_sat.sql", "original_file_path": "macros/tables/sqlserver/ma_sat.sql", "name": "sqlserver__ma_sat", "macro_sql": "{%- macro sqlserver__ma_sat(src_pk, src_cdk, src_hashdiff, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_cdk=src_cdk, src_hashdiff=src_hashdiff,\n                                       src_payload=src_payload, src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_cdk = dbtvault.escape_column_names(src_cdk) -%}\n{%- set src_hashdiff = dbtvault.escape_column_names(src_hashdiff) -%}\n{%- set src_payload = dbtvault.escape_column_names(src_payload) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_cdk, src_payload, src_eff, src_ldts, src_source]) -%}\n{%- set rank_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_ldts]) -%}\n{%- set cdk_cols = dbtvault.expand_column_list(columns=[src_cdk]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' -%}\n    {%- set source_cols_with_rank = source_cols + [config.get('rank_column')] -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{# Select unique source records -#}\nWITH source_data AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT DISTINCT {{ dbtvault.prefix(source_cols_with_rank, 's', alias_target='source') }}\n    {%- else %}\n    SELECT DISTINCT {{ dbtvault.prefix(source_cols, 's', alias_target='source') }}\n    {%- endif %}\n    FROM {{ ref(source_model) }} AS s\n    WHERE {{ dbtvault.multikey([src_pk], prefix='s', condition='IS NOT NULL') }}\n    {%- for child_key in src_cdk %}\n        AND {{ dbtvault.multikey(child_key, prefix='s', condition='IS NOT NULL') }}\n    {%- endfor %}\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n        AND __PERIOD_FILTER__\n    {%- elif model.config.materialized == 'vault_insert_by_rank' %}\n        AND __RANK_FILTER__\n    {%- endif %}\n),\n\n{# if any_incremental -#}\n{% if dbtvault.is_any_incremental() %}\n\nsource_data_with_count AS (\n    SELECT a.*\n        ,b.source_count\n    FROM source_data a\n    INNER JOIN\n    (\n        SELECT {{ dbtvault.prefix([src_pk], 't') }}\n            ,COUNT(*) AS source_count\n        FROM (SELECT DISTINCT {{ dbtvault.prefix([src_pk], 's') }}, {{ dbtvault.prefix([src_hashdiff], 's', alias_target='source') }}, {{ dbtvault.prefix(cdk_cols, 's') }} FROM source_data AS s) AS t\n        GROUP BY {{ dbtvault.prefix([src_pk], 't') }}\n    ) AS b\n    ON {{ dbtvault.multikey([src_pk], prefix=['a','b'], condition='=') }}\n),\n\n{# Select latest records from satellite, restricted to PKs in source data -#}\nlatest_records AS (\n    SELECT {{ dbtvault.prefix([src_pk], 'mas', alias_target='target') }}\n        ,{{ dbtvault.prefix([src_hashdiff], 'mas', alias_target='target') }}\n        ,{{ dbtvault.prefix([src_cdk], 'mas', alias_target='target') }}\n        ,{{ dbtvault.prefix([src_ldts], 'mas', alias_target='target') }}\n        ,mas.latest_rank\n        ,DENSE_RANK() OVER (PARTITION BY {{ dbtvault.prefix([src_pk], 'mas') }}\n            ORDER BY {{ dbtvault.prefix([src_hashdiff], 'mas', alias_target='target') }}, {{ dbtvault.prefix([src_cdk], 'mas') }} ASC) AS check_rank\n    FROM\n    (\n    SELECT {{ dbtvault.prefix([src_pk], 'inner_mas', alias_target='target') }}\n        ,{{ dbtvault.prefix([src_hashdiff], 'inner_mas', alias_target='target') }}\n        ,{{ dbtvault.prefix([src_cdk], 'inner_mas', alias_target='target') }}\n        ,{{ dbtvault.prefix([src_ldts], 'inner_mas', alias_target='target') }}\n        ,RANK() OVER (PARTITION BY {{ dbtvault.prefix([src_pk], 'inner_mas') }}\n            ORDER BY {{ dbtvault.prefix([src_ldts], 'inner_mas') }} DESC) AS latest_rank\n    FROM {{ this }} AS inner_mas\n    INNER JOIN (SELECT DISTINCT {{ dbtvault.prefix([src_pk], 's') }} FROM source_data as s ) AS spk\n        ON {{ dbtvault.multikey([src_pk], prefix=['inner_mas', 'spk'], condition='=') }}\n    ) AS mas\n    WHERE latest_rank = 1\n),\n\n{# Select summary details for each group of latest records -#}\nlatest_group_details AS (\n    SELECT {{ dbtvault.prefix([src_pk], 'lr') }}\n        ,{{ dbtvault.prefix([src_ldts], 'lr') }}\n        ,MAX(lr.check_rank) AS latest_count\n    FROM latest_records AS lr\n    GROUP BY {{ dbtvault.prefix([src_pk], 'lr') }}, {{ dbtvault.prefix([src_ldts], 'lr') }}\n),\n\n{# endif any_incremental -#}\n{%- endif %}\n\n{# Select groups of source records where at least one member does not appear in a group of latest records -#}\nrecords_to_insert AS (\n{% if not dbtvault.is_any_incremental() %}\n    SELECT {{ dbtvault.alias_all(source_cols, 'source_data') }}\n    FROM source_data\n{%- endif %}\n\n{# if any_incremental -#}\n{% if dbtvault.is_any_incremental() %}\n    SELECT {{ dbtvault.alias_all(source_cols, 'source_data_with_count') }}\n    FROM source_data_with_count\n    WHERE EXISTS\n    (\n        SELECT 1\n        FROM source_data_with_count AS stage\n        WHERE NOT EXISTS\n        (\n            SELECT 1\n            FROM\n            (\n                SELECT {{ dbtvault.prefix([src_pk], 'lr', alias_target='target') }}\n                ,{{ dbtvault.prefix([src_hashdiff], 'lr', alias_target='target') }}\n                ,{{ dbtvault.prefix([src_cdk], 'lr', alias_target='target') }}\n                ,{{ dbtvault.prefix([src_ldts], 'lr', alias_target='target') }}\n                ,lg.latest_count\n                FROM latest_records AS lr\n                INNER JOIN latest_group_details AS lg\n                    ON {{ dbtvault.multikey([src_pk], prefix=['lr', 'lg'], condition='=') }}\n                    AND {{ dbtvault.prefix([src_ldts], 'lr') }} = {{ dbtvault.prefix([src_ldts], 'lg') }}\n            ) AS active_records\n            WHERE {{ dbtvault.multikey([src_pk], prefix=['stage', 'active_records'], condition='=') }}\n                AND {{ dbtvault.prefix([src_hashdiff], 'stage') }} = {{ dbtvault.prefix([src_hashdiff], 'active_records', alias_target='target') }}\n{# In order to maintain the parallel with the standard satellite, we don''t allow for groups of records to be updated if the ldts is the only difference #}\n{#        AND {{ dbtvault.prefix([src_ldts], 'stage') }} = {{ dbtvault.prefix([src_ldts], 'active_records') }} #}\n                AND {{ dbtvault.multikey(src_cdk, prefix=['stage', 'active_records'], condition='=') }}\n                AND stage.source_count = active_records.latest_count\n        )\n        AND {{ dbtvault.multikey([src_pk], prefix=['source_data_with_count', 'stage'], condition='=') }}\n    )\n{# endif any_incremental -#}\n{%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental", "macro.dbtvault.alias_all"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.868425}, "macro.dbtvault.sqlserver__t_link": {"unique_id": "macro.dbtvault.sqlserver__t_link", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/sqlserver/t_link.sql", "original_file_path": "macros/tables/sqlserver/t_link.sql", "name": "sqlserver__t_link", "macro_sql": "{%- macro sqlserver__t_link(src_pk, src_fk, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n{{ dbtvault.default__t_link(src_pk=src_pk, src_fk=src_fk, src_payload=src_payload,\n                            src_eff=src_eff, src_ldts=src_ldts, src_source=src_source,\n                            source_model=source_model) }}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__t_link"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.869527}, "macro.dbtvault.sqlserver__sat": {"unique_id": "macro.dbtvault.sqlserver__sat", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/sqlserver/sat.sql", "original_file_path": "macros/tables/sqlserver/sat.sql", "name": "sqlserver__sat", "macro_sql": "{%- macro sqlserver__sat(src_pk, src_hashdiff, src_payload, src_eff, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_hashdiff=src_hashdiff, src_payload=src_payload,\n                                       src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_hashdiff = dbtvault.escape_column_names(src_hashdiff) -%}\n{%- set src_payload = dbtvault.escape_column_names(src_payload) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_payload, src_eff, src_ldts, src_source]) -%}\n{%- set rank_cols = dbtvault.expand_column_list(columns=[src_pk, src_hashdiff, src_ldts]) -%}\n{%- set pk_cols = dbtvault.expand_column_list(columns=[src_pk]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + dbtvault.escape_column_names([config.get('rank_column')]) -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\nWITH source_data AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ dbtvault.prefix(source_cols_with_rank, 'a', alias_target='source') }}\n    {%- else %}\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='source') }}\n    {%- endif %}\n    FROM {{ ref(source_model) }} AS a\n    WHERE {{ dbtvault.multikey(src_pk, prefix='a', condition='IS NOT NULL') }}\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n    AND __PERIOD_FILTER__\n    {% elif model.config.materialized == 'vault_insert_by_rank' %}\n    AND __RANK_FILTER__\n    {% endif %}\n),\n\n{% if dbtvault.is_any_incremental() %}\n\nlatest_records AS (\n    SELECT {{ dbtvault.prefix(rank_cols, 'a', alias_target='target') }}\n    FROM\n    (\n        SELECT {{ dbtvault.prefix(rank_cols, 'current_records', alias_target='target') }},\n            RANK() OVER (\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'current_records') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'current_records') }} DESC\n            ) AS rank\n        FROM {{ this }} AS current_records\n            JOIN (\n                SELECT DISTINCT {{ dbtvault.prefix([src_pk], 'source_data') }}\n                FROM source_data\n            ) AS source_records\n                ON {{ dbtvault.multikey(src_pk, prefix=['current_records','source_records'], condition='=') }}\n    ) AS a\n    WHERE a.rank = 1\n),\n\n{%- endif %}\n\nrecords_to_insert AS (\n    SELECT DISTINCT {{ dbtvault.alias_all(source_cols, 'stage') }}\n    FROM source_data AS stage\n    {%- if dbtvault.is_any_incremental() %}\n        LEFT JOIN latest_records\n        ON {{ dbtvault.multikey(src_pk, prefix=['latest_records','stage'], condition='=') }}\n        WHERE {{ dbtvault.prefix([src_hashdiff], 'latest_records', alias_target='target') }} != {{ dbtvault.prefix([src_hashdiff], 'stage') }}\n            OR {{ dbtvault.prefix([src_hashdiff], 'latest_records', alias_target='target') }} IS NULL\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental", "macro.dbtvault.alias_all"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.878714}, "macro.dbtvault.sqlserver__hub": {"unique_id": "macro.dbtvault.sqlserver__hub", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/sqlserver/hub.sql", "original_file_path": "macros/tables/sqlserver/hub.sql", "name": "sqlserver__hub", "macro_sql": "{%- macro sqlserver__hub(src_pk, src_nk, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_nk=src_nk,\n                                       src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_nk = dbtvault.escape_column_names(src_nk) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_nk, src_ldts, src_source]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + dbtvault.escape_column_names([config.get('rank_column')]) -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{{ 'WITH ' -}}\n\n{%- if not (source_model is iterable and source_model is not string) -%}\n    {%- set source_model = [source_model] -%}\n{%- endif -%}\n\n{%- set ns = namespace(last_cte= \"\") -%}\n\n{%- for src in source_model -%}\n\n{%- set source_number = loop.index | string -%}\n\nrow_rank_{{ source_number }} AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ source_cols_with_rank | join(', ') }}\n    {%- else %}\n    SELECT {{ source_cols | join(', ') }}\n    {%- endif %}\n    FROM\n    (\n        {%- if model.config.materialized == 'vault_insert_by_rank' %}\n        SELECT {{ dbtvault.prefix(source_cols_with_rank, 'rr') }},\n        {%- else %}\n        SELECT {{ dbtvault.prefix(source_cols, 'rr') }},\n        {%- endif %}\n               ROW_NUMBER() OVER(\n                   PARTITION BY {{ dbtvault.prefix([src_pk], 'rr') }}\n                   ORDER BY {{ dbtvault.prefix([src_ldts], 'rr') }}\n               ) AS row_number\n        FROM {{ ref(src) }} AS rr\n        WHERE {{ dbtvault.multikey(src_pk, prefix='rr', condition='IS NOT NULL') }}\n    ) h\n    WHERE h.row_number = 1\n    {%- set ns.last_cte = \"row_rank_{}\".format(source_number) %}\n),{{ \"\\n\" if not loop.last }}\n{% endfor -%}\n{% if source_model | length > 1 %}\nstage_union AS (\n    {%- for src in source_model %}\n    SELECT * FROM row_rank_{{ loop.index | string }}\n    {%- if not loop.last %}\n    UNION ALL\n    {%- endif %}\n    {%- endfor %}\n    {%- set ns.last_cte = \"stage_union\" %}\n),\n{%- endif -%}\n{%- if model.config.materialized == 'vault_insert_by_period' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __PERIOD_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- elif model.config.materialized == 'vault_insert_by_rank' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __RANK_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- endif -%}\n{%- if source_model | length > 1 %}\n\nrow_rank_union AS (\n    SELECT *\n    FROM\n    (\n        SELECT ru.*,\n               ROW_NUMBER() OVER(\n                   PARTITION BY {{ dbtvault.prefix([src_pk], 'ru') }}\n                   ORDER BY {{ dbtvault.prefix([src_ldts], 'ru') }}, {{ dbtvault.prefix([src_source], 'ru') }} ASC\n               ) AS row_rank_number\n        FROM {{ ns.last_cte }} AS ru\n        WHERE {{ dbtvault.multikey(src_pk, prefix='ru', condition='IS NOT NULL') }}\n    ) h\n    WHERE h.row_rank_number = 1\n    {%- set ns.last_cte = \"row_rank_union\" %}\n),\n{% endif %}\nrecords_to_insert AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='target') }}\n    FROM {{ ns.last_cte }} AS a\n    {%- if dbtvault.is_any_incremental() %}\n    LEFT JOIN {{ this }} AS d\n    ON {{ dbtvault.multikey(src_pk, prefix=['a','d'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='d', condition='IS NULL') }}\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.891142}, "macro.dbtvault.sqlserver__eff_sat": {"unique_id": "macro.dbtvault.sqlserver__eff_sat", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/sqlserver/eff_sat.sql", "original_file_path": "macros/tables/sqlserver/eff_sat.sql", "name": "sqlserver__eff_sat", "macro_sql": "{%- macro sqlserver__eff_sat(src_pk, src_dfk, src_sfk, src_start_date, src_end_date, src_eff, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_dfk=src_dfk, src_sfk=src_sfk,\n                                       src_start_date=src_start_date, src_end_date=src_end_date,\n                                       src_eff=src_eff, src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_dfk = dbtvault.escape_column_names(src_dfk) -%}\n{%- set src_sfk = dbtvault.escape_column_names(src_sfk) -%}\n{%- set src_start_date = dbtvault.escape_column_names(src_start_date) -%}\n{%- set src_end_date = dbtvault.escape_column_names(src_end_date) -%}\n{%- set src_eff = dbtvault.escape_column_names(src_eff) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_dfk, src_sfk, src_start_date, src_end_date, src_eff, src_ldts, src_source]) -%}\n{%- set fk_cols = dbtvault.expand_column_list(columns=[src_dfk, src_sfk]) -%}\n{%- set dfk_cols = dbtvault.expand_column_list(columns=[src_dfk]) -%}\n{%- set is_auto_end_dating = config.get('is_auto_end_dating', default=false) %}\n\n{{- dbtvault.prepend_generated_by() }}\n\n{%- set max_datetime = var('max_datetime', '9999-12-31 23:59:59.9999999') %}\n\nWITH source_data AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='source') }}\n    FROM {{ ref(source_model) }} AS a\n    WHERE {{ dbtvault.multikey(src_dfk, prefix='a', condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(src_sfk, prefix='a', condition='IS NOT NULL') }}\n    {%- if model.config.materialized == 'vault_insert_by_period' %}\n    AND __PERIOD_FILTER__\n    {%- elif model.config.materialized == 'vault_insert_by_rank' %}\n    AND __RANK_FILTER__\n    {%- endif %}\n),\n\n{%- if dbtvault.is_any_incremental() %}\n\n{# Selecting the most recent records for each link hashkey -#}\nlatest_records AS (\n    SELECT *\n    FROM\n    (\n        SELECT {{ dbtvault.alias_all(source_cols, 'b') }},\n               ROW_NUMBER() OVER (\n                    PARTITION BY {{ dbtvault.prefix([src_pk], 'b') }}\n                    ORDER BY b.{{ src_ldts }} DESC\n               ) AS row_num\n        FROM {{ this }} AS b\n    ) l\n    WHERE l.row_num = 1\n),\n\n{# Selecting the open records of the most recent records for each link hashkey -#}\nlatest_open AS (\n    SELECT {{ dbtvault.alias_all(source_cols, 'c') }}\n    FROM latest_records AS c\n    WHERE CONVERT(DATE, c.{{ src_end_date }}) = CONVERT(DATE, '{{ max_datetime }}')\n),\n\n{# Selecting the closed records of the most recent records for each link hashkey -#}\nlatest_closed AS (\n    SELECT {{ dbtvault.alias_all(source_cols, 'd') }}\n    FROM latest_records AS d\n    WHERE CONVERT(DATE, d.{{ src_end_date }}) != CONVERT(DATE, '{{ max_datetime }}')\n),\n\n{# Identifying the completely new link relationships to be opened in eff sat -#}\nnew_open_records AS (\n    SELECT DISTINCT\n        {{ dbtvault.alias_all(source_cols, 'f') }}\n    FROM source_data AS f\n    LEFT JOIN latest_records AS lr\n    ON {{ dbtvault.multikey(src_pk, prefix=['f','lr'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='lr', condition='IS NULL') }}\n),\n\n{# Identifying the currently closed link relationships to be reopened in eff sat -#}\nnew_reopened_records AS (\n    SELECT DISTINCT\n        {{ dbtvault.prefix([src_pk], 'lc') }},\n        {{ dbtvault.alias_all(fk_cols, 'lc') }},\n        lc.{{ src_start_date }} AS {{ src_start_date }},\n        g.{{ src_end_date }} AS {{ src_end_date }},\n        g.{{ src_eff }} AS {{ src_eff }},\n        g.{{ src_ldts }},\n        g.{{ src_source }}\n    FROM source_data AS g\n    INNER JOIN latest_closed AS lc\n    ON {{ dbtvault.multikey(src_pk, prefix=['g','lc'], condition='=') }}\n    WHERE CAST((g.{{ src_end_date }}) AS DATE) = CAST(('{{ max_datetime }}') AS DATE)\n),\n\n{%- if is_auto_end_dating %}\n\n{# Creating the closing records -#}\n{# Identifying the currently open relationships that need to be closed due to change in SFK(s) -#}\nnew_closed_records AS (\n    SELECT DISTINCT\n        {{ dbtvault.prefix([src_pk], 'lo') }},\n        {{ dbtvault.alias_all(fk_cols, 'lo') }},\n        lo.{{ src_start_date }} AS {{ src_start_date }},\n        h.{{ src_eff }} AS {{ src_end_date }},\n        h.{{ src_eff }} AS {{ src_eff }},\n        h.{{ src_ldts }},\n        lo.{{ src_source }}\n    FROM source_data AS h\n    INNER JOIN latest_open AS lo\n    ON {{ dbtvault.multikey(src_dfk, prefix=['lo', 'h'], condition='=') }}\n    WHERE ({{ dbtvault.multikey(src_sfk, prefix=['lo', 'h'], condition='<>', operator='OR') }})\n),\n\n{#- else if is_auto_end_dating -#}\n{% else %}\n\nnew_closed_records AS (\n    SELECT DISTINCT\n        lo.{{ src_pk }},\n        {{ dbtvault.alias_all(fk_cols, 'lo') }},\n        lo.{{ src_start_date }} AS {{ src_start_date }},\n        h.{{ src_eff }} AS {{ src_end_date }},\n        h.{{ src_eff }} AS {{ src_eff }},\n        h.{{ src_ldts }},\n        lo.{{ src_source }}\n    FROM source_data AS h\n    LEFT JOIN Latest_open AS lo\n    ON lo.{{ src_pk }} = h.{{ src_pk }}\n    LEFT JOIN latest_closed AS lc\n    ON lc.{{ src_pk }} = h.{{ src_pk }}\n    WHERE CAST((h.{{ src_end_date }}) AS DATE) != CAST(('{{ max_datetime }}') AS DATE)\n    AND lo.{{ src_pk }} IS NOT NULL\n    AND lc.{{ src_pk }} IS NULL\n),\n\n{#- end if is_auto_end_dating -#}\n{%- endif %}\n\nrecords_to_insert AS (\n    SELECT * FROM new_open_records\n    UNION\n    SELECT * FROM new_reopened_records\n    UNION\n    SELECT * FROM new_closed_records\n)\n\n{#- else if not dbtvault.is_any_incremental() -#}\n{%- else %}\n\nrecords_to_insert AS (\n    SELECT {{ dbtvault.alias_all(source_cols, 'i') }}\n    FROM source_data AS i\n)\n\n{#- end if not dbtvault.is_any_incremental() -#}\n{%- endif %}\n\nSELECT * FROM records_to_insert\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental", "macro.dbtvault.alias_all"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.903641}, "macro.dbtvault.sqlserver__link": {"unique_id": "macro.dbtvault.sqlserver__link", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/sqlserver/link.sql", "original_file_path": "macros/tables/sqlserver/link.sql", "name": "sqlserver__link", "macro_sql": "{%- macro sqlserver__link(src_pk, src_fk, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_fk=src_fk,\n                                       src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_fk = dbtvault.escape_column_names(src_fk) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_fk, src_ldts, src_source]) -%}\n{%- set fk_cols = dbtvault.expand_column_list([src_fk]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + dbtvault.escape_column_names([config.get('rank_column')]) -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{{ 'WITH ' -}}\n\n{%- if not (source_model is iterable and source_model is not string) -%}\n    {%- set source_model = [source_model] -%}\n{%- endif -%}\n\n{%- set ns = namespace(last_cte= \"\") -%}\n\n{%- for src in source_model -%}\n\n{%- set source_number = loop.index | string -%}\n\nrow_rank_{{ source_number }} AS (\n    SELECT *\n    FROM\n    (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ dbtvault.prefix(source_cols_with_rank, 'rr') }},\n    {%- else %}\n    SELECT {{ dbtvault.prefix(source_cols, 'rr') }},\n    {%- endif %}\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'rr') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'rr') }}\n           ) AS row_number\n    FROM {{ ref(src) }} AS rr\n    {%- if source_model | length == 1 %}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='rr', condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(fk_cols, prefix='rr', condition='IS NOT NULL') }}\n    {%- endif %}\n    ) l\n    WHERE l.row_number = 1\n    {%- set ns.last_cte = \"row_rank_{}\".format(source_number) %}\n),{{ \"\\n\" if not loop.last }}\n{% endfor -%}\n{% if source_model | length > 1 %}\nstage_union AS (\n    {%- for src in source_model %}\n    SELECT * FROM row_rank_{{ loop.index | string }}\n    {%- if not loop.last %}\n    UNION ALL\n    {%- endif %}\n    {%- endfor %}\n    {%- set ns.last_cte = \"stage_union\" %}\n),\n{%- endif -%}\n{%- if model.config.materialized == 'vault_insert_by_period' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __PERIOD_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- elif model.config.materialized == 'vault_insert_by_rank' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __RANK_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{% endif %}\n{%- if source_model | length > 1 %}\n\nrow_rank_union AS (\n    SELECT *\n    FROM\n    (\n    SELECT ru.*,\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'ru') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'ru') }}, {{ dbtvault.prefix([src_source], 'ru') }} ASC\n           ) AS row_rank_number\n    FROM {{ ns.last_cte }} AS ru\n    WHERE {{ dbtvault.multikey(src_pk, prefix='ru', condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(fk_cols, prefix='ru', condition='IS NOT NULL') }}\n    ) r\n    WHERE r.row_rank_number = 1\n    {%- set ns.last_cte = \"row_rank_union\" %}\n),\n{% endif %}\nrecords_to_insert AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='target') }}\n    FROM {{ ns.last_cte }} AS a\n    {%- if dbtvault.is_any_incremental() %}\n    LEFT JOIN {{ this }} AS d\n    ON {{ dbtvault.multikey(src_pk, prefix=['a','d'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='d', condition='IS NULL') }}\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.9160728}, "macro.dbtvault.source_columns": {"unique_id": "macro.dbtvault.source_columns", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/staging/source_columns.sql", "original_file_path": "macros/staging/source_columns.sql", "name": "source_columns", "macro_sql": "{%- macro source_columns(source_relation=none) -%}\n\n    {%- if source_relation -%}\n        {%- set source_model_cols = adapter.get_columns_in_relation(source_relation) -%}\n\n        {%- set column_list = [] -%}\n\n        {%- for source_col in source_model_cols -%}\n            {%- do column_list.append(source_col.column) -%}\n        {%- endfor -%}\n\n        {%- do return(column_list) -%}\n    {%- endif %}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.9206889}, "macro.dbtvault.rank_columns": {"unique_id": "macro.dbtvault.rank_columns", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/staging/rank_columns.sql", "original_file_path": "macros/staging/rank_columns.sql", "name": "rank_columns", "macro_sql": "{%- macro rank_columns(columns=none) -%}\n\n    {{- adapter.dispatch('rank_columns', 'dbtvault')(columns=columns) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__rank_columns"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.934877}, "macro.dbtvault.default__rank_columns": {"unique_id": "macro.dbtvault.default__rank_columns", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/staging/rank_columns.sql", "original_file_path": "macros/staging/rank_columns.sql", "name": "default__rank_columns", "macro_sql": "\n\n{%- macro default__rank_columns(columns=none) -%}\n\n{%- if columns is mapping and columns is not none -%}\n\n    {%- for col in columns -%}\n\n        {%- if columns[col] is mapping and columns[col].partition_by and columns[col].order_by -%}\n\n            {%- set order_by = columns[col].order_by -%}\n            {%- set partition_by = columns[col].partition_by -%}\n            {%- set dense_rank = columns[col].dense_rank -%}\n\n            {%- if dbtvault.is_nothing(dense_rank) %}\n                {%- set rank_type = \"RANK()\" -%}\n            {%- elif dense_rank is true -%}\n                {%- set rank_type = \"DENSE_RANK()\" -%}\n            {%- else -%}\n                {%- if execute -%}\n                    {%- do exceptions.raise_compiler_error('If dense_rank is provided, it must be true or false, not {}'.format(dense_rank)) -%}\n                {% endif %}\n            {%- endif -%}\n\n            {%- if dbtvault.is_list(order_by) -%}\n\n                {%- set order_by_str_lst = [] -%}\n\n                {% for order_by_col in order_by %}\n\n                    {%- if order_by_col is mapping %}\n                        {%- set column_name, direction = order_by_col.items()|first -%}\n                        {%- set order_by_str = \"{} {}\".format(dbtvault.escape_column_names(column_name), direction) | trim -%}\n                    {%- else -%}\n                        {%- set order_by_str = dbtvault.escape_column_names(order_by_col) -%}\n                    {%- endif -%}\n\n                    {%- do order_by_str_lst.append(order_by_str) -%}\n                {%- endfor -%}\n\n                {%- set order_by_str = order_by_str_lst | join(\", \") -%}\n\n            {%- else -%}\n\n                {%- if order_by is mapping %}\n                    {%- set column_name, direction = order_by.items()|first -%}\n                {%- else -%}\n                    {%- set column_name = order_by -%}\n                    {%- set direction = '' -%}\n                {%- endif -%}\n\n                {%- set order_by_str = \"{} {}\".format(dbtvault.escape_column_names(column_name), direction) | trim -%}\n            {%- endif -%}\n\n            {%- if dbtvault.is_list(partition_by) -%}\n                {%- set partition_by_str = dbtvault.escape_column_names(partition_by) | join(\", \") -%}\n            {%- else -%}\n                {%- set partition_by_str = dbtvault.escape_column_names(partition_by) -%}\n            {%- endif -%}\n\n            {{- \"{} OVER (PARTITION BY {} ORDER BY {}) AS {}\".format(rank_type, partition_by_str, order_by_str, dbtvault.escape_column_names(col)) | indent(4) -}}\n\n        {%- endif -%}\n\n        {{- \",\\n\" if not loop.last -}}\n    {%- endfor -%}\n\n{%- endif %}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.is_nothing", "macro.dbtvault.is_list", "macro.dbtvault.escape_column_names"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.9392462}, "macro.dbtvault.derive_columns": {"unique_id": "macro.dbtvault.derive_columns", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/staging/derive_columns.sql", "original_file_path": "macros/staging/derive_columns.sql", "name": "derive_columns", "macro_sql": "{%- macro derive_columns(source_relation=none, columns=none) -%}\n\n    {{- adapter.dispatch('derive_columns', 'dbtvault')(source_relation=source_relation, columns=columns) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__derive_columns"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.9410079}, "macro.dbtvault.default__derive_columns": {"unique_id": "macro.dbtvault.default__derive_columns", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/staging/derive_columns.sql", "original_file_path": "macros/staging/derive_columns.sql", "name": "default__derive_columns", "macro_sql": "\n\n{%- macro default__derive_columns(source_relation=none, columns=none) -%}\n\n{%- set exclude_columns = [] -%}\n{%- set include_columns = [] -%}\n{%- set src_columns = [] -%}\n{%- set der_columns = [] -%}\n\n{%- set source_cols = dbtvault.source_columns(source_relation=source_relation) -%}\n\n{%- if columns is mapping and columns is not none -%}\n\n    {#- Add aliases of derived columns to excludes and full SQL to includes -#}\n    {%- for col in columns -%}\n\n        {%- if dbtvault.is_list(columns[col]) -%}\n            {%- set column_list = [] -%}\n\n            {%- for concat_component in columns[col] -%}\n                {%- set column_str = dbtvault.as_constant(concat_component) -%}\n                {%- do column_list.append(column_str) -%}\n            {%- endfor -%}\n            {%- set concat = dbtvault.concat_ws(column_list, \"||\") -%}\n            {%- set concat_string = concat ~ \" AS \" ~ dbtvault.escape_column_names(col) -%}\n\n            {% set concat_string = \"CONCAT_WS(\" ~ \"'||', \" ~ column_list | join(\", \") ~ \") AS \" ~ col %}\n\n            {%- do der_columns.append(concat_string) -%}\n            {%- set exclude_columns = exclude_columns + columns[col] -%}\n        {% else %}\n            {%- set column_str = dbtvault.as_constant(columns[col]) -%}\n            {%- do der_columns.append(column_str ~ \" AS \" ~ dbtvault.escape_column_names(col)) -%}\n            {%- do exclude_columns.append(col) -%}\n        {% endif %}\n\n    {%- endfor -%}\n\n    {#- Add all columns from source_model relation -#}\n    {%- if source_relation is defined and source_relation is not none -%}\n\n        {%- for col in source_cols -%}\n            {%- if col not in exclude_columns -%}\n                {%- do src_columns.append(dbtvault.escape_column_names(col)) -%}\n            {%- endif -%}\n        {%- endfor -%}\n\n    {%- endif -%}\n\n    {#- Makes sure the columns are appended in a logical order. Source columns then derived columns -#}\n    {%- set include_columns = src_columns + der_columns -%}\n\n    {#- Print out all columns in includes -#}\n    {%- for col in include_columns -%}\n        {{- col | indent(4) -}}{{ \",\\n\" if not loop.last }}\n    {%- endfor -%}\n\n{%- else -%}\n\n{%- if execute -%}\n{{ exceptions.raise_compiler_error(\"Invalid column configuration:\nexpected format: {'source_relation': Relation, 'columns': {column_name: column_value}}\ngot: {'source_relation': \" ~ source_relation ~ \", 'columns': \" ~ columns ~ \"}\") }}\n{%- endif %}\n\n{%- endif %}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.source_columns", "macro.dbtvault.is_list", "macro.dbtvault.as_constant", "macro.dbtvault.concat_ws", "macro.dbtvault.escape_column_names"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.944999}, "macro.dbtvault.as_constant": {"unique_id": "macro.dbtvault.as_constant", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/as_constant.sql", "original_file_path": "macros/internal/metadata_processing/as_constant.sql", "name": "as_constant", "macro_sql": "{%- macro as_constant(column_str=none) -%}\n\n    {{- adapter.dispatch('as_constant', 'dbtvault')(column_str=column_str) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__as_constant"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.946125}, "macro.dbtvault.default__as_constant": {"unique_id": "macro.dbtvault.default__as_constant", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/as_constant.sql", "original_file_path": "macros/internal/metadata_processing/as_constant.sql", "name": "default__as_constant", "macro_sql": "\n\n{%- macro default__as_constant(column_str) -%}\n\n    {%- if column_str is not none and column_str is string and column_str -%}\n\n        {%- if column_str | first == \"!\" -%}\n        \n            {{- return(\"'\" ~ column_str[1:] ~ \"'\") -}}\n        \n        {%- else -%}\n        \n            {%- if dbtvault.is_expression(column_str) -%}\n\n                {{- return(column_str) -}}\n\n            {%- else -%}\n\n                {{- return(dbtvault.escape_column_names(column_str)) -}}\n\n            {%- endif -%}\n\n        {%- endif -%}\n    {%- else -%}\n        {%- if execute -%}\n            {{ exceptions.raise_compiler_error(\"Invalid columns_str object provided. Must be a string and not null.\") }}\n        {%- endif %}\n    {%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.is_expression", "macro.dbtvault.escape_column_names"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.9473631}, "macro.dbtvault.escape_column_names": {"unique_id": "macro.dbtvault.escape_column_names", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/escape_column_names.sql", "original_file_path": "macros/internal/metadata_processing/escape_column_names.sql", "name": "escape_column_names", "macro_sql": "{%- macro escape_column_names(columns=none) -%}\n\n{# Different platforms use different escape characters, the default below is for Snowflake which uses double quotes #}\n\n    {%- if dbtvault.is_something(columns) -%}\n\n        {%- set col_string = '' -%}\n        {%- set col_list = [] -%}\n        {%- set col_mapping = {} -%}\n\n        {%- if columns is string -%}\n\n            {%- set col_string = dbtvault.escape_column_name(columns) -%}\n\n        {%- elif dbtvault.is_list(columns) -%}\n\n            {%- for col in columns -%}\n\n                {%- if col is string -%}\n\n                    {%- set escaped_col = dbtvault.escape_column_name(col) -%}\n\n                    {%- do col_list.append(escaped_col) -%}\n\n                {%- else -%}\n\n                    {%- if execute -%}\n                        {{- exceptions.raise_compiler_error(\"Invalid column name(s) provided. Must be a string.\") -}}\n                    {%- endif -%}\n\n                {%- endif -%}\n\n            {%- endfor -%}\n\n        {%- elif columns is mapping -%}\n\n            {%- if columns['source_column'] and columns['alias'] -%}\n\n                {%- set escaped_source_col = dbtvault.escape_column_name(columns['source_column']) -%}\n                {%- set escaped_alias_col = dbtvault.escape_column_name(columns['alias']) -%}\n                {%- set col_mapping = {\"source_column\": escaped_source_col, \"alias\": escaped_alias_col} -%}\n\n            {%- else -%}\n\n                {%- if execute -%}\n                    {{- exceptions.raise_compiler_error(\"Invalid column name(s) provided. Must be a string, a list of strings, or a dictionary of hashdiff metadata.\") -}}\n                {%- endif %}\n\n            {%- endif -%}\n\n        {%- else -%}\n\n            {%- if execute -%}\n                {{- exceptions.raise_compiler_error(\"Invalid column name(s) provided. Must be a string, a list of strings, or a dictionary of hashdiff metadata.\") -}}\n            {%- endif %}\n\n        {%- endif -%}\n\n    {%- elif columns == '' -%}\n\n        {%- if execute -%}\n            {{- exceptions.raise_compiler_error(\"Expected a column name or a list of column names, got an empty string\") -}}\n        {%- endif -%}\n\n    {%- endif -%}\n\n{%- if columns is none -%}\n\n    {%- do return(none) -%}\n\n{%- elif columns == [] -%}\n\n    {%- do return([]) -%}\n\n{%- elif columns == {} -%}\n\n    {%- do return({}) -%}\n\n{%- elif columns is string -%}\n\n    {%- do return(col_string) -%}\n\n{%- elif dbtvault.is_list(columns) -%}\n\n    {%- do return(col_list) -%}\n\n{%- elif columns is mapping -%}\n\n    {%- do return(col_mapping) -%}\n\n{%- endif -%}\n\n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.is_something", "macro.dbtvault.escape_column_name", "macro.dbtvault.is_list"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.9568698}, "macro.dbtvault.escape_column_name": {"unique_id": "macro.dbtvault.escape_column_name", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/escape_column_names.sql", "original_file_path": "macros/internal/metadata_processing/escape_column_names.sql", "name": "escape_column_name", "macro_sql": "{%- macro escape_column_name(column) -%}\n\n    {{- adapter.dispatch('escape_column_name', 'dbtvault')(column=column) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__escape_column_name"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.9572449}, "macro.dbtvault.default__escape_column_name": {"unique_id": "macro.dbtvault.default__escape_column_name", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/escape_column_names.sql", "original_file_path": "macros/internal/metadata_processing/escape_column_names.sql", "name": "default__escape_column_name", "macro_sql": "\n\n{%- macro default__escape_column_name(column) -%}\n\n    {%- set escape_char_left  = var('escape_char_left',  '\"') -%}\n    {%- set escape_char_right = var('escape_char_right', '\"') -%}\n\n    {%- set escaped_column_name = escape_char_left ~ column | replace(escape_char_left, '') | replace(escape_char_right, '') | trim ~ escape_char_right -%}\n\n    {%- do return(escaped_column_name) -%}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.9580748}, "macro.dbtvault.sqlserver__escape_column_name": {"unique_id": "macro.dbtvault.sqlserver__escape_column_name", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/escape_column_names.sql", "original_file_path": "macros/internal/metadata_processing/escape_column_names.sql", "name": "sqlserver__escape_column_name", "macro_sql": "{%- macro sqlserver__escape_column_name(column) -%}\n\n    {%- set escape_char_left  = var('escape_char_left',  '\"') -%}\n    {%- set escape_char_right = var('escape_char_right', '\"') -%}\n\n    {%- set escaped_column_name = escape_char_left ~ column | replace(escape_char_left, '') | replace(escape_char_right, '') | trim ~ escape_char_right -%}\n\n    {%- do return(escaped_column_name) -%}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.958903}, "macro.dbtvault.bigquery__escape_column_name": {"unique_id": "macro.dbtvault.bigquery__escape_column_name", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/escape_column_names.sql", "original_file_path": "macros/internal/metadata_processing/escape_column_names.sql", "name": "bigquery__escape_column_name", "macro_sql": "{%- macro bigquery__escape_column_name(column) -%}\n\n    {%- set escape_char_left  = var('escape_char_left',  '`') -%}\n    {%- set escape_char_right = var('escape_char_right', '`') -%}\n\n    {%- set escaped_column_name = escape_char_left ~ column | replace(escape_char_left, '') | replace(escape_char_right, '') | trim ~ escape_char_right -%}\n\n    {%- do return(escaped_column_name) -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.9597352}, "macro.dbtvault.alias": {"unique_id": "macro.dbtvault.alias", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/alias.sql", "original_file_path": "macros/internal/metadata_processing/alias.sql", "name": "alias", "macro_sql": "{%- macro alias(alias_config=none, prefix=none) -%}\n\n    {{- adapter.dispatch('alias', 'dbtvault')(alias_config=alias_config, prefix=prefix) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__alias"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.961226}, "macro.dbtvault.default__alias": {"unique_id": "macro.dbtvault.default__alias", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/alias.sql", "original_file_path": "macros/internal/metadata_processing/alias.sql", "name": "default__alias", "macro_sql": "\n\n{%- macro default__alias(alias_config=none, prefix=none) -%}\n\n{%- if alias_config is defined and alias_config is not none and alias_config -%}\n\n    {%- if alias_config is mapping -%}\n\n        {%- if alias_config['source_column'] and alias_config['alias'] -%}\n\n            {%- if prefix -%}\n                {{prefix}}.{{ alias_config['source_column'] }} AS {{ alias_config['alias'] }}\n            {%- else -%}\n                {{ alias_config['source_column'] }} AS {{ alias_config['alias'] }}\n            {%- endif -%}\n\n        {%- endif -%}\n\n    {%- else -%}\n\n        {%- if prefix -%}\n\n        {{- dbtvault.prefix([alias_config], prefix) -}}\n\n        {%- else -%}\n\n        {{ alias_config }}\n\n        {%- endif -%}\n\n    {%- endif -%}\n\n{%- else -%}\n\n    {%- if execute -%}\n\n        {{ exceptions.raise_compiler_error(\"Invalid alias configuration:\\nexpected format: {source_column: 'column', alias: 'column_alias'}\\ngot: \" ~ alias_config) }}\n\n    {%- endif -%}\n\n{%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.prefix"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.9628842}, "macro.dbtvault.concat_ws": {"unique_id": "macro.dbtvault.concat_ws", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/concat_ws.sql", "original_file_path": "macros/internal/metadata_processing/concat_ws.sql", "name": "concat_ws", "macro_sql": "{%- macro concat_ws(string_list, separator=\"||\") -%}\n\n    {{- adapter.dispatch('concat_ws', 'dbtvault')(string_list=string_list, separator=separator) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__concat_ws"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.963824}, "macro.dbtvault.default__concat_ws": {"unique_id": "macro.dbtvault.default__concat_ws", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/concat_ws.sql", "original_file_path": "macros/internal/metadata_processing/concat_ws.sql", "name": "default__concat_ws", "macro_sql": "\n\n{%- macro default__concat_ws(string_list, separator=\"||\") -%}\n\n    {{  \"CONCAT_WS('\" ~ separator ~ \"', \" ~ string_list | join(\", \") ~ \")\" }}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.964223}, "macro.dbtvault.bigquery__concat_ws": {"unique_id": "macro.dbtvault.bigquery__concat_ws", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/concat_ws.sql", "original_file_path": "macros/internal/metadata_processing/concat_ws.sql", "name": "bigquery__concat_ws", "macro_sql": "{%- macro bigquery__concat_ws(string_list, separator=\"||\") -%}\n\n    {{- 'CONCAT(' -}}\n    {%- for str in string_list -%}\n        {{- \"{}\".format(str) -}}\n        {{- \",'{}',\".format(separator) if not loop.last -}}\n    {%- endfor -%}\n    {{- '\\n)' -}}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.964873}, "macro.dbtvault.multikey": {"unique_id": "macro.dbtvault.multikey", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/multikey.sql", "original_file_path": "macros/internal/metadata_processing/multikey.sql", "name": "multikey", "macro_sql": "{%- macro multikey(columns, prefix=none, condition=none, operator='AND') -%}\n\n    {{- adapter.dispatch('multikey', 'dbtvault')(columns=columns, prefix=prefix, condition=condition, operator=operator) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__multikey"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.966862}, "macro.dbtvault.default__multikey": {"unique_id": "macro.dbtvault.default__multikey", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/multikey.sql", "original_file_path": "macros/internal/metadata_processing/multikey.sql", "name": "default__multikey", "macro_sql": "\n\n{%- macro default__multikey(columns, prefix=none, condition=none, operator='AND') -%}\n\n    {%- if prefix is string -%}\n        {%- set prefix = [prefix] -%}\n    {%- endif -%}\n\n    {%- if columns is string -%}\n        {%- set columns = [columns] -%}\n    {%- endif -%}\n\n    {%- if condition in ['<>', '!=', '='] -%}\n        {%- for col in columns -%}\n            {%- if prefix -%}\n                {{- dbtvault.prefix([col], prefix[0], alias_target='target') }} {{ condition }} {{ dbtvault.prefix([col], prefix[1]) -}}\n            {%- endif %}\n            {%- if not loop.last %} {{ operator }} {% endif -%}\n        {% endfor -%}\n    {%- else -%}\n        {%- if dbtvault.is_list(columns) -%}\n            {%- for col in columns -%}\n                {{ (prefix[0] ~ '.') if prefix }}{{ col }} {{ condition if condition else '' }}\n                {%- if not loop.last -%} {{ \"\\n    \" ~ operator }} {% endif -%}\n            {%- endfor -%}\n        {%- else -%}\n            {{ prefix[0] ~ '.' if prefix }}{{ columns }} {{ condition if condition else '' }}\n        {%- endif -%}\n    {%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.prefix", "macro.dbtvault.is_list"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.969601}, "macro.dbtvault.expand_column_list": {"unique_id": "macro.dbtvault.expand_column_list", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/expand_column_list.sql", "original_file_path": "macros/internal/metadata_processing/expand_column_list.sql", "name": "expand_column_list", "macro_sql": "{%- macro expand_column_list(columns=none) -%}\n\n{%- if not columns -%}\n    {%- if execute -%}\n         {{- exceptions.raise_compiler_error(\"Expected a list of columns, got: \" ~ columns) -}}\n    {%- endif -%}\n{%- endif -%}\n\n{%- set col_list = [] -%}\n\n{%- if dbtvault.is_list(columns) -%}\n\n    {%- set columns = columns | reject(\"none\") %}\n\n    {%- for col in columns -%}\n\n        {%- if col is string -%}\n\n            {%- do col_list.append(col) -%}\n\n        {#- If list of lists -#}\n        {%- elif dbtvault.is_list(col) -%}\n\n            {%- for cols in col -%}\n\n                {%- do col_list.append(cols) -%}\n\n            {%- endfor -%}\n        {%- elif col is mapping -%}\n\n            {%- do col_list.append(col) -%}\n\n        {%- else -%}\n\n            {%- if execute -%}\n                {{- exceptions.raise_compiler_error(\"Invalid columns object provided. Must be a list of lists, dictionaries or strings.\") -}}\n            {%- endif %}\n\n        {%- endif -%}\n\n    {%- endfor -%}\n{%- else -%}\n\n    {%- if execute -%}\n        {{- exceptions.raise_compiler_error(\"Invalid columns object provided. Must be a list.\") -}}\n    {%- endif %}\n\n{%- endif -%}\n\n{%- do return(col_list) -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.is_list"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.972527}, "macro.dbtvault.check_required_parameters": {"unique_id": "macro.dbtvault.check_required_parameters", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/check_required_parameters.sql", "original_file_path": "macros/internal/metadata_processing/check_required_parameters.sql", "name": "check_required_parameters", "macro_sql": "{%- macro check_required_parameters() -%}\n\n    {%- set ns = namespace(missing_parameters=[]) -%}\n\n    {%- if kwargs is not none -%}\n\n        {%- for k, v in kwargs.items() %}\n            {%- do ns.missing_parameters.append(k) if v is none -%}\n        {%- endfor -%}\n\n        {%- if ns.missing_parameters -%}\n            {{- exceptions.raise_compiler_error(\"Required parameter(s) missing or none in '{}': {}\".format(this, ns.missing_parameters | join(\", \"))) -}}\n        {%- endif -%}\n    {%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.974098}, "macro.dbtvault.alias_all": {"unique_id": "macro.dbtvault.alias_all", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/alias_all.sql", "original_file_path": "macros/internal/metadata_processing/alias_all.sql", "name": "alias_all", "macro_sql": "{%- macro alias_all(columns=none, prefix=none) -%}\n\n    {{- adapter.dispatch('alias_all', 'dbtvault')(columns=columns, prefix=prefix) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__alias_all"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.975115}, "macro.dbtvault.default__alias_all": {"unique_id": "macro.dbtvault.default__alias_all", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/metadata_processing/alias_all.sql", "original_file_path": "macros/internal/metadata_processing/alias_all.sql", "name": "default__alias_all", "macro_sql": "\n\n{%- macro default__alias_all(columns, prefix) -%}\n\n{%- if dbtvault.is_list(columns) -%}\n\n    {%- for column in columns -%}\n        {{ dbtvault.alias(alias_config=column, prefix=prefix) }}\n        {%- if not loop.last -%} , {% endif -%}\n    {%- endfor -%}\n\n{%- elif columns is string -%}\n\n{{ dbtvault.alias(alias_config=columns, prefix=prefix) }}\n\n{%- else -%}\n\n    {%- if execute -%}\n        {{ exceptions.raise_compiler_error(\"Invalid columns object provided. Must be a list or a string.\") }}\n    {%- endif %}\n\n{%- endif %}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.is_list", "macro.dbtvault.alias"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.976234}, "macro.dbtvault.prepend_generated_by": {"unique_id": "macro.dbtvault.prepend_generated_by", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/helpers/prepend_generated_by.sql", "original_file_path": "macros/internal/helpers/prepend_generated_by.sql", "name": "prepend_generated_by", "macro_sql": "{%- macro prepend_generated_by() -%}\n-- Generated by dbtvault.\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.976616}, "macro.dbtvault.is_list": {"unique_id": "macro.dbtvault.is_list", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/helpers/is_checks.sql", "original_file_path": "macros/internal/helpers/is_checks.sql", "name": "is_list", "macro_sql": "{%- macro is_list(obj, empty_is_false=false) -%}\n\n    {%- if obj is iterable and obj is not string and obj is not mapping -%}\n        {%- if obj is none and obj is undefined and not obj and empty_is_false -%}\n            {%- do return(false) -%}\n        {%- endif -%}\n\n        {%- do return(true) -%}\n    {%- else -%}\n        {%- do return(false) -%}\n    {%- endif -%}\n\n{%- endmacro -%}\n\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.979597}, "macro.dbtvault.is_nothing": {"unique_id": "macro.dbtvault.is_nothing", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/helpers/is_checks.sql", "original_file_path": "macros/internal/helpers/is_checks.sql", "name": "is_nothing", "macro_sql": "{%- macro is_nothing(obj) -%}\n\n    {%- if obj is none or obj is undefined or not obj -%}\n        {%- do return(true) -%}\n    {%- else -%}\n        {%- do return(false) -%}\n    {%- endif -%}\n\n{%- endmacro -%}\n\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.980522}, "macro.dbtvault.is_something": {"unique_id": "macro.dbtvault.is_something", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/helpers/is_checks.sql", "original_file_path": "macros/internal/helpers/is_checks.sql", "name": "is_something", "macro_sql": "{%- macro is_something(obj) -%}\n\n    {%- if obj is not none and obj is defined and obj -%}\n        {%- do return(true) -%}\n    {%- else -%}\n        {%- do return(false) -%}\n    {%- endif -%}\n\n{%- endmacro -%}\n\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.981081}, "macro.dbtvault.is_expression": {"unique_id": "macro.dbtvault.is_expression", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/helpers/is_checks.sql", "original_file_path": "macros/internal/helpers/is_checks.sql", "name": "is_expression", "macro_sql": "{%- macro is_expression(obj) -%}\n\n    {%- if obj is string -%}\n        {%- if (obj | first == \"'\" and obj | last == \"'\") or (\"(\" in obj and \")\" in obj) or \"::\" in obj -%}\n            {%- do return(true) -%}\n        {%- else -%}\n            {%- do return(false) -%}\n        {%- endif -%}\n    {%- else -%}\n        {%- do return(false) -%}\n    {%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.982084}, "macro.dbtvault.process_columns_to_select": {"unique_id": "macro.dbtvault.process_columns_to_select", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/helpers/stage_processing_macros.sql", "original_file_path": "macros/internal/helpers/stage_processing_macros.sql", "name": "process_columns_to_select", "macro_sql": "{%- macro process_columns_to_select(columns_list=none, exclude_columns_list=none) -%}\n\n    {% set columns_to_select = [] %}\n\n    {% if not dbtvault.is_list(columns_list) or not dbtvault.is_list(exclude_columns_list)  %}\n\n        {{- exceptions.raise_compiler_error(\"One or both arguments are not of list type.\") -}}\n\n    {%- endif -%}\n\n    {%- if dbtvault.is_something(columns_list) and dbtvault.is_something(exclude_columns_list) -%}\n\n        {%- for col in columns_list -%}\n\n            {%- if col not in exclude_columns_list -%}\n                {%- do columns_to_select.append(col) -%}\n            {%- endif -%}\n\n        {%- endfor -%}\n\n    {%- endif -%}\n\n    {%- do return(columns_to_select) -%}\n\n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.is_list", "macro.dbtvault.is_something"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.9870589}, "macro.dbtvault.extract_column_names": {"unique_id": "macro.dbtvault.extract_column_names", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/helpers/stage_processing_macros.sql", "original_file_path": "macros/internal/helpers/stage_processing_macros.sql", "name": "extract_column_names", "macro_sql": "{%- macro extract_column_names(columns_dict=none) -%}\n\n    {%- set extracted_column_names = [] -%}\n\n    {%- if columns_dict is mapping -%}\n        {%- for key, value in columns_dict.items() -%}\n            {%- do extracted_column_names.append(key) -%}\n        {%- endfor -%}\n\n        {%- do return(extracted_column_names) -%}\n    {%- else -%}\n        {%- do return([]) -%}\n    {%- endif -%}\n\n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.987919}, "macro.dbtvault.process_hash_column_excludes": {"unique_id": "macro.dbtvault.process_hash_column_excludes", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/helpers/stage_processing_macros.sql", "original_file_path": "macros/internal/helpers/stage_processing_macros.sql", "name": "process_hash_column_excludes", "macro_sql": "{%- macro process_hash_column_excludes(hash_columns=none, source_columns=none) -%}\n\n    {%- set processed_hash_columns = {} -%}\n\n    {%- for col, col_mapping in hash_columns.items() -%}\n        \n        {%- if col_mapping is mapping -%}\n            {%- if col_mapping.exclude_columns -%}\n\n                {%- if col_mapping.columns -%}\n\n                    {%- set columns_to_hash = dbtvault.process_columns_to_select(source_columns, col_mapping.columns) -%}\n\n                    {%- do hash_columns[col].pop('exclude_columns') -%}\n                    {%- do hash_columns[col].update({'columns': columns_to_hash}) -%}\n\n                    {%- do processed_hash_columns.update({col: hash_columns[col]}) -%}\n                {%- else -%}\n\n                    {%- do hash_columns[col].pop('exclude_columns') -%}\n                    {%- do hash_columns[col].update({'columns': source_columns}) -%}\n\n                    {%- do processed_hash_columns.update({col: hash_columns[col]}) -%}\n                {%- endif -%}\n            {%- else -%}\n                {%- do processed_hash_columns.update({col: col_mapping}) -%}\n            {%- endif -%}\n        {%- else -%}\n            {%- do processed_hash_columns.update({col: col_mapping}) -%}\n        {%- endif -%}\n\n    {%- endfor -%}\n\n    {%- do return(processed_hash_columns) -%}\n\n{%- endmacro -%}\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.process_columns_to_select"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.990756}, "macro.dbtvault.print_list": {"unique_id": "macro.dbtvault.print_list", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/internal/helpers/stage_processing_macros.sql", "original_file_path": "macros/internal/helpers/stage_processing_macros.sql", "name": "print_list", "macro_sql": "{%- macro print_list(list_to_print=none, indent=4) -%}\n\n    {%- for col_name in list_to_print -%}\n        {{- col_name | indent(indent) -}}{{ \",\\n    \" if not loop.last }}\n    {%- endfor -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134125.991311}, "macro.dbtvault.materialization_vault_insert_by_rank_default": {"unique_id": "macro.dbtvault.materialization_vault_insert_by_rank_default", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/vault_insert_by_rank_materialization.sql", "original_file_path": "macros/materialisations/vault_insert_by_rank_materialization.sql", "name": "materialization_vault_insert_by_rank_default", "macro_sql": "{% materialization vault_insert_by_rank, default -%}\n\n    {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n    {% if target.type == \"sqlserver\" %}\n        {%- set target_relation = this.incorporate(type='table') -%}\n    {%  else %}\n        {%- set target_relation = this -%}\n    {% endif %}\n    {%- set existing_relation = load_relation(this) -%}\n    {%- set tmp_relation = make_temp_relation(target_relation) -%}\n\n    {%- set rank_column = dbtvault.escape_column_names(config.require('rank_column')) -%}\n    {%- set rank_source_models = config.require('rank_source_models') -%}\n\n    {%- set min_max_ranks = dbtvault.get_min_max_ranks(rank_column, rank_source_models) | as_native -%}\n\n    {%- set to_drop = [] -%}\n\n    {%- do dbtvault.check_placeholder(sql, \"__RANK_FILTER__\") -%}\n\n    {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n    -- `BEGIN` happens here:\n    {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n    {% if existing_relation is none %}\n\n        {% set filtered_sql = dbtvault.replace_placeholder_with_rank_filter(sql, rank_column, 1) %}\n        {% set build_sql = create_table_as(False, target_relation, filtered_sql) %}\n\n        {% do to_drop.append(tmp_relation) %}\n\n    {% elif existing_relation.is_view %}\n\n        {{ log(\"Dropping relation \" ~ target_relation ~ \" because it is a view and this model is a table (vault_insert_by_rank).\") }}\n        {% do adapter.drop_relation(existing_relation) %}\n\n        {% set filtered_sql = dbtvault.replace_placeholder_with_rank_filter(sql, rank_column, 1) %}\n        {% set build_sql = create_table_as(False, target_relation, filtered_sql) %}\n\n    {% elif full_refresh_mode %}\n        {% set filtered_sql = dbtvault.replace_placeholder_with_rank_filter(sql, rank_column, 1) %}\n        {% set build_sql = create_table_as(False, target_relation, filtered_sql) %}\n    {% else %}\n\n        {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n        {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n        {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n        {% for i in range(min_max_ranks.max_rank | int ) -%}\n\n            {%- set iteration_number = i + 1 -%}\n\n            {%- set filtered_sql = dbtvault.replace_placeholder_with_rank_filter(sql, rank_column, iteration_number) -%}\n\n            {{ dbt_utils.log_info(\"Running for {} {} of {} on column '{}' [{}]\".format('rank', iteration_number, min_max_ranks.max_rank, rank_column, model.unique_id)) }}\n\n            {% set tmp_relation = make_temp_relation(target_relation) %}\n\n            {# This call statement drops and then creates a temporary table #}\n            {# but MSSQL will fail to drop any temporary table created by a previous loop iteration #}\n            {# See MSSQL note and drop code below #}\n            {% call statement() -%}\n                {{ create_table_as(True, tmp_relation, filtered_sql) }}\n            {%- endcall %}\n\n            {{ adapter.expand_target_column_types(from_relation=tmp_relation,\n                                                  to_relation=target_relation) }}\n\n            {%- set insert_query_name = 'main-' ~ i -%}\n            {% call statement(insert_query_name, fetch_result=True) -%}\n                INSERT INTO {{ target_relation }} ({{ target_cols_csv }})\n                (\n                    SELECT {{ target_cols_csv }}\n                    FROM {{ tmp_relation.include(schema=True) }}\n                );\n            {%- endcall %}\n\n            {% set result = load_result(insert_query_name) %}\n\n            {% if 'response' in result.keys() %} {# added in v0.19.0 #}\n                {% set rows_inserted = result['response']['rows_affected'] %}\n            {% else %} {# older versions #}\n                {% set rows_inserted = result['status'].split(\" \")[2] | int %}\n            {% endif %}\n\n            {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n            {%- do loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %}\n\n            {{ dbt_utils.log_info(\"Ran for {} {} of {}; {} records inserted [{}]\".format('rank', iteration_number,\n                                                                                          min_max_ranks.max_rank,\n                                                                                          rows_inserted,\n                                                                                          model.unique_id)) }}\n\n            {% if target.type == \"sqlserver\" %}\n                {# In MSSQL a temporary table can only be dropped by the connection or session that created it #}\n                {# so drop it now before the commit below closes this session #}\n                {%- set drop_query_name = 'DROP_QUERY-' ~ i -%}\n                {% call statement(drop_query_name, fetch_result=True) -%}\n                    DROP TABLE {{ tmp_relation }};\n                {%- endcall %}\n            {%  endif %}\n\n            {% do to_drop.append(tmp_relation) %}\n            {% do adapter.commit() %}\n\n        {% endfor %}\n        {% call noop_statement('main', \"INSERT {}\".format(loop_vars['sum_rows_inserted']) ) -%}\n            {{ filtered_sql }}\n        {%- endcall %}\n\n    {% endif %}\n\n    {% if build_sql is defined %}\n        {% call statement(\"main\", fetch_result=True) %}\n            {{ build_sql }}\n        {% endcall %}\n\n        {% set result = load_result('main') %}\n\n        {% if 'response' in result.keys() %} {# added in v0.19.0 #}\n            {% set rows_inserted = result['response']['rows_affected'] %}\n        {% else %} {# older versions #}\n            {% set rows_inserted = result['status'].split(\" \")[2] | int %}\n        {% endif %}\n\n        {% call noop_statement('main', \"BASE LOAD {}\".format(rows_inserted)) -%}\n            {{ build_sql }}\n        {%- endcall %}\n\n        -- `COMMIT` happens here\n        {% do adapter.commit() %}\n    {% endif %}\n\n    {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n    {% for rel in to_drop %}\n        {% if rel.type is not none %}\n            {% do adapter.drop_relation(rel) %}\n        {% endif %}\n    {% endfor %}\n\n    {% set target_relation = target_relation.incorporate(type='table') %}\n\n    {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n    {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.load_relation", "macro.dbt.make_temp_relation", "macro.dbtvault.escape_column_names", "macro.dbtvault.get_min_max_ranks", "macro.dbtvault.check_placeholder", "macro.dbt.run_hooks", "macro.dbtvault.replace_placeholder_with_rank_filter", "macro.dbt.create_table_as", "macro.dbt_utils.log_info", "macro.dbt.statement", "macro.dbt.noop_statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.006839}, "macro.dbtvault.materialization_bridge_incremental_default": {"unique_id": "macro.dbtvault.materialization_bridge_incremental_default", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/incremental_bridge_materialization.sql", "original_file_path": "macros/materialisations/incremental_bridge_materialization.sql", "name": "materialization_bridge_incremental_default", "macro_sql": "{%- materialization bridge_incremental, default -%}\n\n  {%- set full_refresh_mode = should_full_refresh() -%}\n\n  {% if target.type == \"sqlserver\" %}\n      {%- set target_relation = this.incorporate(type='table') -%}\n  {%  else %}\n      {%- set target_relation = this -%}\n  {% endif %}\n  {%- set existing_relation = load_relation(this) -%}\n  {%- set tmp_relation = make_temp_relation(target_relation) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {%- set to_drop = [] -%}\n  {%- if existing_relation is none -%}\n      {%- set build_sql = create_table_as(False, target_relation, sql) -%}\n  {%- elif existing_relation.is_view or full_refresh_mode -%}\n      {#-- Make sure the backup doesn't exist so we don't encounter issues with the rename below #}\n      {%- set backup_identifier = existing_relation.identifier ~ \"__dbt_backup\" -%}\n      {%- set backup_relation = existing_relation.incorporate(path={\"identifier\": backup_identifier}) -%}\n      {%- do adapter.drop_relation(backup_relation) -%}\n\n      {%- do adapter.rename_relation(target_relation, backup_relation) -%}\n      {%- set build_sql = create_table_as(False, target_relation, sql) -%}\n      {%- do to_drop.append(backup_relation) -%}\n  {%- else -%}\n\n      {%- set tmp_relation = make_temp_relation(target_relation) -%}\n      {%- do run_query(create_table_as(True, tmp_relation, sql)) -%}\n      {%- do adapter.expand_target_column_types(\n             from_relation=tmp_relation,\n             to_relation=target_relation) -%}\n      {%- set build_sql = dbtvault.incremental_bridge_replace(tmp_relation, target_relation) -%}\n{%- endif -%}\n\n  {%- call statement(\"main\") -%}\n      {{ build_sql }}\n  {%- endcall -%}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {%- do adapter.commit() -%}\n\n  {%- for rel in to_drop -%}\n      {%- do adapter.drop_relation(rel) -%}\n  {%- endfor -%}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.load_relation", "macro.dbt.make_temp_relation", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt.run_query", "macro.dbtvault.incremental_bridge_replace", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.012057}, "macro.dbtvault.check_placeholder": {"unique_id": "macro.dbtvault.check_placeholder", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/shared_helpers.sql", "original_file_path": "macros/materialisations/shared_helpers.sql", "name": "check_placeholder", "macro_sql": "{%- macro check_placeholder(model_sql, placeholder='__PERIOD_FILTER__') -%}\n\n    {%- if model_sql.find(placeholder) == -1 -%}\n    {%- set error_message -%}\n    Model '{{ model.unique_id }}' does not include the required string '{{ placeholder }}' in its sql\n        {%- endset -%}\n        {{- exceptions.raise_compiler_error(error_message) -}}\n    {%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.013089}, "macro.dbtvault.materialization_vault_insert_by_period_default": {"unique_id": "macro.dbtvault.materialization_vault_insert_by_period_default", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/vault_insert_by_period_materialization.sql", "original_file_path": "macros/materialisations/vault_insert_by_period_materialization.sql", "name": "materialization_vault_insert_by_period_default", "macro_sql": "{% materialization vault_insert_by_period, default -%}\n\n    {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n    {% if target.type == \"sqlserver\" %}\n        {%- set target_relation = this.incorporate(type='table') -%}\n    {%  else %}\n        {%- set target_relation = this -%}\n    {% endif %}\n    {%- set existing_relation = load_relation(this) -%}\n    {%- set tmp_relation = make_temp_relation(target_relation) -%}\n\n    {%- set timestamp_field = dbtvault.escape_column_names(config.require('timestamp_field')) -%}\n    {%- set date_source_models = config.get('date_source_models', default=none) -%}\n\n    {%- set start_stop_dates = dbtvault.get_start_stop_dates(timestamp_field, date_source_models) | as_native -%}\n\n    {%- set period = config.get('period', default='day') -%}\n    {%- set to_drop = [] -%}\n\n    {%- do dbtvault.check_placeholder(sql) -%}\n\n    {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n    -- `BEGIN` happens here:\n    {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n    {% if existing_relation is none %}\n\n        {% set filtered_sql = dbtvault.replace_placeholder_with_period_filter(sql, timestamp_field,\n                                                                       start_stop_dates.start_date,\n                                                                       start_stop_dates.stop_date,\n                                                                       0, period) %}\n        {% set build_sql = create_table_as(False, target_relation, filtered_sql) %}\n        {% do to_drop.append(tmp_relation) %}\n\n    {% elif existing_relation.is_view %}\n\n        {{ log(\"Dropping relation \" ~ target_relation ~ \" because it is a view and this model is a table (vault_insert_by_period).\") }}\n        {% do adapter.drop_relation(existing_relation) %}\n        {% set build_sql = create_table_as(False, target_relation, filtered_sql) %}\n\n        {% set filtered_sql = dbtvault.replace_placeholder_with_period_filter(sql, timestamp_field,\n                                                                       start_stop_dates.start_date,\n                                                                       start_stop_dates.stop_date,\n                                                                       0, period) %}\n        {% set build_sql = create_table_as(False, target_relation, filtered_sql) %}\n\n    {% elif full_refresh_mode %}\n        {% set filtered_sql = dbtvault.replace_placeholder_with_period_filter(sql, timestamp_field,\n                                                                       start_stop_dates.start_date,\n                                                                       start_stop_dates.stop_date,\n                                                                       0, period) %}\n        {% set build_sql = create_table_as(False, target_relation, filtered_sql) %}\n    {% else %}\n\n        {% set period_boundaries = dbtvault.get_period_boundaries(schema,\n                                                                  target_relation.name,\n                                                                  timestamp_field,\n                                                                  start_stop_dates.start_date,\n                                                                  start_stop_dates.stop_date,\n                                                                  period) %}\n\n        {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\n        {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\n        {%- set loop_vars = {'sum_rows_inserted': 0} -%}\n\n        {% for i in range(period_boundaries.num_periods) -%}\n\n            {%- set iteration_number = i + 1 -%}\n            {%- set period_of_load = dbtvault.get_period_of_load(period, i, period_boundaries.start_timestamp) -%}\n\n            {{ dbt_utils.log_info(\"Running for {} {} of {} ({}) [{}]\".format(period, iteration_number, period_boundaries.num_periods, period_of_load, model.unique_id)) }}\n\n            {% set tmp_relation = make_temp_relation(target_relation) %}\n\n            {% set tmp_table_sql = dbtvault.get_period_filter_sql(target_cols_csv, sql, timestamp_field, period,\n                                                                  period_boundaries.start_timestamp,\n                                                                  period_boundaries.stop_timestamp, i) %}\n\n            {# This call statement drops and then creates a temporary table #}\n            {# but MSSQL will fail to drop any temporary table created by a previous loop iteration #}\n            {# See MSSQL note and drop code below #}\n            {% call statement() -%}\n                {{ create_table_as(True, tmp_relation, tmp_table_sql) }}\n            {%- endcall %}\n\n            {{ adapter.expand_target_column_types(from_relation=tmp_relation,\n                                                  to_relation=target_relation) }}\n\n            {%- set insert_query_name = 'main-' ~ i -%}\n            {% call statement(insert_query_name, fetch_result=True) -%}\n                INSERT INTO {{ target_relation }} ({{ target_cols_csv }})\n                (\n                    SELECT {{ target_cols_csv }}\n                    FROM {{ tmp_relation.include(schema=True) }}\n                );\n            {%- endcall %}\n\n            {% set result = load_result(insert_query_name) %}\n\n            {% if 'response' in result.keys() %} {# added in v0.19.0 #}\n                {% set rows_inserted = result['response']['rows_affected'] %}\n            {% else %} {# older versions #}\n                {% set rows_inserted = result['status'].split(\" \")[2] | int %}\n            {% endif %}\n\n            {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\n            {%- do loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %}\n\n            {{ dbt_utils.log_info(\"Ran for {} {} of {} ({}); {} records inserted [{}]\".format(period, iteration_number,\n                                                                                              period_boundaries.num_periods,\n                                                                                              period_of_load, rows_inserted,\n                                                                                              model.unique_id)) }}\n\n            {% if target.type == \"sqlserver\" %}\n                {# In MSSQL a temporary table can only be dropped by the connection or session that created it #}\n                {# so drop it now before the commit below closes this session #}\n                {%- set drop_query_name = 'DROP_QUERY-' ~ i -%}\n                {% call statement(drop_query_name, fetch_result=True) -%}\n                    DROP TABLE {{ tmp_relation }};\n                {%- endcall %}\n            {%  endif %}\n\n            {% do to_drop.append(tmp_relation) %}\n            {% do adapter.commit() %}\n\n        {% endfor %}\n\n        {% call noop_statement('main', \"INSERT {}\".format(loop_vars['sum_rows_inserted']) ) -%}\n            {{ tmp_table_sql }}\n        {%- endcall %}\n\n    {% endif %}\n\n    {% if build_sql is defined %}\n        {% call statement(\"main\", fetch_result=True) %}\n            {{ build_sql }}\n        {% endcall %}\n\n        {% set result = load_result('main') %}\n\n        {% if 'response' in result.keys() %} {# added in v0.19.0 #}\n            {% set rows_inserted = result['response']['rows_affected'] %}\n        {% else %} {# older versions #}\n            {% set rows_inserted = result['status'].split(\" \")[2] | int %}\n        {% endif %}\n\n        {% call noop_statement('main', \"BASE LOAD {}\".format(rows_inserted)) -%}\n            {{ build_sql }}\n        {%- endcall %}\n\n        -- `COMMIT` happens here\n        {% do adapter.commit() %}\n    {% endif %}\n\n    {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n    {% for rel in to_drop %}\n        {% if rel.type is not none %}\n            {% do adapter.drop_relation(rel) %}\n        {% endif %}\n    {% endfor %}\n\n    {% set target_relation = target_relation.incorporate(type='table') %}\n\n    {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n    {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.load_relation", "macro.dbt.make_temp_relation", "macro.dbtvault.escape_column_names", "macro.dbtvault.get_start_stop_dates", "macro.dbtvault.check_placeholder", "macro.dbt.run_hooks", "macro.dbtvault.replace_placeholder_with_period_filter", "macro.dbt.create_table_as", "macro.dbtvault.get_period_boundaries", "macro.dbtvault.get_period_of_load", "macro.dbt_utils.log_info", "macro.dbtvault.get_period_filter_sql", "macro.dbt.statement", "macro.dbt.noop_statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.037214}, "macro.dbtvault.incremental_pit_replace": {"unique_id": "macro.dbtvault.incremental_pit_replace", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/incremental_pit_bridge_replace.sql", "original_file_path": "macros/materialisations/incremental_pit_bridge_replace.sql", "name": "incremental_pit_replace", "macro_sql": "{% macro incremental_pit_replace(tmp_relation, target_relation, statement_name=\"main\") %}\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n\n    TRUNCATE TABLE {{ target_relation }};\n\n    INSERT INTO {{ target_relation }} ({{ dest_cols_csv }})\n    (\n       SELECT {{ dest_cols_csv }}\n       FROM {{ tmp_relation }}\n    );\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.038686}, "macro.dbtvault.incremental_bridge_replace": {"unique_id": "macro.dbtvault.incremental_bridge_replace", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/incremental_pit_bridge_replace.sql", "original_file_path": "macros/materialisations/incremental_pit_bridge_replace.sql", "name": "incremental_bridge_replace", "macro_sql": "{% macro incremental_bridge_replace(tmp_relation, target_relation, statement_name=\"main\") %}\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n\n    TRUNCATE TABLE {{ target_relation }};\n\n    INSERT INTO {{ target_relation }} ({{ dest_cols_csv }})\n    (\n       SELECT {{ dest_cols_csv }}\n       FROM {{ tmp_relation }}\n    );\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.039474}, "macro.dbtvault.materialization_pit_incremental_default": {"unique_id": "macro.dbtvault.materialization_pit_incremental_default", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/incremental_pit_materialization.sql", "original_file_path": "macros/materialisations/incremental_pit_materialization.sql", "name": "materialization_pit_incremental_default", "macro_sql": "{%- materialization pit_incremental, default -%}\n\n  {%- set full_refresh_mode = should_full_refresh() -%}\n\n  {% if target.type == \"sqlserver\" %}\n      {%- set target_relation = this.incorporate(type='table') -%}\n  {%  else %}\n      {%- set target_relation = this -%}\n  {% endif %}\n  {%- set existing_relation = load_relation(this) -%}\n  {%- set tmp_relation = make_temp_relation(target_relation) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {%- set to_drop = [] -%}\n  {%- if existing_relation is none -%}\n      {%- set build_sql = create_table_as(False, target_relation, sql) -%}\n  {%- elif existing_relation.is_view or full_refresh_mode -%}\n      {#-- Make sure the backup doesn't exist so we don't encounter issues with the rename below #}\n      {%- set backup_identifier = existing_relation.identifier ~ \"__dbt_backup\" -%}\n      {%- set backup_relation = existing_relation.incorporate(path={\"identifier\": backup_identifier}) -%}\n      {%- do adapter.drop_relation(backup_relation) -%}\n\n      {%- do adapter.rename_relation(target_relation, backup_relation) -%}\n      {%- set build_sql = create_table_as(False, target_relation, sql) -%}\n      {%- do to_drop.append(backup_relation) -%}\n  {%- else -%}\n\n      {%- set tmp_relation = make_temp_relation(target_relation) -%}\n      {%- do run_query(create_table_as(True, tmp_relation, sql)) -%}\n      {%- do adapter.expand_target_column_types(\n             from_relation=tmp_relation,\n             to_relation=target_relation) -%}\n      {%- set build_sql = dbtvault.incremental_pit_replace(tmp_relation, target_relation) -%}\n{%- endif -%}\n\n  {%- call statement(\"main\") -%}\n      {{ build_sql }}\n  {%- endcall -%}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {%- do adapter.commit() -%}\n\n  {%- for rel in to_drop -%}\n      {%- do adapter.drop_relation(rel) -%}\n  {%- endfor -%}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.should_full_refresh", "macro.dbt.load_relation", "macro.dbt.make_temp_relation", "macro.dbt.run_hooks", "macro.dbt.create_table_as", "macro.dbt.run_query", "macro.dbtvault.incremental_pit_replace", "macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.0444129}, "macro.dbtvault.is_any_incremental": {"unique_id": "macro.dbtvault.is_any_incremental", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/mat_is_checks.sql", "original_file_path": "macros/materialisations/mat_is_checks.sql", "name": "is_any_incremental", "macro_sql": "{%- macro is_any_incremental() -%}\n    {%- if dbtvault.is_vault_insert_by_period() or dbtvault.is_vault_insert_by_rank() or dbtvault.is_pit_incremental() or dbtvault.is_bridge_incremental() or is_incremental() -%}\n        {%- do return(true) -%}\n    {%- else -%}\n        {%- do return(false) -%}\n    {%- endif -%}\n{%- endmacro -%}\n\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.is_vault_insert_by_period", "macro.dbtvault.is_vault_insert_by_rank", "macro.dbtvault.is_pit_incremental", "macro.dbtvault.is_bridge_incremental", "macro.dbt.is_incremental"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.0464141}, "macro.dbtvault.is_vault_insert_by_period": {"unique_id": "macro.dbtvault.is_vault_insert_by_period", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/mat_is_checks.sql", "original_file_path": "macros/materialisations/mat_is_checks.sql", "name": "is_vault_insert_by_period", "macro_sql": "{% macro is_vault_insert_by_period() %}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n\n            {{ return(relation is not none\n                      and relation.type == 'table'\n                      and model.config.materialized == 'vault_insert_by_period'\n                      and not flags.FULL_REFRESH) }}\n    {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.047376}, "macro.dbtvault.is_vault_insert_by_rank": {"unique_id": "macro.dbtvault.is_vault_insert_by_rank", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/mat_is_checks.sql", "original_file_path": "macros/materialisations/mat_is_checks.sql", "name": "is_vault_insert_by_rank", "macro_sql": "{% macro is_vault_insert_by_rank() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n\n            {{ return(relation is not none\n                      and relation.type == 'table'\n                      and model.config.materialized == 'vault_insert_by_rank'\n                      and not flags.FULL_REFRESH) }}\n    {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.04843}, "macro.dbtvault.is_bridge_incremental": {"unique_id": "macro.dbtvault.is_bridge_incremental", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/mat_is_checks.sql", "original_file_path": "macros/materialisations/mat_is_checks.sql", "name": "is_bridge_incremental", "macro_sql": "{% macro is_bridge_incremental() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n\n            {{ return(relation is not none\n                      and relation.type == 'table'\n                      and model.config.materialized == 'bridge_incremental'\n                      and not flags.FULL_REFRESH) }}\n    {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.0494}, "macro.dbtvault.is_pit_incremental": {"unique_id": "macro.dbtvault.is_pit_incremental", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/mat_is_checks.sql", "original_file_path": "macros/materialisations/mat_is_checks.sql", "name": "is_pit_incremental", "macro_sql": "{% macro is_pit_incremental() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n\n            {{ return(relation is not none\n                      and relation.type == 'table'\n                      and model.config.materialized == 'pit_incremental'\n                      and not flags.FULL_REFRESH) }}\n    {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.0503738}, "macro.dbtvault.get_min_max_ranks": {"unique_id": "macro.dbtvault.get_min_max_ranks", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/rank_mat_helpers/get_min_max_ranks.sql", "original_file_path": "macros/materialisations/rank_mat_helpers/get_min_max_ranks.sql", "name": "get_min_max_ranks", "macro_sql": "{% macro get_min_max_ranks(rank_column, rank_source_models) %}\n\n    {% if rank_source_models is not none %}\n\n        {% if rank_source_models is string %}\n            {% set rank_source_models = [rank_source_models] %}\n        {% endif %}\n\n        {% set query_sql %}\n            WITH stage AS (\n            {% for source_model in rank_source_models %}\n                SELECT {{ rank_column }} FROM {{ ref(source_model) }}\n                {% if not loop.last %} UNION ALL {% endif %}\n            {% endfor %})\n\n            SELECT MIN({{ rank_column }}) AS MIN, MAX({{ rank_column }}) AS MAX\n            FROM stage\n        {% endset %}\n\n        {% set min_max_dict = dbtvault.get_query_results_as_dict(query_sql) %}\n\n        {% set min_rank = min_max_dict['MIN'][0] | string %}\n        {% set max_rank = min_max_dict['MAX'][0] | string %}\n        {% set min_max_ranks = {\"min_rank\": min_rank, \"max_rank\": max_rank} %}\n\n        {% do return(min_max_ranks) %}\n\n    {% else %}\n        {%- if execute -%}\n            {{ exceptions.raise_compiler_error(\"Invalid 'vault_insert_by_rank' configuration. Must provide 'rank_column', and 'rank_source_models' options.\") }}\n        {%- endif -%}\n    {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.get_query_results_as_dict"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.0535989}, "macro.dbtvault.replace_placeholder_with_rank_filter": {"unique_id": "macro.dbtvault.replace_placeholder_with_rank_filter", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/rank_mat_helpers/replace_placeholder_with_rank_filter.sql", "original_file_path": "macros/materialisations/rank_mat_helpers/replace_placeholder_with_rank_filter.sql", "name": "replace_placeholder_with_rank_filter", "macro_sql": "{%- macro replace_placeholder_with_rank_filter(core_sql, rank_column, rank_iteration) -%}\n\n    {% set macro = adapter.dispatch('replace_placeholder_with_rank_filter',\n                                    'dbtvault')(core_sql=core_sql,\n                                                rank_column=rank_column,\n                                                rank_iteration=rank_iteration) %}\n    {% do return(macro) %}\n    {%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__replace_placeholder_with_rank_filter"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.055344}, "macro.dbtvault.default__replace_placeholder_with_rank_filter": {"unique_id": "macro.dbtvault.default__replace_placeholder_with_rank_filter", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/rank_mat_helpers/replace_placeholder_with_rank_filter.sql", "original_file_path": "macros/materialisations/rank_mat_helpers/replace_placeholder_with_rank_filter.sql", "name": "default__replace_placeholder_with_rank_filter", "macro_sql": "{% macro default__replace_placeholder_with_rank_filter(core_sql, rank_column, rank_iteration) %}\n\n    {%- set rank_filter -%}\n    {{ rank_column }}:: INTEGER = {{ rank_iteration }}::INTEGER\n    {%- endset -%}\n\n    {%- set filtered_sql = core_sql | replace(\"__RANK_FILTER__\", rank_filter) -%}\n\n    {% do return(filtered_sql) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.05601}, "macro.dbtvault.sqlserver__replace_placeholder_with_rank_filter": {"unique_id": "macro.dbtvault.sqlserver__replace_placeholder_with_rank_filter", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/rank_mat_helpers/replace_placeholder_with_rank_filter.sql", "original_file_path": "macros/materialisations/rank_mat_helpers/replace_placeholder_with_rank_filter.sql", "name": "sqlserver__replace_placeholder_with_rank_filter", "macro_sql": "{% macro sqlserver__replace_placeholder_with_rank_filter(core_sql, rank_column, rank_iteration) %}\n\n    {%- set rank_filter -%}\n        CAST({{ rank_column }} AS INT) = CAST({{ rank_iteration }} AS INT)\n    {%- endset -%}\n\n    {%- set filtered_sql = core_sql | replace(\"__RANK_FILTER__\", rank_filter) -%}\n\n    {% do return(filtered_sql) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.056654}, "macro.dbtvault.bigquery__replace_placeholder_with_rank_filter": {"unique_id": "macro.dbtvault.bigquery__replace_placeholder_with_rank_filter", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/rank_mat_helpers/replace_placeholder_with_rank_filter.sql", "original_file_path": "macros/materialisations/rank_mat_helpers/replace_placeholder_with_rank_filter.sql", "name": "bigquery__replace_placeholder_with_rank_filter", "macro_sql": "{% macro bigquery__replace_placeholder_with_rank_filter(core_sql, rank_column, rank_iteration) %}\n    {%- set rank_filter -%}\n        CAST({{ rank_column }} AS INTEGER) = CAST({{ rank_iteration }} AS INTEGER)\n    {%- endset -%}\n\n    {%- set filtered_sql = core_sql | replace(\"__RANK_FILTER__\", rank_filter) -%}\n\n    {% do return(filtered_sql) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.057293}, "macro.dbtvault.replace_placeholder_with_period_filter": {"unique_id": "macro.dbtvault.replace_placeholder_with_period_filter", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/replace_placeholder_with_period_filter.sql", "original_file_path": "macros/materialisations/period_mat_helpers/replace_placeholder_with_period_filter.sql", "name": "replace_placeholder_with_period_filter", "macro_sql": "{%- macro replace_placeholder_with_period_filter(core_sql, timestamp_field, start_timestamp, stop_timestamp, offset, period) -%}\n\n    {% set macro = adapter.dispatch('replace_placeholder_with_period_filter',\n                                    'dbtvault')(core_sql=core_sql,\n                                                timestamp_field=timestamp_field,\n                                                start_timestamp=start_timestamp,\n                                                stop_timestamp=stop_timestamp,\n                                                offset=offset,\n                                                period=period) %}\n    {% do return(macro) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__replace_placeholder_with_period_filter"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.060544}, "macro.dbtvault.default__replace_placeholder_with_period_filter": {"unique_id": "macro.dbtvault.default__replace_placeholder_with_period_filter", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/replace_placeholder_with_period_filter.sql", "original_file_path": "macros/materialisations/period_mat_helpers/replace_placeholder_with_period_filter.sql", "name": "default__replace_placeholder_with_period_filter", "macro_sql": "{% macro default__replace_placeholder_with_period_filter(core_sql, timestamp_field, start_timestamp, stop_timestamp, offset, period) %}\n\n    {%- set period_filter -%}\n        (TO_DATE({{ timestamp_field }})\n        >= DATE_TRUNC('{{ period }}', TO_DATE('{{ start_timestamp }}') + INTERVAL '{{ offset }} {{ period }}') AND\n             TO_DATE({{ timestamp_field }}) < DATE_TRUNC('{{ period }}', TO_DATE('{{ start_timestamp }}') + INTERVAL '{{ offset }} {{ period }}' + INTERVAL '1 {{ period }}'))\n      AND (TO_DATE({{ timestamp_field }}) >= TO_DATE('{{ start_timestamp }}'))\n    {%- endset -%}\n    {%- set filtered_sql = core_sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n    {% do return(filtered_sql) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.06168}, "macro.dbtvault.bigquery__replace_placeholder_with_period_filter": {"unique_id": "macro.dbtvault.bigquery__replace_placeholder_with_period_filter", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/replace_placeholder_with_period_filter.sql", "original_file_path": "macros/materialisations/period_mat_helpers/replace_placeholder_with_period_filter.sql", "name": "bigquery__replace_placeholder_with_period_filter", "macro_sql": "{% macro bigquery__replace_placeholder_with_period_filter(core_sql, timestamp_field, start_timestamp, stop_timestamp, offset, period) %}\n\n    {%- set period_filter -%}\n            (DATE({{ timestamp_field }}) >= DATE_TRUNC(DATE_ADD( DATE('{{ start_timestamp }}'), INTERVAL {{ offset }} {{ period }}), {{ period }} ) AND\n             DATE({{ timestamp_field }}) < DATE_TRUNC(DATE_ADD(DATE_ADD( DATE('{{ start_timestamp }}'), INTERVAL {{ offset }} {{ period }}), INTERVAL 1 {{ period }}), {{ period }} )\n      AND DATE({{ timestamp_field }}) >= DATE('{{ start_timestamp }}'))\n    {%- endset -%}\n\n    {%- set filtered_sql = core_sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n    {% do return(filtered_sql) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.062997}, "macro.dbtvault.sqlserver__replace_placeholder_with_period_filter": {"unique_id": "macro.dbtvault.sqlserver__replace_placeholder_with_period_filter", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/replace_placeholder_with_period_filter.sql", "original_file_path": "macros/materialisations/period_mat_helpers/replace_placeholder_with_period_filter.sql", "name": "sqlserver__replace_placeholder_with_period_filter", "macro_sql": "{% macro sqlserver__replace_placeholder_with_period_filter(core_sql, timestamp_field, start_timestamp, stop_timestamp, offset, period) %}\n\n    {#  MSSQL cannot CAST datetime2 strings with more than 7 decimal places #}\n    {% set start_timestamp_mssql = start_timestamp[0:27] %}\n\n    {%- set period_filter -%}\n            (CAST({{ timestamp_field }} AS DATE) >= DATEADD({{ period }}, DATEDIFF({{ period }}, 0, DATEADD({{ period }}, {{ offset }}, CAST('{{ start_timestamp_mssql }}' AS DATETIME2))), 0) AND\n             CAST({{ timestamp_field }} AS DATE) < DATEADD({{ period }}, 1, DATEADD({{ period }}, {{ offset }}, CAST('{{ start_timestamp_mssql }}' AS DATETIME2)))\n      AND (CAST({{ timestamp_field }} AS DATE) >= CAST('{{ start_timestamp_mssql }}' AS DATE)))\n    {%- endset -%}\n\n    {%- set filtered_sql = core_sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\n\n    {% do return(filtered_sql) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.064301}, "macro.dbtvault.get_period_boundaries": {"unique_id": "macro.dbtvault.get_period_boundaries", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/get_period_boundaries.sql", "original_file_path": "macros/materialisations/period_mat_helpers/get_period_boundaries.sql", "name": "get_period_boundaries", "macro_sql": "{%- macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n    {% set macro = adapter.dispatch('get_period_boundaries',\n                                    'dbtvault')(target_schema=target_schema,\n                                                target_table=target_table,\n                                                timestamp_field=timestamp_field,\n                                                start_date=start_date,\n                                                stop_date=stop_date,\n                                                period=period) %}\n\n    {% do return(macro) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__get_period_boundaries"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.069398}, "macro.dbtvault.default__get_period_boundaries": {"unique_id": "macro.dbtvault.default__get_period_boundaries", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/get_period_boundaries.sql", "original_file_path": "macros/materialisations/period_mat_helpers/get_period_boundaries.sql", "name": "default__get_period_boundaries", "macro_sql": "{% macro default__get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n    {% set period_boundary_sql -%}\n        WITH period_data AS (\n            SELECT\n                COALESCE(MAX({{ timestamp_field }}), '{{ start_date }}')::TIMESTAMP AS start_timestamp,\n                COALESCE({{ dbt_utils.dateadd('millisecond', 86399999, \"NULLIF('\" ~ stop_date | lower ~ \"','none')::TIMESTAMP\") }},\n                         {{ dbtvault.current_timestamp() }} ) AS stop_timestamp\n            FROM {{ target_schema }}.{{ target_table }}\n        )\n        SELECT\n            start_timestamp,\n            stop_timestamp,\n            {{ dbt_utils.datediff('start_timestamp',\n                                  'stop_timestamp',\n                                  period) }} + 1 AS num_periods\n        FROM period_data\n    {%- endset %}\n\n    {% set period_boundaries_dict = dbtvault.get_query_results_as_dict(period_boundary_sql) %}\n\n    {% set period_boundaries = {'start_timestamp': period_boundaries_dict['START_TIMESTAMP'][0] | string,\n                                'stop_timestamp': period_boundaries_dict['STOP_TIMESTAMP'][0] | string,\n                                'num_periods': period_boundaries_dict['NUM_PERIODS'][0] | int} %}\n\n    {% do return(period_boundaries) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbtvault.current_timestamp", "macro.dbt_utils.datediff", "macro.dbtvault.get_query_results_as_dict"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.071151}, "macro.dbtvault.bigquery__get_period_boundaries": {"unique_id": "macro.dbtvault.bigquery__get_period_boundaries", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/get_period_boundaries.sql", "original_file_path": "macros/materialisations/period_mat_helpers/get_period_boundaries.sql", "name": "bigquery__get_period_boundaries", "macro_sql": "{% macro bigquery__get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n    {% set period_boundary_sql -%}\n        with data as (\n            select\n                coalesce(CAST(max({{ timestamp_field }}) AS DATETIME), CAST('{{ start_date }}' AS DATETIME)) as START_TIMESTAMP,\n                coalesce({{ dbt_utils.dateadd('millisecond', 86399999, \"nullif('\" ~ stop_date | lower ~ \"','none')\") }},\n                         CAST(CURRENT_TIMESTAMP() AS DATETIME) ) as STOP_TIMESTAMP\n            from {{ target_schema }}.{{ target_table }}\n        )\n        select\n            START_TIMESTAMP,\n            STOP_TIMESTAMP,\n            {{ dbt_utils.datediff('start_timestamp',\n                                  'stop_timestamp',\n                                  period) }} + 1 as NUM_PERIODS\n        from data\n    {%- endset %}\n\n\n    {% set period_boundaries_dict = dbtvault.get_query_results_as_dict(period_boundary_sql) %}\n\n    {% set period_boundaries = {'start_timestamp': period_boundaries_dict['START_TIMESTAMP'][0] | string,\n                                'stop_timestamp': period_boundaries_dict['STOP_TIMESTAMP'][0] | string,\n                                'num_periods': period_boundaries_dict['NUM_PERIODS'][0] | int} %}\n\n    {% do return(period_boundaries) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbt_utils.datediff", "macro.dbtvault.get_query_results_as_dict"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.07284}, "macro.dbtvault.sqlserver__get_period_boundaries": {"unique_id": "macro.dbtvault.sqlserver__get_period_boundaries", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/get_period_boundaries.sql", "original_file_path": "macros/materialisations/period_mat_helpers/get_period_boundaries.sql", "name": "sqlserver__get_period_boundaries", "macro_sql": "{% macro sqlserver__get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\n\n    {#  MSSQL cannot CAST datetime2 strings with more than 7 decimal places #}\n    {% set start_date_mssql = start_date[0:27] %}\n    {% set stop_date_mssql  = stop_date[0:27] %}\n\n    {% set period_boundary_sql -%}\n        WITH period_data AS (\n            SELECT\n                CAST(COALESCE(MAX({{ timestamp_field }}), CAST('{{ start_date_mssql }}' AS DATETIME2)) AS DATETIME2) AS start_timestamp,\n                COALESCE({{ dbt_utils.dateadd('millisecond', 86399999, \"CAST(NULLIF('\" ~ stop_date_mssql | lower ~ \"','none') AS DATETIME2)\") }},\n                         {{ dbtvault.current_timestamp() }} ) AS stop_timestamp\n            FROM {{ target_schema }}.{{ target_table }}\n        )\n        SELECT\n            start_timestamp,\n            stop_timestamp,\n            {{ dbt_utils.datediff('start_timestamp',\n                                  'stop_timestamp',\n                                  period) }} + 1 AS num_periods\n        FROM period_data\n    {%- endset %}\n\n    {% set period_boundaries_dict = dbtvault.get_query_results_as_dict(period_boundary_sql) %}\n\n    {% set period_boundaries = {'start_timestamp': period_boundaries_dict['START_TIMESTAMP'][0] | string,\n                                'stop_timestamp': period_boundaries_dict['STOP_TIMESTAMP'][0] | string,\n                                'num_periods': period_boundaries_dict['NUM_PERIODS'][0] | int} %}\n\n    {% do return(period_boundaries) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.dateadd", "macro.dbtvault.current_timestamp", "macro.dbt_utils.datediff", "macro.dbtvault.get_query_results_as_dict"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.0749152}, "macro.dbtvault.get_start_stop_dates": {"unique_id": "macro.dbtvault.get_start_stop_dates", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/get_start_stop_dates.sql", "original_file_path": "macros/materialisations/period_mat_helpers/get_start_stop_dates.sql", "name": "get_start_stop_dates", "macro_sql": "{% macro get_start_stop_dates(timestamp_field, date_source_models) %}\n\n    {% if config.get('start_date', default=none) is not none %}\n\n        {%- set start_date = config.get('start_date') -%}\n        {%- set stop_date = config.get('stop_date', default=none) -%}\n\n        {% do return({'start_date': start_date,'stop_date': stop_date}) %}\n\n    {% elif date_source_models is not none %}\n\n        {% if date_source_models is string %}\n            {% set date_source_models = [date_source_models] %}\n        {% endif %}\n        {% set query_sql %}\n            WITH stage AS (\n            {% for source_model in date_source_models %}\n                SELECT {{ timestamp_field }} FROM {{ ref(source_model) }}\n                {% if not loop.last %} UNION ALL {% endif %}\n            {% endfor %})\n\n            SELECT MIN({{ timestamp_field }}) AS MIN, MAX({{ timestamp_field }}) AS MAX\n            FROM stage\n        {% endset %}\n\n        {% set min_max_dict = dbtvault.get_query_results_as_dict(query_sql) %}\n\n        {% set start_date = min_max_dict['MIN'][0] | string %}\n        {% set stop_date = min_max_dict['MAX'][0] | string %}\n        {% set min_max_dates = {\"start_date\": start_date, \"stop_date\": stop_date} %}\n\n        {% do return(min_max_dates) %}\n\n    {% else %}\n        {%- if execute -%}\n            {{ exceptions.raise_compiler_error(\"Invalid 'vault_insert_by_period' configuration. Must provide 'start_date' and 'stop_date', just 'stop_date', and/or 'date_source_models' options.\") }}\n        {%- endif -%}\n    {% endif %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.get_query_results_as_dict"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.079097}, "macro.dbtvault.get_period_filter_sql": {"unique_id": "macro.dbtvault.get_period_filter_sql", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/get_period_filter_sql.sql", "original_file_path": "macros/materialisations/period_mat_helpers/get_period_filter_sql.sql", "name": "get_period_filter_sql", "macro_sql": "{%- macro get_period_filter_sql(target_cols_csv, base_sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n    {% set macro = adapter.dispatch('get_period_filter_sql',\n                                    'dbtvault')(target_cols_csv=target_cols_csv,\n                                                base_sql=base_sql,\n                                                timestamp_field=timestamp_field,\n                                                period=period,\n                                                start_timestamp=start_timestamp,\n                                                stop_timestamp=stop_timestamp,\n                                                offset=offset) %}\n    {% do return(macro) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__get_period_filter_sql"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.082467}, "macro.dbtvault.default__get_period_filter_sql": {"unique_id": "macro.dbtvault.default__get_period_filter_sql", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/get_period_filter_sql.sql", "original_file_path": "macros/materialisations/period_mat_helpers/get_period_filter_sql.sql", "name": "default__get_period_filter_sql", "macro_sql": "{% macro default__get_period_filter_sql(target_cols_csv, base_sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n    {%- set filtered_sql = {'sql': base_sql} -%}\n\n    {%- do filtered_sql.update({'sql': dbtvault.replace_placeholder_with_period_filter(filtered_sql.sql,\n                                                                                       timestamp_field,\n                                                                                       start_timestamp,\n                                                                                       stop_timestamp,\n                                                                                       offset, period)}) -%}\n    select {{ target_cols_csv }} from ({{ filtered_sql.sql }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.replace_placeholder_with_period_filter"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.0833569}, "macro.dbtvault.sqlserver__get_period_filter_sql": {"unique_id": "macro.dbtvault.sqlserver__get_period_filter_sql", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/get_period_filter_sql.sql", "original_file_path": "macros/materialisations/period_mat_helpers/get_period_filter_sql.sql", "name": "sqlserver__get_period_filter_sql", "macro_sql": "{% macro sqlserver__get_period_filter_sql(target_cols_csv, base_sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\n\n    {%- set filtered_sql = {'sql': base_sql} -%}\n\n    {%- do filtered_sql.update({'sql': dbtvault.replace_placeholder_with_period_filter(filtered_sql.sql,\n                                                                                       timestamp_field,\n                                                                                       start_timestamp,\n                                                                                       stop_timestamp,\n                                                                                       offset, period)}) -%}\n    {# MSSQL does not allow CTEs in a subquery #}\n    {{ filtered_sql.sql }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.replace_placeholder_with_period_filter"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.084212}, "macro.dbtvault.get_period_of_load": {"unique_id": "macro.dbtvault.get_period_of_load", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/get_period_of_load.sql", "original_file_path": "macros/materialisations/period_mat_helpers/get_period_of_load.sql", "name": "get_period_of_load", "macro_sql": "{%- macro get_period_of_load(period, offset, start_timestamp) -%}\n\n    {% set macro = adapter.dispatch('get_period_of_load',\n                                    'dbtvault')(period=period,\n                                                offset=offset,\n                                                start_timestamp=start_timestamp) %}\n\n    {% do return(macro) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__get_period_of_load"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.086092}, "macro.dbtvault.default__get_period_of_load": {"unique_id": "macro.dbtvault.default__get_period_of_load", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/get_period_of_load.sql", "original_file_path": "macros/materialisations/period_mat_helpers/get_period_of_load.sql", "name": "default__get_period_of_load", "macro_sql": "\n\n\n\n\n{%- macro default__get_period_of_load(period, offset, start_timestamp) -%}\n\n    {% set period_of_load_sql -%}\n        SELECT DATE_TRUNC('{{ period }}', DATEADD({{ period }}, {{ offset }}, TO_DATE('{{ start_timestamp }}'))) AS period_of_load\n    {%- endset %}\n\n    {% set period_of_load_dict = dbtvault.get_query_results_as_dict(period_of_load_sql) %}\n\n    {% set period_of_load = period_of_load_dict['PERIOD_OF_LOAD'][0] | string %}\n\n    {% do return(period_of_load) %}\n{%- endmacro -%}\n\n\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.get_query_results_as_dict"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.086987}, "macro.dbtvault.bigquery__get_period_of_load": {"unique_id": "macro.dbtvault.bigquery__get_period_of_load", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/get_period_of_load.sql", "original_file_path": "macros/materialisations/period_mat_helpers/get_period_of_load.sql", "name": "bigquery__get_period_of_load", "macro_sql": "{%- macro bigquery__get_period_of_load(period, offset, start_timestamp) -%}\n\n    {% set period_of_load_sql -%}\n        SELECT DATE_TRUNC(DATE_ADD( DATE('{{start_timestamp}}'), INTERVAL {{ offset }} {{ period }}), {{ period }}  ) AS PERIOD_OF_LOAD\n    {%- endset %}\n\n    {% set period_of_load_dict = dbtvault.get_query_results_as_dict(period_of_load_sql) %}\n\n    {% set period_of_load = period_of_load_dict['PERIOD_OF_LOAD'][0] | string %}\n\n    {% do return(period_of_load) %}\n{%- endmacro -%}\n\n\n\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.get_query_results_as_dict"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.087884}, "macro.dbtvault.sqlserver__get_period_of_load": {"unique_id": "macro.dbtvault.sqlserver__get_period_of_load", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/materialisations/period_mat_helpers/get_period_of_load.sql", "original_file_path": "macros/materialisations/period_mat_helpers/get_period_of_load.sql", "name": "sqlserver__get_period_of_load", "macro_sql": "{%- macro sqlserver__get_period_of_load(period, offset, start_timestamp) -%}\n    {#  MSSQL cannot CAST datetime2 strings with more than 7 decimal places #}\n    {% set start_timestamp_mssql = start_timestamp[0:23] %}\n\n    {% set period_of_load_sql -%}\n        SELECT DATEADD({{ period }}, DATEDIFF({{period}}, 0, DATEADD({{ period }}, {{ offset }}, CAST('{{ start_timestamp_mssql }}' AS DATETIME2))), 0) AS period_of_load\n    {%- endset %}\n\n    {% set period_of_load_dict = dbtvault.get_query_results_as_dict(period_of_load_sql) %}\n\n    {% set period_of_load = period_of_load_dict['PERIOD_OF_LOAD'][0] | string %}\n\n    {% do return(period_of_load) %}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.get_query_results_as_dict"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.0889862}, "macro.dbtvault.type_timestamp": {"unique_id": "macro.dbtvault.type_timestamp", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/datatypes.sql", "original_file_path": "macros/supporting/datatypes.sql", "name": "type_timestamp", "macro_sql": "{%- macro type_timestamp() -%}\n  {{ return(adapter.dispatch('type_timestamp', 'dbtvault')()) }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.089642}, "macro.dbtvault.default__type_timestamp": {"unique_id": "macro.dbtvault.default__type_timestamp", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/datatypes.sql", "original_file_path": "macros/supporting/datatypes.sql", "name": "default__type_timestamp", "macro_sql": "{%- macro default__type_timestamp() -%}\n    {{ dbt_utils.type_timestamp() }}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.type_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.089879}, "macro.dbtvault.sqlserver__type_timestamp": {"unique_id": "macro.dbtvault.sqlserver__type_timestamp", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/datatypes.sql", "original_file_path": "macros/supporting/datatypes.sql", "name": "sqlserver__type_timestamp", "macro_sql": "{%- macro sqlserver__type_timestamp() -%}\n    datetime2\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.090046}, "macro.dbtvault.max_datetime": {"unique_id": "macro.dbtvault.max_datetime", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/max_datetime.sql", "original_file_path": "macros/supporting/max_datetime.sql", "name": "max_datetime", "macro_sql": "{%- macro max_datetime() -%}\n\n    {{- return(adapter.dispatch('max_datetime', 'dbtvault')()) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__max_datetime"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.090793}, "macro.dbtvault.default__max_datetime": {"unique_id": "macro.dbtvault.default__max_datetime", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/max_datetime.sql", "original_file_path": "macros/supporting/max_datetime.sql", "name": "default__max_datetime", "macro_sql": "\n\n{%- macro default__max_datetime() %}\n\n    {% do return('9999-12-31 23:59:59.999999') %}\n\n{% endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.091074}, "macro.dbtvault.sqlserver__max_datetime": {"unique_id": "macro.dbtvault.sqlserver__max_datetime", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/max_datetime.sql", "original_file_path": "macros/supporting/max_datetime.sql", "name": "sqlserver__max_datetime", "macro_sql": "{%- macro sqlserver__max_datetime() %}\n\n    {% do return('9999-12-31 23:59:59.9999999') %}\n\n{% endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.0913541}, "macro.dbtvault.bigquery__max_datetime": {"unique_id": "macro.dbtvault.bigquery__max_datetime", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/max_datetime.sql", "original_file_path": "macros/supporting/max_datetime.sql", "name": "bigquery__max_datetime", "macro_sql": "{%- macro bigquery__max_datetime() %}\n\n    {% do return('9999-12-31 23:59:59.999999') %}\n\n{% endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.091629}, "macro.dbtvault.prefix": {"unique_id": "macro.dbtvault.prefix", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/prefix.sql", "original_file_path": "macros/supporting/prefix.sql", "name": "prefix", "macro_sql": "{%- macro prefix(columns, prefix_str, alias_target) -%}\n\n    {{- adapter.dispatch('prefix', 'dbtvault')(columns=columns,\n                                               prefix_str=prefix_str,\n                                               alias_target=alias_target) -}}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__prefix"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.116766}, "macro.dbtvault.default__prefix": {"unique_id": "macro.dbtvault.default__prefix", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/prefix.sql", "original_file_path": "macros/supporting/prefix.sql", "name": "default__prefix", "macro_sql": "{%- macro default__prefix(columns=none, prefix_str=none, alias_target='source') -%}\n\n    {%- if columns and prefix_str -%}\n\n        {%- for col in columns -%}\n\n            {%- if col is mapping -%}\n\n                {%- if alias_target == 'source' -%}\n\n                    {{- dbtvault.prefix([col['source_column']], prefix_str) -}}\n\n                {%- elif alias_target == 'target' -%}\n\n                    {{- dbtvault.prefix([col['alias']], prefix_str) -}}\n\n                {%- else -%}\n\n                    {{- dbtvault.prefix([col['source_column']], prefix_str) -}}\n\n                {%- endif -%}\n\n                {%- if not loop.last -%} , {% endif %}\n\n            {%- else -%}\n\n                {%- if col is iterable and col is not string -%}\n\n                    {{- dbtvault.prefix(col, prefix_str) -}}\n\n                {%- elif col is not none -%}\n\n                    {{- prefix_str}}.{{col.strip() -}}\n                {% else %}\n\n                    {%- if execute -%}\n                        {{- exceptions.raise_compiler_error(\"Unexpected or missing configuration for '\" ~ this ~ \"' Unable to prefix columns.\") -}}\n                    {%- endif -%}\n                {%- endif -%}\n\n                {{- ', ' if not loop.last -}}\n\n            {%- endif -%}\n\n        {%- endfor -%}\n\n    {%- else -%}\n\n        {%- if execute -%}\n            {{- exceptions.raise_compiler_error(\"Invalid parameters provided to prefix macro. Expected: (columns [list/string], prefix_str [string]) got: (\" ~ columns ~ \", \" ~ prefix_str ~ \")\") -}}\n        {%- endif -%}\n    {%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.prefix"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.119307}, "macro.dbtvault.current_timestamp": {"unique_id": "macro.dbtvault.current_timestamp", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/current_timestamp.sql", "original_file_path": "macros/supporting/current_timestamp.sql", "name": "current_timestamp", "macro_sql": "{% macro current_timestamp() -%}\n  {{ return(adapter.dispatch('current_timestamp', 'dbtvault')()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.120167}, "macro.dbtvault.default__current_timestamp": {"unique_id": "macro.dbtvault.default__current_timestamp", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/current_timestamp.sql", "original_file_path": "macros/supporting/current_timestamp.sql", "name": "default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() %}\n    {{ dbt_utils.current_timestamp() }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.current_timestamp"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.120417}, "macro.dbtvault.sqlserver__current_timestamp": {"unique_id": "macro.dbtvault.sqlserver__current_timestamp", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/current_timestamp.sql", "original_file_path": "macros/supporting/current_timestamp.sql", "name": "sqlserver__current_timestamp", "macro_sql": "{% macro sqlserver__current_timestamp() %}\n    sysdatetime()\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.1205802}, "macro.dbtvault.current_timestamp_in_utc": {"unique_id": "macro.dbtvault.current_timestamp_in_utc", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/current_timestamp.sql", "original_file_path": "macros/supporting/current_timestamp.sql", "name": "current_timestamp_in_utc", "macro_sql": "{% macro current_timestamp_in_utc() -%}\n  {{ return(adapter.dispatch('current_timestamp_in_utc', 'dbtvault')()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__current_timestamp_in_utc"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.120914}, "macro.dbtvault.default__current_timestamp_in_utc": {"unique_id": "macro.dbtvault.default__current_timestamp_in_utc", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/current_timestamp.sql", "original_file_path": "macros/supporting/current_timestamp.sql", "name": "default__current_timestamp_in_utc", "macro_sql": "{% macro default__current_timestamp_in_utc() %}\n    {{dbt_utils.current_timestamp_in_utc()}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.current_timestamp_in_utc"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.121158}, "macro.dbtvault.sqlserver__current_timestamp_in_utc": {"unique_id": "macro.dbtvault.sqlserver__current_timestamp_in_utc", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/current_timestamp.sql", "original_file_path": "macros/supporting/current_timestamp.sql", "name": "sqlserver__current_timestamp_in_utc", "macro_sql": "{% macro sqlserver__current_timestamp_in_utc() %}\n    sysutcdatetime()\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.1213179}, "macro.dbtvault.get_query_results_as_dict": {"unique_id": "macro.dbtvault.get_query_results_as_dict", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/get_query_results_as_dict.sql", "original_file_path": "macros/supporting/get_query_results_as_dict.sql", "name": "get_query_results_as_dict", "macro_sql": "{% macro get_query_results_as_dict(query) %}\n    {{ return(adapter.dispatch('get_query_results_as_dict', 'dbtvault')(query)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__get_query_results_as_dict"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.1222668}, "macro.dbtvault.default__get_query_results_as_dict": {"unique_id": "macro.dbtvault.default__get_query_results_as_dict", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/get_query_results_as_dict.sql", "original_file_path": "macros/supporting/get_query_results_as_dict.sql", "name": "default__get_query_results_as_dict", "macro_sql": "{% macro default__get_query_results_as_dict(query) %}\n    {{ return(dbt_utils.get_query_results_as_dict(query)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_utils.get_query_results_as_dict"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.1225889}, "macro.dbtvault.sqlserver__get_query_results_as_dict": {"unique_id": "macro.dbtvault.sqlserver__get_query_results_as_dict", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/get_query_results_as_dict.sql", "original_file_path": "macros/supporting/get_query_results_as_dict.sql", "name": "sqlserver__get_query_results_as_dict", "macro_sql": "{% macro sqlserver__get_query_results_as_dict(query) %}\n\n    {%- call statement('get_query_results', fetch_result=True,auto_begin=false) -%}\n\n        {{ query }}\n\n    {%- endcall -%}\n\n    {% set sql_results={} %}\n\n    {%- if execute -%}\n        {% set sql_results_table = load_result('get_query_results').table.columns %}\n        {% for column_name, column in sql_results_table.items() %}\n            {# Column names in upper case for consistency #}\n            {% do sql_results.update({column_name.upper(): column.values()}) %}\n        {% endfor %}\n    {%- endif -%}\n\n    {{ return(sql_results) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.statement"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648134126.1238241}, "macro.dbtvault.hash_columns": {"unique_id": "macro.dbtvault.hash_columns", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/staging/hash_columns.sql", "original_file_path": "macros/staging/hash_columns.sql", "name": "hash_columns", "macro_sql": "{%- macro hash_columns(columns=none) -%}\n\n    {{- adapter.dispatch('hash_columns', 'dbtvault')(columns=columns) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__hash_columns"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648138062.993757}, "macro.dbtvault.default__hash_columns": {"unique_id": "macro.dbtvault.default__hash_columns", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/staging/hash_columns.sql", "original_file_path": "macros/staging/hash_columns.sql", "name": "default__hash_columns", "macro_sql": "\n\n{%- macro default__hash_columns(columns=none) -%}\n\n{%- if columns is mapping and columns is not none -%}\n\n    {%- for col in columns -%}\n\n        {% if columns[col] is mapping and columns[col].is_hashdiff -%}\n\n            {{- dbtvault.hash(columns=columns[col]['columns'], \n                              alias=col, \n                              is_hashdiff=columns[col]['is_hashdiff']) -}}\n\n        {%- elif columns[col] is not mapping -%}\n\n            {{- dbtvault.hash(columns=columns[col],\n                              alias=col,\n                              is_hashdiff=false) -}}\n        \n        {%- elif columns[col] is mapping and not columns[col].is_hashdiff -%}\n\n            {%- if execute -%}\n                {%- do exceptions.warn(\"[\" ~ this ~ \"] Warning: You provided a list of columns under a 'columns' key, but did not provide the 'is_hashdiff' flag. Use list syntax for PKs.\") -%}\n            {% endif %}\n\n            {{- dbtvault.hash(columns=columns[col]['columns'], alias=col) -}}\n\n        {%- endif -%}\n\n        {{- \",\\n\" if not loop.last -}}\n    {%- endfor -%}\n\n{%- endif %}\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.hash"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648138062.996737}, "macro.dbtvault.stage": {"unique_id": "macro.dbtvault.stage", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/staging/stage.sql", "original_file_path": "macros/staging/stage.sql", "name": "stage", "macro_sql": "{%- macro stage(include_source_columns=none, source_model=none, hashed_columns=none, derived_columns=none, ranked_columns=none) -%}\n\n    {%- if include_source_columns is none -%}\n        {%- set include_source_columns = true -%}\n    {%- endif -%}\n\n    {{- adapter.dispatch('stage', 'dbtvault')(include_source_columns=include_source_columns,\n                                              source_model=source_model,\n                                              hashed_columns=hashed_columns,\n                                              derived_columns=derived_columns,\n                                              ranked_columns=ranked_columns) -}}\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__stage"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648138063.001703}, "macro.dbtvault.default__stage": {"unique_id": "macro.dbtvault.default__stage", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/staging/stage.sql", "original_file_path": "macros/staging/stage.sql", "name": "default__stage", "macro_sql": "{%- macro default__stage(include_source_columns, source_model, hashed_columns, derived_columns, ranked_columns) -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{% if (source_model is none) and execute %}\n\n    {%- set error_message -%}\n    Staging error: Missing source_model configuration. A source model name must be provided.\n    e.g.\n    [REF STYLE]\n    source_model: model_name\n    OR\n    [SOURCES STYLE]\n    source_model:\n        source_name: source_table_name\n    {%- endset -%}\n\n    {{- exceptions.raise_compiler_error(error_message) -}}\n{%- endif -%}\n\n{#- Check for source format or ref format and create relation object from source_model -#}\n{% if source_model is mapping and source_model is not none -%}\n\n    {%- set source_name = source_model | first -%}\n    {%- set source_table_name = source_model[source_name] -%}\n\n    {%- set source_relation = source(source_name, source_table_name) -%}\n    {%- set all_source_columns = dbtvault.source_columns(source_relation=source_relation) -%}\n{%- elif source_model is not mapping and source_model is not none -%}\n\n    {%- set source_relation = ref(source_model) -%}\n    {%- set all_source_columns = dbtvault.source_columns(source_relation=source_relation) -%}\n{%- else -%}\n\n    {%- set all_source_columns = [] -%}\n{%- endif -%}\n\n{%- set derived_column_names = dbtvault.extract_column_names(derived_columns) -%}\n{%- set hashed_column_names = dbtvault.extract_column_names(hashed_columns) -%}\n{%- set ranked_column_names = dbtvault.extract_column_names(ranked_columns) -%}\n{%- set exclude_column_names = derived_column_names + hashed_column_names %}\n{%- set source_and_derived_column_names = all_source_columns + derived_column_names %}\n\n{%- set source_columns_to_select = dbtvault.process_columns_to_select(all_source_columns, exclude_column_names) -%}\n{%- set derived_columns_to_select = dbtvault.process_columns_to_select(source_and_derived_column_names, hashed_column_names) | unique | list -%}\n{%- set final_columns_to_select = [] -%}\n\n{#- Include source columns in final column selection if true -#}\n{%- if include_source_columns -%}\n    {%- if dbtvault.is_nothing(derived_columns)\n           and dbtvault.is_nothing(hashed_columns)\n           and dbtvault.is_nothing(ranked_columns) -%}\n        {%- set final_columns_to_select = final_columns_to_select + dbtvault.escape_column_names(all_source_columns) -%}\n    {%- else -%}\n        {#- Only include non-overriden columns if not just source columns -#}\n        {%- set final_columns_to_select = final_columns_to_select + dbtvault.escape_column_names(source_columns_to_select) -%}\n    {%- endif -%}\n{%- endif %}\n\nWITH source_data AS (\n\n    SELECT\n\n    {{- \"\\n\\n    \" ~ dbtvault.print_list(dbtvault.escape_column_names(all_source_columns)) if all_source_columns else \" *\" }}\n\n    FROM {{ source_relation }}\n    {%- set last_cte = \"source_data\" %}\n)\n\n{%- if dbtvault.is_something(derived_columns) -%},\n\nderived_columns AS (\n\n    SELECT\n\n    {{ dbtvault.derive_columns(source_relation=source_relation, columns=derived_columns) | indent(4) }}\n\n    FROM {{ last_cte }}\n    {%- set last_cte = \"derived_columns\" -%}\n    {%- set final_columns_to_select = final_columns_to_select + dbtvault.escape_column_names(derived_column_names) %}\n)\n{%- endif -%}\n\n{% if dbtvault.is_something(hashed_columns) -%},\n\nhashed_columns AS (\n\n    SELECT\n\n    {{ dbtvault.print_list(dbtvault.escape_column_names(derived_columns_to_select)) }},\n\n    {% set processed_hash_columns = dbtvault.process_hash_column_excludes(hashed_columns, all_source_columns) -%}\n    {{- dbtvault.hash_columns(columns=processed_hash_columns) | indent(4) }}\n\n    FROM {{ last_cte }}\n    {%- set last_cte = \"hashed_columns\" -%}\n    {%- set final_columns_to_select = final_columns_to_select + dbtvault.escape_column_names(hashed_column_names) %}\n)\n{%- endif -%}\n\n{% if dbtvault.is_something(ranked_columns) -%},\n\nranked_columns AS (\n\n    SELECT *,\n\n    {{ dbtvault.rank_columns(columns=ranked_columns) | indent(4) if dbtvault.is_something(ranked_columns) }}\n\n    FROM {{ last_cte }}\n    {%- set last_cte = \"ranked_columns\" -%}\n    {%- set final_columns_to_select = final_columns_to_select + dbtvault.escape_column_names(ranked_column_names) %}\n)\n{%- endif -%}\n\n,\n\ncolumns_to_select AS (\n\n    SELECT\n\n    {{ dbtvault.print_list(final_columns_to_select) }}\n\n    FROM {{ last_cte }}\n)\n\nSELECT * FROM columns_to_select\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.prepend_generated_by", "macro.dbtvault.source_columns", "macro.dbtvault.extract_column_names", "macro.dbtvault.process_columns_to_select", "macro.dbtvault.is_nothing", "macro.dbtvault.escape_column_names", "macro.dbtvault.print_list", "macro.dbtvault.is_something", "macro.dbtvault.derive_columns", "macro.dbtvault.process_hash_column_excludes", "macro.dbtvault.hash_columns", "macro.dbtvault.rank_columns"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648138063.010154}, "macro.dbtvault.hash": {"unique_id": "macro.dbtvault.hash", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/hash.sql", "original_file_path": "macros/supporting/hash.sql", "name": "hash", "macro_sql": "{%- macro hash(columns=none, alias=none, is_hashdiff=false) -%}\n\n    {%- if is_hashdiff is none -%}\n        {%- set is_hashdiff = false -%}\n    {%- endif -%}\n\n    {{- adapter.dispatch('hash', 'dbtvault')(columns=columns, alias=alias, is_hashdiff=is_hashdiff) -}}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.default__hash"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648138063.019121}, "macro.dbtvault.default__hash": {"unique_id": "macro.dbtvault.default__hash", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/hash.sql", "original_file_path": "macros/supporting/hash.sql", "name": "default__hash", "macro_sql": "\n\n{%- macro default__hash(columns, alias, is_hashdiff) -%}\n\n{%- set hash = var('hash', 'MD5') -%}\n{%- set concat_string = var('concat_string', '||') -%}\n{%- set null_placeholder_string = var('null_placeholder_string', '^^') -%}\n\n{#- Select hashing algorithm -#}\n{%- if hash == 'MD5' -%}\n    {%- set hash_alg = 'MD5' -%}\n    {%- set hash_size = 16 -%} {#- \"not used for md5 algorithm\" -#}\n{%- elif hash == 'SHA' -%}\n    {%- set hash_alg = 'SHA2' -%}\n    {%- set hash_size = 256 -%}\n{%- else -%}\n    {%- set hash_alg = 'MD5' -%}\n    {%- set hash_size = 16 -%}\n{%- endif -%}\n\n{%- set standardise = \"NULLIF(UPPER(TRIM(CAST([EXPRESSION] AS STRING))), '')\" %}\n\n{#- Alpha sort columns before hashing if a hashdiff -#}\n{%- if is_hashdiff and dbtvault.is_list(columns) -%}\n    {%- set columns = columns|sort -%}\n{%- endif -%}\n\n{#- If single column to hash -#}\n{%- if columns is string -%}\n    {%- set column_str = dbtvault.as_constant(columns) -%}\n    {%- if dbtvault.is_expression(column_str) -%}\n        {%- set escaped_column_str = column_str -%}\n    {%- else -%}\n        {%- set escaped_column_str = dbtvault.escape_column_names(column_str) -%}\n    {%- endif -%}\n    {%- if hash == 'SHA' -%}\n        {{- \"{}({}, {}) AS {}\".format(hash_alg, standardise | replace('[EXPRESSION]', escaped_column_str), hash_size, dbtvault.escape_column_names(alias)) | indent(4) -}}\n    {%- else -%}\n        {{- \"{}({}) AS {}\".format(hash_alg, standardise | replace('[EXPRESSION]', escaped_column_str), dbtvault.escape_column_names(alias)) | indent(4) -}}\n    {%- endif -%}\n\n{#- Else a list of columns to hash -#}\n{%- else -%}\n    {%- set all_null = [] -%}\n\n    {%- if is_hashdiff -%}\n        {{- \"{}(CONCAT_WS('{}',\".format(hash_alg, concat_string) | indent(4) -}}\n    {%- else -%}\n        {{- \"{}(NULLIF(CONCAT_WS('{}',\".format(hash_alg, concat_string) | indent(4) -}}\n    {%- endif -%}\n\n    {%- for column in columns -%}\n\n        {%- do all_null.append(null_placeholder_string) -%}\n\n        {%- set column_str = dbtvault.as_constant(column) -%}\n        {%- if dbtvault.is_expression(column_str) -%}\n            {%- set escaped_column_str = column_str -%}\n        {%- else -%}\n            {%- set escaped_column_str = dbtvault.escape_column_names(column_str) -%}\n        {%- endif -%}\n        {{- \"\\nIFNULL({}, '{}')\".format(standardise | replace('[EXPRESSION]', escaped_column_str), null_placeholder_string) | indent(4) -}}\n        {{- \",\" if not loop.last -}}\n\n        {%- if loop.last -%}\n\n            {% if is_hashdiff %}\n                {%- if hash == 'SHA' -%}\n                    {{- \"\\n), {}) AS {}\".format(hash_size, dbtvault.escape_column_names(alias)) -}}\n                {%- else -%}\n                    {{- \"\\n)) AS {}\".format(dbtvault.escape_column_names(alias)) -}}\n                {%- endif -%}\n            {%- else -%}\n                {%- if hash == 'SHA' -%}\n                    {{- \"\\n), '{}'), {}) AS {}\".format(all_null | join(\"\"), hash_size, dbtvault.escape_column_names(alias)) -}}\n                {%- else -%}\n                    {{- \"\\n), '{}')) AS {}\".format(all_null | join(\"\"), dbtvault.escape_column_names(alias)) -}}\n                {%- endif -%}\n            {%- endif -%}\n        {%- else -%}\n\n            {%- do all_null.append(concat_string) -%}\n\n        {%- endif -%}\n\n    {%- endfor -%}\n\n{%- endif -%}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.is_list", "macro.dbtvault.as_constant", "macro.dbtvault.is_expression", "macro.dbtvault.escape_column_names"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648138063.02706}, "macro.dbtvault.bigquery__hash": {"unique_id": "macro.dbtvault.bigquery__hash", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/hash.sql", "original_file_path": "macros/supporting/hash.sql", "name": "bigquery__hash", "macro_sql": "{%- macro bigquery__hash(columns, alias, is_hashdiff) -%}\n\n{%- set hash = var('hash', 'MD5') -%}\n{%- set concat_string = var('concat_string', '||') -%}\n{%- set null_placeholder_string = var('null_placeholder_string', '^^') -%}\n\n{#- Select hashing algorithm -#}\n\n{%- if hash == 'MD5' -%}\n    {%- set hash_alg = 'MD5' -%}\n{%- elif hash == 'SHA' -%}\n    {%- set hash_alg = 'SHA256' -%}\n{%- endif -%}\n\n{%- set standardise = \"NULLIF(UPPER(TRIM(CAST([EXPRESSION] AS STRING))), '')\" %}\n\n{#- Alpha sort columns before hashing if a hashdiff -#}\n{%- if is_hashdiff and dbtvault.is_list(columns) -%}\n    {%- set columns = columns|sort -%}\n{%- endif -%}\n\n{#- If single column to hash -#}\n{%- if columns is string -%}\n    {%- set column_str = dbtvault.as_constant(columns) -%}\n    {%- if dbtvault.is_expression(column_str) -%}\n        {%- set escaped_column_str = column_str -%}\n    {%- else -%}\n        {%- set escaped_column_str = dbtvault.escape_column_names(column_str) -%}\n    {%- endif -%}\n    {{- \"CAST(UPPER(TO_HEX({}({}))) AS STRING) AS {}\".format(hash_alg, standardise | replace('[EXPRESSION]', escaped_column_str), dbtvault.escape_column_names(alias)) | indent(4) -}}\n\n{#- Else a list of columns to hash -#}\n{%- else -%}\n {%- set all_null = [] -%}\n    {%- if is_hashdiff -%}\n        {{- \"UPPER(TO_HEX({}(CONCAT(\".format(hash_alg) | indent(4) -}}\n\n    {%- else -%}\n        {{- \"UPPER(TO_HEX({}(NULLIF(CONCAT(\".format(hash_alg) | indent(4) -}}\n    {%- endif -%}\n\n    {%- for column in columns -%}\n\n        {%- do all_null.append(null_placeholder_string) -%}\n\n        {%- set column_str = dbtvault.as_constant(column) -%}\n        {%- if dbtvault.is_expression(column_str) -%}\n            {%- set escaped_column_str = column_str -%}\n        {%- else -%}\n            {%- set escaped_column_str = dbtvault.escape_column_names(column_str) -%}\n        {%- endif -%}\n        {{- \"\\nIFNULL({}, '{}')\".format(standardise | replace('[EXPRESSION]', escaped_column_str), null_placeholder_string) | indent(4) -}}\n        {{- \",'{}',\".format(concat_string) if not loop.last -}}\n        {%- if loop.last -%}\n\n            {% if is_hashdiff %}\n                {{- \"\\n)))) AS {}\".format(dbtvault.escape_column_names(alias)) -}}\n            {%- else -%}\n                {{- \"\\n), '{}')))) AS {}\".format(all_null | join(\"\"), dbtvault.escape_column_names(alias)) -}}\n            {%- endif -%}\n        {%- else -%}\n\n            {%- do all_null.append(concat_string) -%}\n        {%- endif -%}\n\n    {%- endfor -%}\n\n{%- endif -%}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.is_list", "macro.dbtvault.as_constant", "macro.dbtvault.is_expression", "macro.dbtvault.escape_column_names"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648138063.033196}, "macro.dbtvault.sqlserver__hash": {"unique_id": "macro.dbtvault.sqlserver__hash", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/supporting/hash.sql", "original_file_path": "macros/supporting/hash.sql", "name": "sqlserver__hash", "macro_sql": "{%- macro sqlserver__hash(columns, alias, is_hashdiff) -%}\n\n{%- set hash = var('hash', 'MD5') -%}\n{%- set concat_string = var('concat_string', '||') -%}\n{%- set null_placeholder_string = var('null_placeholder_string', '^^') -%}\n\n{#- Select hashing algorithm -#}\n{%- if hash == 'MD5' -%}\n    {%- set hash_alg = 'MD5' -%}\n    {%- set hash_size = 16 -%}\n{%- elif hash == 'SHA' -%}\n    {%- set hash_alg = 'SHA2_256' -%}\n    {%- set hash_size = 32 -%}\n{%- else -%}\n    {%- set hash_alg = 'MD5' -%}\n    {%- set hash_size = 16 -%}\n{%- endif -%}\n\n{%- set standardise = \"NULLIF(UPPER(TRIM(CAST([EXPRESSION] AS VARCHAR(max)))), '')\" %}\n\n{#- Alpha sort columns before hashing if a hashdiff -#}\n{%- if is_hashdiff and dbtvault.is_list(columns) -%}\n    {%- set columns = columns|sort -%}\n{%- endif -%}\n\n{#- If single column to hash -#}\n{%- if columns is string -%}\n    {%- set column_str = dbtvault.as_constant(columns) -%}\n    {%- if dbtvault.is_expression(column_str) -%}\n        {%- set escaped_column_str = column_str -%}\n    {%- else -%}\n        {%- set escaped_column_str = dbtvault.escape_column_names(column_str) -%}\n    {%- endif -%}\n    {{- \"CAST(HASHBYTES('{}', {}) AS BINARY({})) AS {}\".format(hash_alg, standardise | replace('[EXPRESSION]', escaped_column_str), hash_size, dbtvault.escape_column_names(alias)) | indent(4) -}}\n\n{#- Else a list of columns to hash -#}\n{%- else -%}\n    {%- set all_null = [] -%}\n\n    {%- if is_hashdiff -%}\n        {{- \"CAST(HASHBYTES('{}', (CONCAT_WS('{}',\".format(hash_alg, concat_string) | indent(4) -}}\n    {%- else -%}\n        {{- \"CAST(HASHBYTES('{}', (NULLIF(CONCAT_WS('{}',\".format(hash_alg, concat_string) | indent(4) -}}\n    {%- endif -%}\n\n    {%- for column in columns -%}\n\n        {%- do all_null.append(null_placeholder_string) -%}\n\n        {%- set column_str = dbtvault.as_constant(column) -%}\n        {%- if dbtvault.is_expression(column_str) -%}\n            {%- set escaped_column_str = column_str -%}\n        {%- else -%}\n            {%- set escaped_column_str = dbtvault.escape_column_names(column_str) -%}\n        {%- endif -%}\n        {{- \"\\nISNULL({}, '{}')\".format(standardise | replace('[EXPRESSION]', escaped_column_str), null_placeholder_string) | indent(4) -}}\n        {{- \",\" if not loop.last -}}\n\n        {%- if loop.last -%}\n\n            {% if is_hashdiff %}\n                {{- \"\\n))) AS BINARY({})) AS {}\".format(hash_size, dbtvault.escape_column_names(alias)) -}}\n            {%- else -%}\n                {{- \"\\n), '{}'))) AS BINARY({})) AS {}\".format(all_null | join(\"\"), hash_size, dbtvault.escape_column_names(alias)) -}}\n            {%- endif -%}\n        {%- else -%}\n\n            {%- do all_null.append(concat_string) -%}\n\n        {%- endif -%}\n\n    {%- endfor -%}\n\n{%- endif -%}\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.is_list", "macro.dbtvault.as_constant", "macro.dbtvault.is_expression", "macro.dbtvault.escape_column_names"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648138063.0393012}, "macro.dbtvault.link": {"unique_id": "macro.dbtvault.link", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/link.sql", "original_file_path": "macros/tables/snowflake/link.sql", "name": "link", "macro_sql": "{%- macro link(src_pk, src_fk, src_ldts, src_source, source_model) -%}\n\n    {{- adapter.dispatch('link', 'dbtvault')(src_pk=src_pk, src_fk=src_fk,\n                                             src_ldts=src_ldts, src_source=src_source,\n                                             source_model=source_model) -}}\n\n{%- endmacro -%}\n\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.spark__link"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648139060.2954612}, "macro.dbtvault.default__link": {"unique_id": "macro.dbtvault.default__link", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/snowflake/link.sql", "original_file_path": "macros/tables/snowflake/link.sql", "name": "default__link", "macro_sql": "{%- macro default__link(src_pk, src_fk, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_fk=src_fk,\n                                       src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set src_pk = dbtvault.escape_column_names(src_pk) -%}\n{%- set src_fk = dbtvault.escape_column_names(src_fk) -%}\n{%- set src_ldts = dbtvault.escape_column_names(src_ldts) -%}\n{%- set src_source = dbtvault.escape_column_names(src_source) -%}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_fk, src_ldts, src_source]) -%}\n{%- set fk_cols = dbtvault.expand_column_list([src_fk]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + dbtvault.escape_column_names([config.get('rank_column')]) -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{{ 'WITH ' -}}\n\n{%- if not (source_model is iterable and source_model is not string) -%}\n    {%- set source_model = [source_model] -%}\n{%- endif -%}\n\n{%- set ns = namespace(last_cte= \"\") -%}\n\n{%- for src in source_model -%}\n\n{%- set source_number = loop.index | string -%}\n\nrow_rank_{{ source_number }} AS (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ dbtvault.prefix(source_cols_with_rank, 'rr') }},\n    {%- else %}\n    SELECT {{ dbtvault.prefix(source_cols, 'rr') }},\n    {%- endif %}\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'rr') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'rr') }}\n           ) AS row_number\n    FROM {{ ref(src) }} AS rr\n    {%- if source_model | length == 1 %}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='rr', condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(fk_cols, prefix='rr', condition='IS NOT NULL') }}\n    {%- endif %}\n    QUALIFY row_number = 1\n    {%- set ns.last_cte = \"row_rank_{}\".format(source_number) %}\n),{{ \"\\n\" if not loop.last }}\n{% endfor -%}\n{% if source_model | length > 1 %}\nstage_union AS (\n    {%- for src in source_model %}\n    SELECT * FROM row_rank_{{ loop.index | string }}\n    {%- if not loop.last %}\n    UNION ALL\n    {%- endif %}\n    {%- endfor %}\n    {%- set ns.last_cte = \"stage_union\" %}\n),\n{%- endif -%}\n{%- if model.config.materialized == 'vault_insert_by_period' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __PERIOD_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- elif model.config.materialized == 'vault_insert_by_rank' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __RANK_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{% endif %}\n{%- if source_model | length > 1 %}\n\nrow_rank_union AS (\n    SELECT ru.*,\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'ru') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'ru') }}, {{ dbtvault.prefix([src_source], 'ru') }} ASC\n           ) AS row_rank_number\n    FROM {{ ns.last_cte }} AS ru\n    WHERE {{ dbtvault.multikey(src_pk, prefix='ru', condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(fk_cols, prefix='ru', condition='IS NOT NULL') }}\n    QUALIFY row_rank_number = 1\n    {%- set ns.last_cte = \"row_rank_union\" %}\n),\n{% endif %}\nrecords_to_insert AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='target') }}\n    FROM {{ ns.last_cte }} AS a\n    {%- if dbtvault.is_any_incremental() %}\n    LEFT JOIN {{ this }} AS d\n    ON {{ dbtvault.multikey(src_pk, prefix=['a','d'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='d', condition='IS NULL') }}\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.escape_column_names", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648139060.304576}, "macro.dbtvault.spark__link": {"unique_id": "macro.dbtvault.spark__link", "package_name": "dbtvault", "root_path": "/Users/ananda.dwi/Documents/projects/test_dbx/dbt_packages/dbtvault", "path": "macros/tables/databricks/link.sql", "original_file_path": "macros/tables/databricks/link.sql", "name": "spark__link", "macro_sql": "{%- macro spark__link(src_pk, src_fk, src_ldts, src_source, source_model) -%}\n\n{{- dbtvault.check_required_parameters(src_pk=src_pk, src_fk=src_fk,\n                                       src_ldts=src_ldts, src_source=src_source,\n                                       source_model=source_model) -}}\n\n{%- set source_cols = dbtvault.expand_column_list(columns=[src_pk, src_fk, src_ldts, src_source]) -%}\n{%- set src_pk_cols =dbtvault.expand_column_list(columns=[src_pk])  -%}\n\n{%- set fk_cols = dbtvault.expand_column_list([src_fk]) -%}\n\n{%- if model.config.materialized == 'vault_insert_by_rank' %}\n    {%- set source_cols_with_rank = source_cols + [config.get('rank_column')] -%}\n{%- endif -%}\n\n{{ dbtvault.prepend_generated_by() }}\n\n{{ 'WITH ' -}}\n\n{%- if not (source_model is iterable and source_model is not string) -%}\n    {%- set source_model = [source_model] -%}\n{%- endif -%}\n\n{%- set ns = namespace(last_cte= \"\") -%}\n\n{%- for src in source_model -%}\n\n{%- set source_number = loop.index | string -%}\n\nrow_rank_{{ source_number }} AS (\n    SELECT *\n    FROM\n    (\n    {%- if model.config.materialized == 'vault_insert_by_rank' %}\n    SELECT {{ dbtvault.prefix(source_cols_with_rank, 'rr') }},\n    {%- else %}\n    SELECT {{ dbtvault.prefix(source_cols, 'rr') }},\n    {%- endif %}\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'rr') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'rr') }}\n           ) AS row_number\n    FROM {{ ref(src) }} AS rr\n    {%- if source_model | length == 1 %}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='rr', condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(fk_cols, prefix='rr', condition='IS NOT NULL') }}\n    {%- endif %}\n    ) l\n    WHERE l.row_number = 1\n    {%- set ns.last_cte = \"row_rank_{}\".format(source_number) %}\n),{{ \"\\n\" if not loop.last }}\n{% endfor -%}\n{% if source_model | length > 1 %}\nstage_union AS (\n    {%- for src in source_model %}\n    SELECT * FROM row_rank_{{ loop.index | string }}\n    {%- if not loop.last %}\n    UNION ALL\n    {%- endif %}\n    {%- endfor %}\n    {%- set ns.last_cte = \"stage_union\" %}\n),\n{%- endif -%}\n{%- if model.config.materialized == 'vault_insert_by_period' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __PERIOD_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{%- elif model.config.materialized == 'vault_insert_by_rank' %}\nstage_mat_filter AS (\n    SELECT *\n    FROM {{ ns.last_cte }}\n    WHERE __RANK_FILTER__\n    {%- set ns.last_cte = \"stage_mat_filter\" %}\n),\n{% endif %}\n{%- if source_model | length > 1 %}\n\nrow_rank_union AS (\n    SELECT *\n    FROM\n    (\n    SELECT ru.*,\n           ROW_NUMBER() OVER(\n               PARTITION BY {{ dbtvault.prefix([src_pk], 'ru') }}\n               ORDER BY {{ dbtvault.prefix([src_ldts], 'ru') }}, {{ dbtvault.prefix([src_source], 'ru') }} ASC\n           ) AS row_rank_number\n    FROM {{ ns.last_cte }} AS ru\n    WHERE {{ dbtvault.multikey(src_pk, prefix='ru', condition='IS NOT NULL') }}\n    AND {{ dbtvault.multikey(fk_cols, prefix='ru', condition='IS NOT NULL') }}\n    ) r\n    WHERE r.row_rank_number = 1\n    {%- set ns.last_cte = \"row_rank_union\" %}\n),\n{% endif %}\nrecords_to_insert AS (\n    SELECT {{ dbtvault.prefix(source_cols, 'a', alias_target='target') }}\n    FROM {{ ns.last_cte }} AS a\n    {%- if dbtvault.is_any_incremental() %}\n    LEFT JOIN {{ this }} AS d\n    ON {{ dbtvault.multikey(src_pk, prefix=['a','d'], condition='=') }}\n    WHERE {{ dbtvault.multikey(src_pk, prefix='d', condition='IS NULL') }}\n    {%- endif %}\n)\n\nSELECT * FROM records_to_insert\n\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbtvault.check_required_parameters", "macro.dbtvault.expand_column_list", "macro.dbtvault.prepend_generated_by", "macro.dbtvault.prefix", "macro.dbtvault.multikey", "macro.dbtvault.is_any_incremental"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": [], "created_at": 1648139060.318293}}, "docs": {"dbt.__overview__": {"unique_id": "dbt.__overview__", "package_name": "dbt", "root_path": "/usr/local/lib/python3.9/site-packages/dbt/include/global_project", "path": "overview.md", "original_file_path": "docs/overview.md", "name": "__overview__", "block_contents": "### Welcome!\n\nWelcome to the auto-generated documentation for your dbt project!\n\n### Navigation\n\nYou can use the `Project` and `Database` navigation tabs on the left side of the window to explore the models\nin your project.\n\n#### Project Tab\nThe `Project` tab mirrors the directory structure of your dbt project. In this tab, you can see all of the\nmodels defined in your dbt project, as well as models imported from dbt packages.\n\n#### Database Tab\nThe `Database` tab also exposes your models, but in a format that looks more like a database explorer. This view\nshows relations (tables and views) grouped into database schemas. Note that ephemeral models are _not_ shown\nin this interface, as they do not exist in the database.\n\n### Graph Exploration\nYou can click the blue icon on the bottom-right corner of the page to view the lineage graph of your models.\n\nOn model pages, you'll see the immediate parents and children of the model you're exploring. By clicking the `Expand`\nbutton at the top-right of this lineage pane, you'll be able to see all of the models that are used to build,\nor are built from, the model you're exploring.\n\nOnce expanded, you'll be able to use the `--select` and `--exclude` model selection syntax to filter the\nmodels in the graph. For more information on model selection, check out the [dbt docs](https://docs.getdbt.com/docs/model-selection-syntax).\n\nNote that you can also right-click on models to interactively filter and explore the graph.\n\n---\n\n### More information\n\n- [What is dbt](https://docs.getdbt.com/docs/introduction)?\n- Read the [dbt viewpoint](https://docs.getdbt.com/docs/viewpoint)\n- [Installation](https://docs.getdbt.com/docs/installation)\n- Join the [dbt Community](https://www.getdbt.com/community/) for questions and discussion"}}, "exposures": {}, "metrics": {}, "selectors": {}, "disabled": {}, "parent_map": {"model.test_dbx.raw_order_product": ["source.test_dbx.test_dbt.order", "source.test_dbx.test_dbt.order_product"], "model.test_dbx.raw_product": ["source.test_dbx.test_dbt.product"], "model.test_dbx.raw_customer": ["source.test_dbx.test_dbt.customer"], "model.test_dbx.sat_order": ["model.test_dbx.stg_order_product"], "model.test_dbx.hub_customer": ["model.test_dbx.stg_customer"], "model.test_dbx.sat_customer": ["model.test_dbx.stg_customer"], "model.test_dbx.stg_customer": ["model.test_dbx.raw_customer"], "model.test_dbx.hub_order": ["model.test_dbx.stg_order_product"], "model.test_dbx.stg_order_product": ["model.test_dbx.raw_order_product"], "model.test_dbx.hub_product": ["model.test_dbx.stg_product"], "model.test_dbx.sat_product": ["model.test_dbx.stg_product"], "model.test_dbx.stg_product": ["model.test_dbx.raw_product"], "model.test_dbx.link_order_product": ["model.test_dbx.stg_order_product"], "model.test_dbx.sat_order_product": ["model.test_dbx.stg_order_product"], "source.test_dbx.test_dbt.customer": [], "source.test_dbx.test_dbt.product": [], "source.test_dbx.test_dbt.order": [], "source.test_dbx.test_dbt.order_product": []}, "child_map": {"model.test_dbx.raw_order_product": ["model.test_dbx.stg_order_product"], "model.test_dbx.raw_product": ["model.test_dbx.stg_product"], "model.test_dbx.raw_customer": ["model.test_dbx.stg_customer"], "model.test_dbx.sat_order": [], "model.test_dbx.hub_customer": [], "model.test_dbx.sat_customer": [], "model.test_dbx.stg_customer": ["model.test_dbx.hub_customer", "model.test_dbx.sat_customer"], "model.test_dbx.hub_order": [], "model.test_dbx.stg_order_product": ["model.test_dbx.hub_order", "model.test_dbx.link_order_product", "model.test_dbx.sat_order", "model.test_dbx.sat_order_product"], "model.test_dbx.hub_product": [], "model.test_dbx.sat_product": [], "model.test_dbx.stg_product": ["model.test_dbx.hub_product", "model.test_dbx.sat_product"], "model.test_dbx.link_order_product": [], "model.test_dbx.sat_order_product": [], "source.test_dbx.test_dbt.customer": ["model.test_dbx.raw_customer"], "source.test_dbx.test_dbt.product": ["model.test_dbx.raw_product"], "source.test_dbx.test_dbt.order": ["model.test_dbx.raw_order_product"], "source.test_dbx.test_dbt.order_product": ["model.test_dbx.raw_order_product"]}}